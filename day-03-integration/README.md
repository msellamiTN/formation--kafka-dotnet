# ğŸ“… Day 03 â€” IntÃ©gration, Tests & ObservabilitÃ©

> **Jeudi 12 fÃ©vrier 2026** | 6h (9hâ€“12h / 13h30â€“16h30) | **Niveau** : AvancÃ© â†’ Production

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ã€ la fin de cette journÃ©e, vous serez capable de :

| # | Objectif | Bloc |
| --- | -------- | ---- |
| 1 | Construire un **traitement temps rÃ©el** avec Kafka Streams (KStream, KTable, agrÃ©gations) | 3.1 |
| 2 | DÃ©ployer des **connecteurs Source/Sink** et les gÃ©rer via REST API | 3.2 |
| 3 | Ã‰crire des **tests unitaires** avec MockProducer / MockConsumer | 3.3 |
| 4 | ImplÃ©menter des **tests d'intÃ©gration** avec EmbeddedKafka | 3.3 |
| 5 | Collecter les **mÃ©triques JMX** des brokers Kafka | 3.4 |
| 6 | Surveiller le **consumer lag** et la santÃ© du cluster via REST | 3.4 |
| 7 | Exposer des **mÃ©triques Prometheus** depuis Spring Boot / ASP.NET | 3.4 |

> **Ratio thÃ©orie/pratique** : 30% / 70% â€” Chaque bloc commence par 15-20 min de thÃ©orie puis enchaÃ®ne sur un lab hands-on.

---

## ğŸ“‹ PrÃ©requis

- âœ… **Day 01 & Day 02 complÃ©tÃ©s** (Labs 1.2aâ€“2.3a)
- âœ… Infrastructure Kafka fonctionnelle (Docker ou OpenShift Sandbox)
- âœ… Topic `banking.transactions` existant (6 partitions)
- âœ… **.NET 8 SDK + Confluent.Kafka 2.3.0+** (piste .NET)
- âœ… **Java 17 + Spring Boot 3.2+** (piste Java)

---

## ğŸ—ï¸ Dual Track : .NET vs Java

Day 03 propose **deux pistes parallÃ¨les** pour couvrir les deux Ã©cosystÃ¨mes principaux de Kafka :

| Piste | Technologie | Public Cible | Avantages |
| ----- | ----------- | ------------ | --------- |
| **.NET** | C# + Confluent.Kafka | Ã‰quipes Microsoft | Performance native, intÃ©gration Ã©cosystÃ¨me .NET |
| **Java** | Spring Boot + Spring Kafka | Ã‰quipes Java/Spring | Ã‰cosystÃ¨me mature, Kafka Streams natif |

> **ğŸ“‹ Choix de piste** : Les deux pistes couvrent les mÃªmes concepts. Choisissez selon votre expertise ou explorez les deux pour comparer !

---

## ğŸ—“ï¸ Planning de la journÃ©e

| CrÃ©neau | Bloc | DurÃ©e | Contenu |
| ------- | ---- | ----- | ------- |
| 09h00â€“09h30 | Recap | 30 min | Quiz Day 02 + correction, questions ouvertes |
| 09h30â€“11h00 | **3.1** | 1h30 | Kafka Streams : KStream, KTable, agrÃ©gations, fenÃªtrage |
| 11h00â€“11h15 | | 15 min | â˜• Pause |
| 11h15â€“12h00 | **3.2** | 45 min | Kafka Connect : Source/Sink, REST API, dÃ©mo |
| 12h00â€“13h30 | | 1h30 | ğŸ½ï¸ DÃ©jeuner |
| 13h30â€“14h30 | **3.3** | 1h | Tests Kafka : MockProducer/Consumer, EmbeddedKafka |
| 14h30â€“14h45 | | 15 min | â˜• Pause |
| 14h45â€“16h00 | **3.4** | 1h15 | ObservabilitÃ© : JMX, Prometheus, Grafana, Consumer Lag |
| 16h00â€“16h30 | Recap | 30 min | Bilan formation 3 jours, Q&A, prochaines Ã©tapes |

---

## ğŸ“š Bloc 3.1 â€” Kafka Streams (1h30)

> **ThÃ©orie** : 20 min | **Lab** : 1h10

### Concepts clÃ©s

```mermaid
flowchart LR
    subgraph Input["ğŸ“¥ Ã‰vÃ©nements"]
        IN["sales-events"]
    end

    subgraph Topology["ğŸ”„ Kafka Streams Topology"]
        FILTER["âš¡ Filter >100â‚¬"]
        AGG["ğŸ“Š Aggregate par produit"]
        WIN["â° FenÃªtrage par minute"]
        JOIN["ğŸ”— Join avec rÃ©fÃ©rentiel"]
    end

    subgraph Output["ğŸ“¤ RÃ©sultats"]
        OUT1["large-sales"]
        OUT2["sales-by-product"]
        OUT3["sales-per-minute"]
        OUT4["enriched-sales"]
    end

    IN --> FILTER --> OUT1
    IN --> AGG --> OUT2
    IN --> WIN --> OUT3
    IN --> JOIN --> OUT4
```

| Concept | Description | Exemple |
| ------- | ----------- | ------- |
| **KStream** | Flux continu d'Ã©vÃ©nements | Transactions bancaires |
| **KTable** | Vue matÃ©rialisÃ©e (changelog) | Soldes par compte |
| **Aggregation** | Regroupement et calcul | Total ventes par produit |
| **Windowing** | FenÃªtrage temporel | Statistiques par minute |
| **Join** | Enrichissement de donnÃ©es | Transaction + dÃ©tails produit |
| **State Store** | Stockage local queryable | RequÃªtes REST sur l'Ã©tat |

### Lab 3.1a â€” Kafka Streams Processing

#### ğŸ“‚ Piste .NET
> **[lab-3.1a â€” Kafka Streams (.NET)](./module-05-kafka-streams-ksqldb/dotnet/)**

**Objectifs du lab** :

1. Construire une topologie de traitement temps rÃ©el
2. ImplÃ©menter des agrÃ©gations par produit
3. Configurer le fenÃªtrage temporel (par minute)
4. Exposer les rÃ©sultats via REST API

#### ğŸ“‚ Piste Java
> **[lab-3.1a â€” Kafka Streams (Java)](./module-05-kafka-streams-ksqldb/java/README.md)**

**Objectifs du lab** :

1. Construire une `SalesTopology` avec KStream et KTable
2. ImplÃ©menter des agrÃ©gations par produit avec state store
3. Configurer le fenÃªtrage temporel (par minute)
4. Exposer les state stores via REST API (Interactive Queries)

**Concepts Java** :

```java
// Aggregate sales by product
salesStream
    .groupByKey()
    .aggregate(
        SaleAggregate::new,
        (key, value, aggregate) -> aggregate.add(sale),
        Materialized.as("sales-by-product-store")
    );

// Windowed aggregation per minute
salesStream
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(1)))
    .aggregate(/* ... */);
```

---

## ğŸ”Œ Bloc 3.2 â€” Kafka Connect (45 min)

> **ThÃ©orie** : 30 min | **DÃ©mo** : 15 min

### Concepts clÃ©s

```mermaid
flowchart LR
    subgraph Sources["ğŸ“¥ Sources"]
        DB[("ğŸ—„ï¸ SQL Server")]
        FILE["ğŸ“„ CSV/JSON"]
    end

    subgraph Connect["ğŸ”Œ Kafka Connect"]
        SC["Source Connector"]
        SK["Sink Connector"]
    end

    subgraph Kafka["ğŸ“¦ Kafka"]
        T["Topics"]
    end

    subgraph Sinks["ğŸ“¤ Destinations"]
        ES[("ğŸ” Elasticsearch")]
        S3["â˜ï¸ Blob Storage"]
    end

    DB --> SC --> T
    FILE --> SC
    T --> SK --> ES
    T --> SK --> S3
```

| Concept | Description |
| ------- | ----------- |
| **Source Connector** | Lit des donnÃ©es externes â†’ Kafka topics |
| **Sink Connector** | Lit Kafka topics â†’ Ã©crit vers systÃ¨mes externes |
| **Worker** | Process JVM qui exÃ©cute les connecteurs |
| **Task** | UnitÃ© de parallÃ©lisme au sein d'un connecteur |
| **Converter** | Transforme les donnÃ©es (JsonConverter, AvroConverter) |

> ğŸ”— **Lab complet Kafka Connect** : voir **[Module 06](./module-06-kafka-connect/README.md)**

---

## ğŸ§ª Bloc 3.3 â€” Tests Kafka (1h)

> **ThÃ©orie** : 15 min | **Lab** : 45 min

### Concepts clÃ©s

```mermaid
flowchart TB
    subgraph Pyramid["ğŸ”º Pyramide de Tests Kafka"]
        E2E["ğŸ” E2E Tests<br/>(Testcontainers + Real Kafka)<br/>10%"]
        INT["ğŸ“¦ Tests d'intÃ©gration<br/>(EmbeddedKafka)<br/>30%"]
        UNIT["âš¡ Tests unitaires<br/>(MockProducer/Consumer)<br/>60%"]
    end

    UNIT --> INT --> E2E

    style E2E fill:#ffcccc
    style INT fill:#ffffcc
    style UNIT fill:#ccffcc
```

| Niveau | Outil | Vitesse | FidÃ©litÃ© | Isolation |
| ------ | ----- | ------- | -------- | --------- |
| **Unit** | MockProducer/Consumer | âš¡âš¡âš¡ | â­ | âœ… Totale |
| **Integration** | EmbeddedKafka | âš¡âš¡ | â­â­ | âœ… Process |
| **E2E** | Testcontainers | âš¡ | â­â­â­ | âœ… Container |

### Lab 3.3a â€” Tests unitaires & intÃ©gration

#### ğŸ“‚ Piste .NET
> **[lab-3.3a â€” Tests Kafka (.NET)](./module-07-testing/dotnet/)**

**Objectifs du lab** :

1. Ã‰crire des tests unitaires avec Moq pour le Producer
2. Tester le Consumer avec des mocks
3. ImplÃ©menter des tests d'intÃ©gration avec Testcontainers
4. Valider la sÃ©rialisation/dÃ©sÃ©rialisation JSON

#### ğŸ“‚ Piste Java
> **[lab-3.3a â€” Tests Kafka (Java)](./module-07-testing/java/README.md)**

**Objectifs du lab** :

1. Ã‰crire des tests unitaires avec `MockProducer` (5 tests)
2. Tester le Consumer avec `MockConsumer` (4 tests)
3. Valider le routage par clÃ©, la sÃ©rialisation JSON, la gestion d'erreurs
4. (Bonus) Tests d'intÃ©gration avec EmbeddedKafka

**Concepts Java** :

```java
// MockProducer - test sans broker Kafka
MockProducer<String, String> mockProducer =
    new MockProducer<>(true, new StringSerializer(), new StringSerializer());

service.send(transaction);

assertEquals(1, mockProducer.history().size());
assertEquals("CUST-001", mockProducer.history().get(0).key());

// MockConsumer - test sans broker Kafka
MockConsumer<String, String> mockConsumer =
    new MockConsumer<>(OffsetResetStrategy.EARLIEST);
mockConsumer.addRecord(new ConsumerRecord<>(TOPIC, 0, 0L, key, json));
```

---

## ğŸ“Š Bloc 3.4 â€” ObservabilitÃ© (1h15)

> **ThÃ©orie** : 20 min | **Lab** : 55 min

### Concepts clÃ©s â€” Les 3 piliers

```mermaid
flowchart TB
    subgraph Observability["ğŸ“Š ObservabilitÃ© Kafka"]
        subgraph Metrics["ğŸ“ˆ MÃ©triques"]
            JMX["JMX Exporter"]
            PROM["Prometheus"]
            GRAF["Grafana"]
        end

        subgraph Logs["ğŸ“ Logs"]
            KL["Kafka Logs"]
            AL["App Logs"]
            ELK["ELK Stack"]
        end

        subgraph Traces["ğŸ”— Traces"]
            OT["OpenTelemetry"]
            JAEG["Jaeger"]
            CORR["Correlation IDs"]
        end
    end

    JMX --> PROM --> GRAF
    KL --> ELK
    AL --> ELK
    OT --> JAEG
```

| MÃ©trique | Description | Seuil d'alerte |
| -------- | ----------- | -------------- |
| **consumer_lag** | Messages non consommÃ©s | > 1000 |
| **request_latency_avg** | Latence moyenne | > 100ms |
| **bytes_in_per_sec** | DÃ©bit entrant | Selon capacitÃ© |
| **under_replicated_partitions** | Partitions sous-rÃ©pliquÃ©es | > 0 |
| **active_controller_count** | ContrÃ´leurs actifs | â‰  1 |

### Lab 3.4a â€” Tableau de bord MÃ©triques

#### ğŸ“‚ Piste Java
> **[lab-3.4a â€” Metrics Dashboard (Java)](./module-08-observability/java/README.md)**

**Objectifs du lab** :

1. Interroger la santÃ© du cluster Kafka via `AdminClient`
2. Surveiller le **consumer lag** par groupe
3. Lister les topics avec mÃ©tadonnÃ©es (partitions, rÃ©plication)
4. Exposer des mÃ©triques **Prometheus** via Micrometer

**Concepts Java** :

```java
// AdminClient pour la santÃ© du cluster
DescribeClusterResult cluster = adminClient.describeCluster();
Collection<Node> nodes = cluster.nodes().get();
Node controller = cluster.controller().get();

// Consumer lag
Map<TopicPartition, OffsetAndMetadata> offsets =
    adminClient.listConsumerGroupOffsets(groupId)
        .partitionsToOffsetAndMetadata().get();
```

---

## ğŸ—ï¸ Architecture Day 03

```mermaid
flowchart TB
    subgraph OpenShift["â˜ï¸ OpenShift Sandbox (msellamitn-dev)"]
        subgraph Infra["Infrastructure"]
            K["ğŸ“¦ Kafka<br/>kafka-svc:9092"]
        end

        subgraph Bloc31["Bloc 3.1 - Kafka Streams"]
            STREAMS["ğŸ”· ebanking-streams-java<br/>:8080"]
        end

        subgraph Bloc34["Bloc 3.4 - ObservabilitÃ©"]
            METRICS["ğŸ”· ebanking-metrics-java<br/>:8080"]
        end
    end

    subgraph Local["ğŸ–¥ï¸ DÃ©veloppement Local"]
        subgraph Bloc32["Bloc 3.2 - Kafka Connect"]
            KC["ğŸ”Œ Kafka Connect<br/>:8083"]
        end

        subgraph Bloc33["Bloc 3.3 - Tests"]
            TESTS["ğŸ§ª mvn test / dotnet test"]
        end

        subgraph Docker["ğŸ³ Docker"]
            PROM["ğŸ“ˆ Prometheus<br/>:9090"]
            GRAF["ğŸ“‰ Grafana<br/>:3000"]
        end
    end

    STREAMS -->|"read/write topics"| K
    METRICS -->|"AdminClient"| K
    KC -->|"source/sink"| K
```

---

## ğŸ“¦ Modules & Labs

| Bloc | Module | Lab | DurÃ©e | Description |
| ---- | ------ | --- | ----- | ----------- |
| 3.1 | [Kafka Streams](./module-05-kafka-streams-ksqldb/README.md) | Lab 3.1a | 1h10 | KStream, KTable, agrÃ©gations, fenÃªtrage |
| 3.2 | [Kafka Connect](./module-06-kafka-connect/README.md) | (dÃ©mo) | 15 min | Source/Sink connectors, REST API |
| 3.3 | [Tests Kafka](./module-07-testing/README.md) | Lab 3.3a | 45 min | MockProducer/Consumer, EmbeddedKafka |
| 3.4 | [ObservabilitÃ©](./module-08-observability/README.md) | Lab 3.4a | 55 min | AdminClient, Prometheus, Consumer Lag |

---

## ğŸš€ Quick Start

### DÃ©marrer l'infrastructure

<details>
<summary>ğŸ³ Docker</summary>

```bash
# Depuis la racine du projet
cd day-01-foundations/module-01-cluster
./scripts/up.sh

# VÃ©rifier que Kafka est healthy
docker ps | grep kafka
```

</details>

<details>
<summary>â˜ï¸ OpenShift Sandbox</summary>

```bash
oc login --token=<TOKEN> --server=<SERVER>
oc get pods -l app=kafka
```

</details>

### DÃ©ployer les labs Java sur OpenShift

<details>
<summary>ğŸ–¥ï¸ PowerShell</summary>

```powershell
cd day-03-integration\scripts\powershell
.\deploy-all-labs.ps1 -Token "sha256~XXX" -Server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

<details>
<summary>ğŸ§ Bash</summary>

```bash
cd day-03-integration/scripts/bash
./deploy-all-labs.sh --token "sha256~XXX" --server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

### Tester toutes les APIs

<details>
<summary>ğŸ–¥ï¸ PowerShell</summary>

```powershell
.\test-all-apis.ps1 -Token "sha256~XXX" -Server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

<details>
<summary>ğŸ§ Bash</summary>

```bash
./test-all-apis.sh --token "sha256~XXX" --server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

### Lancer les tests locaux (Lab 3.3a)

```bash
# Piste Java
cd day-03-integration/module-07-testing/java
mvn test

# Piste .NET
cd day-03-integration/module-07-testing/dotnet
dotnet test
```

---

## ğŸš¢ DÃ©ploiement â€” 3 Environnements

Chaque lab Day 03 peut Ãªtre dÃ©ployÃ© dans **3 environnements**, comme les labs Day 01 et Day 02 :

| Environnement | Outil | Kafka Bootstrap | AccÃ¨s API |
| ------------- | ----- | --------------- | --------- |
| **ğŸ³ Docker / Local** | `mvn spring-boot:run` | `localhost:9092` | `http://localhost:8080/` |
| **â˜ï¸ OpenShift Sandbox** | `oc new-build` + Binary Build | `kafka-svc:9092` | `https://{route}/` |
| **â˜¸ï¸ K8s / OKD** | `docker build` + `kubectl apply` | `kafka-svc:9092` | `http://localhost:8080/` (port-forward) |

### Ports locaux Day 03

| Lab | API Name | Port Local | URL |
| --- | -------- | ---------- | --- |
| 3.1a | Kafka Streams API | `:8080` | `http://localhost:8080/api/v1/sales` |
| 3.4a | Metrics Dashboard API | `:8080` | `http://localhost:8080/api/v1/metrics/cluster` |

### RÃ©capitulatif des noms d'applications

| Lab | App Name (oc/kubectl) | Route OpenShift |
| --- | --------------------- | --------------- |
| 3.1a | `ebanking-streams-java` | `ebanking-streams-java-secure` |
| 3.4a | `ebanking-metrics-java` | `ebanking-metrics-java-secure` |

### DÃ©ploiement sur OpenShift (Sandbox ou CRC)

```bash
# Pattern commun : Binary Build S2I pour chaque lab Java
cd day-03-integration/module-05-kafka-streams-ksqldb/java

oc new-build java:openjdk-17-ubi8 --binary=true --name=ebanking-streams-java
oc start-build ebanking-streams-java --from-dir=. --follow
oc new-app ebanking-streams-java
oc set env deployment/ebanking-streams-java SERVER_PORT=8080 KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092
oc create route edge ebanking-streams-java-secure --service=ebanking-streams-java --port=8080-tcp
```

---

## ğŸ“‹ Endpoints API

### Lab 3.1a â€” Kafka Streams Processing

| MÃ©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/` | Informations de l'application |
| GET | `/actuator/health` | VÃ©rification de santÃ© |
| POST | `/api/v1/sales` | Produire un Ã©vÃ©nement de vente |
| GET | `/api/v1/stats/by-product` | Statistiques agrÃ©gÃ©es par produit |
| GET | `/api/v1/stats/per-minute` | Statistiques fenÃªtrÃ©es par minute |
| GET | `/api/v1/stores/{name}/all` | Interroger un state store |
| GET | `/api/v1/stores/{name}/{key}` | Interroger un state store par clÃ© |

### Lab 3.4a â€” Tableau de bord MÃ©triques

| MÃ©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/` | Informations de l'application |
| GET | `/actuator/health` | VÃ©rification de santÃ© |
| GET | `/actuator/prometheus` | MÃ©triques Prometheus (Micrometer) |
| GET | `/api/v1/metrics/cluster` | SantÃ© du cluster Kafka (brokers, contrÃ´leur) |
| GET | `/api/v1/metrics/topics` | MÃ©tadonnÃ©es des topics (partitions, rÃ©plication) |
| GET | `/api/v1/metrics/consumers` | Consumer lag par groupe |

---

## âš ï¸ Troubleshooting

| Erreur | Cause | Solution |
| ------ | ----- | -------- |
| `Connector not found` | Plugin non installÃ© | VÃ©rifier `/usr/share/java/` |
| `No tasks assigned` | Configuration invalide | Valider avec PUT validate |
| `Testcontainers timeout` | Docker lent | Augmenter timeout startup |
| `Prometheus scrape failed` | JMX non exposÃ© | VÃ©rifier KAFKA_JMX_OPTS |
| `Streams not ready (503)` | Kafka Streams en dÃ©marrage | Attendre state = RUNNING |
| `AdminClient timeout` | Broker Kafka inaccessible | VÃ©rifier KAFKA_BOOTSTRAP_SERVERS |
| `MockProducer history empty` | Mock non injectÃ© | VÃ©rifier l'injection dans le service |

---

## âœ… Validation Day 03

- [ ] Lab 3.1a : Topologie Kafka Streams fonctionnelle, agrÃ©gations par produit, fenÃªtrage par minute
- [ ] Lab 3.1a : State stores accessibles via REST API
- [ ] Lab 3.2 : Comprendre Source/Sink connectors et la REST API de Kafka Connect
- [ ] Lab 3.3a : 9 tests unitaires passent (5 producer + 4 consumer) avec MockProducer/Consumer
- [ ] Lab 3.4a : SantÃ© du cluster visible via `/api/v1/metrics/cluster`
- [ ] Lab 3.4a : Consumer lag calculÃ© via `/api/v1/metrics/consumers`
- [ ] Lab 3.4a : MÃ©triques Prometheus exposÃ©es via `/actuator/prometheus`
- [ ] Comprendre les 3 piliers de l'observabilitÃ© (mÃ©triques, logs, traces)

---

## â¡ï¸ Navigation

â¬…ï¸ **[Day 02 â€” Patterns de Production & SÃ©rialisation](../day-02-development/README.md)** | ğŸ  **[Overview](../README.md)**
