# üìÖ Day 03 ‚Äî Int√©gration, Tests & Observabilit√©

> **Jeudi 12 f√©vrier 2026** | 6h (9h‚Äì12h / 13h30‚Äì16h30) | **Niveau** : Avanc√© ‚Üí Production

---

## üéØ Objectifs p√©dagogiques

√Ä la fin de cette journ√©e, vous serez capable de :

| # | Objectif | Bloc |
| --- | -------- | ---- |
| 1 | Construire un **traitement temps r√©el** avec Kafka Streams (KStream, KTable, agr√©gations) | 3.1 |
| 2 | D√©ployer des **connecteurs Source/Sink** et les g√©rer via REST API | 3.2 |
| 3 | √âcrire des **tests unitaires** avec MockProducer / MockConsumer | 3.3 |
| 4 | Impl√©menter des **tests d'int√©gration** avec EmbeddedKafka | 3.3 |
| 5 | Collecter les **m√©triques JMX** des brokers Kafka | 3.4 |
| 6 | Surveiller le **consumer lag** et la sant√© du cluster via REST | 3.4 |
| 7 | Exposer des **m√©triques Prometheus** depuis Spring Boot / ASP.NET | 3.4 |

> **Ratio th√©orie/pratique** : 30% / 70% ‚Äî Chaque bloc commence par 15-20 min de th√©orie puis encha√Æne sur un lab hands-on.

---

## üìã Pr√©requis

- ‚úÖ **Day 01 & Day 02 compl√©t√©s** (Labs 1.2a‚Äì2.3a)
- ‚úÖ Infrastructure Kafka fonctionnelle (Docker ou OpenShift Sandbox)
- ‚úÖ Topic `banking.transactions` existant (6 partitions)
- ‚úÖ **.NET 8 SDK + Confluent.Kafka 2.3.0+** (piste .NET)
- ‚úÖ **Java 17 + Spring Boot 3.2+** (piste Java)

---

## üèóÔ∏è Dual Track : .NET vs Java

Day 03 propose **deux pistes parall√®les** pour couvrir les deux √©cosyst√®mes principaux de Kafka :

| Piste | Technologie | Public Cible | Avantages |
| ----- | ----------- | ------------ | --------- |
| **.NET** | C# + Confluent.Kafka | √âquipes Microsoft | Performance native, int√©gration √©cosyst√®me .NET |
| **Java** | Spring Boot + Spring Kafka | √âquipes Java/Spring | √âcosyst√®me mature, Kafka Streams natif |

> **üìã Choix de piste** : Les deux pistes couvrent les m√™mes concepts. Choisissez selon votre expertise ou explorez les deux pour comparer !

---

## üóìÔ∏è Planning de la journ√©e

| Cr√©neau | Bloc | Dur√©e | Contenu |
| ------- | ---- | ----- | ------- |
| 09h00‚Äì09h30 | Recap | 30 min | Quiz Day 02 + correction, questions ouvertes |
| 09h30‚Äì11h00 | **3.1** | 1h30 | Kafka Streams : KStream, KTable, agr√©gations, fen√™trage |
| 11h00‚Äì11h15 | | 15 min | ‚òï Pause |
| 11h15‚Äì12h00 | **3.2** | 45 min | Kafka Connect : Source/Sink, REST API, d√©mo |
| 12h00‚Äì13h30 | | 1h30 | üçΩÔ∏è D√©jeuner |
| 13h30‚Äì14h30 | **3.3** | 1h | Tests Kafka : MockProducer/Consumer, EmbeddedKafka |
| 14h30‚Äì14h45 | | 15 min | ‚òï Pause |
| 14h45‚Äì16h00 | **3.4** | 1h15 | Observabilit√© : JMX, Prometheus, Grafana, Consumer Lag |
| 16h00‚Äì16h30 | Recap | 30 min | Bilan formation 3 jours, Q&A, prochaines √©tapes |

---

## üìö Bloc 3.1 ‚Äî Kafka Streams (1h30)

> **Th√©orie** : 20 min | **Lab** : 1h10

### Concepts cl√©s

```mermaid
flowchart LR
    subgraph Input["üì• √âv√©nements"]
        IN["sales-events"]
    end

    subgraph Topology["üîÑ Kafka Streams Topology"]
        FILTER["‚ö° Filter >100‚Ç¨"]
        AGG["üìä Aggregate par produit"]
        WIN["‚è∞ Fen√™trage par minute"]
        JOIN["üîó Join avec r√©f√©rentiel"]
    end

    subgraph Output["üì§ R√©sultats"]
        OUT1["large-sales"]
        OUT2["sales-by-product"]
        OUT3["sales-per-minute"]
        OUT4["enriched-sales"]
    end

    IN --> FILTER --> OUT1
    IN --> AGG --> OUT2
    IN --> WIN --> OUT3
    IN --> JOIN --> OUT4
```

| Concept | Description | Exemple |
| ------- | ----------- | ------- |
| **KStream** | Flux continu d'√©v√©nements | Transactions bancaires |
| **KTable** | Vue mat√©rialis√©e (changelog) | Soldes par compte |
| **Aggregation** | Regroupement et calcul | Total ventes par produit |
| **Windowing** | Fen√™trage temporel | Statistiques par minute |
| **Join** | Enrichissement de donn√©es | Transaction + d√©tails produit |
| **State Store** | Stockage local queryable | Requ√™tes REST sur l'√©tat |

### Lab 3.1a ‚Äî Kafka Streams Processing

#### üìÇ Piste .NET
> **[lab-3.1a ‚Äî Kafka Streams (.NET)](./module-05-kafka-streams-ksqldb/dotnet/)**

**Objectifs du lab** :

1. Construire une topologie de traitement temps r√©el
2. Impl√©menter des agr√©gations par produit
3. Configurer le fen√™trage temporel (par minute)
4. Exposer les r√©sultats via REST API

#### üìÇ Piste Java
> **[lab-3.1a ‚Äî Kafka Streams (Java)](./module-05-kafka-streams-ksqldb/java/README.md)**

**Objectifs du lab** :

1. Construire une `SalesTopology` avec KStream et KTable
2. Impl√©menter des agr√©gations par produit avec state store
3. Configurer le fen√™trage temporel (par minute)
4. Exposer les state stores via REST API (Interactive Queries)

**Concepts Java** :

```java
// Aggregate sales by product
salesStream
    .groupByKey()
    .aggregate(
        SaleAggregate::new,
        (key, value, aggregate) -> aggregate.add(sale),
        Materialized.as("sales-by-product-store")
    );

// Windowed aggregation per minute
salesStream
    .windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(1)))
    .aggregate(/* ... */);
```

---

## üîå Bloc 3.2 ‚Äî Kafka Connect (45 min)

> **Th√©orie** : 30 min | **D√©mo** : 15 min

### Concepts cl√©s

```mermaid
flowchart LR
    subgraph Sources["üì• Sources"]
        DB[("üóÑÔ∏è SQL Server")]
        FILE["üìÑ CSV/JSON"]
    end

    subgraph Connect["üîå Kafka Connect"]
        SC["Source Connector"]
        SK["Sink Connector"]
    end

    subgraph Kafka["üì¶ Kafka"]
        T["Topics"]
    end

    subgraph Sinks["üì§ Destinations"]
        ES[("üîç Elasticsearch")]
        S3["‚òÅÔ∏è Blob Storage"]
    end

    DB --> SC --> T
    FILE --> SC
    T --> SK --> ES
    T --> SK --> S3
```

| Concept | Description |
| ------- | ----------- |
| **Source Connector** | Lit des donn√©es externes ‚Üí Kafka topics |
| **Sink Connector** | Lit Kafka topics ‚Üí √©crit vers syst√®mes externes |
| **Worker** | Process JVM qui ex√©cute les connecteurs |
| **Task** | Unit√© de parall√©lisme au sein d'un connecteur |
| **Converter** | Transforme les donn√©es (JsonConverter, AvroConverter) |

> üîó **Lab complet Kafka Connect** : voir **[Module 06](./module-06-kafka-connect/README.md)**

---

## üß™ Bloc 3.3 ‚Äî Tests Kafka (1h)

> **Th√©orie** : 15 min | **Lab** : 45 min

### Concepts cl√©s

```mermaid
flowchart TB
    subgraph Pyramid["üî∫ Pyramide de Tests Kafka"]
        E2E["üîù E2E Tests<br/>(Testcontainers + Real Kafka)<br/>10%"]
        INT["üì¶ Tests d'int√©gration<br/>(EmbeddedKafka)<br/>30%"]
        UNIT["‚ö° Tests unitaires<br/>(MockProducer/Consumer)<br/>60%"]
    end

    UNIT --> INT --> E2E

    style E2E fill:#ffcccc
    style INT fill:#ffffcc
    style UNIT fill:#ccffcc
```

| Niveau | Outil | Vitesse | Fid√©lit√© | Isolation |
| ------ | ----- | ------- | -------- | --------- |
| **Unit** | MockProducer/Consumer | ‚ö°‚ö°‚ö° | ‚≠ê | ‚úÖ Totale |
| **Integration** | EmbeddedKafka | ‚ö°‚ö° | ‚≠ê‚≠ê | ‚úÖ Process |
| **E2E** | Testcontainers | ‚ö° | ‚≠ê‚≠ê‚≠ê | ‚úÖ Container |

### Lab 3.3a ‚Äî Tests unitaires & int√©gration

#### üìÇ Piste .NET
> **[lab-3.3a ‚Äî Tests Kafka (.NET)](./module-07-testing/dotnet/)**

**Objectifs du lab** :

1. √âcrire des tests unitaires avec Moq pour le Producer
2. Tester le Consumer avec des mocks
3. Impl√©menter des tests d'int√©gration avec Testcontainers
4. Valider la s√©rialisation/d√©s√©rialisation JSON

#### üìÇ Piste Java
> **[lab-3.3a ‚Äî Tests Kafka (Java)](./module-07-testing/java/README.md)**

**Objectifs du lab** :

1. √âcrire des tests unitaires avec `MockProducer` (5 tests)
2. Tester le Consumer avec `MockConsumer` (4 tests)
3. Valider le routage par cl√©, la s√©rialisation JSON, la gestion d'erreurs
4. (Bonus) Tests d'int√©gration avec EmbeddedKafka

**Concepts Java** :

```java
// MockProducer - test sans broker Kafka
MockProducer<String, String> mockProducer =
    new MockProducer<>(true, new StringSerializer(), new StringSerializer());

service.send(transaction);

assertEquals(1, mockProducer.history().size());
assertEquals("CUST-001", mockProducer.history().get(0).key());

// MockConsumer - test sans broker Kafka
MockConsumer<String, String> mockConsumer =
    new MockConsumer<>(OffsetResetStrategy.EARLIEST);
mockConsumer.addRecord(new ConsumerRecord<>(TOPIC, 0, 0L, key, json));
```

---

## üìä Bloc 3.4 ‚Äî Observabilit√© (1h15)

> **Th√©orie** : 20 min | **Lab** : 55 min

### Concepts cl√©s ‚Äî Les 3 piliers

```mermaid
flowchart TB
    subgraph Observability["üìä Observabilit√© Kafka"]
        subgraph Metrics["üìà M√©triques"]
            JMX["JMX Exporter"]
            PROM["Prometheus"]
            GRAF["Grafana"]
        end

        subgraph Logs["üìù Logs"]
            KL["Kafka Logs"]
            AL["App Logs"]
            ELK["ELK Stack"]
        end

        subgraph Traces["üîó Traces"]
            OT["OpenTelemetry"]
            JAEG["Jaeger"]
            CORR["Correlation IDs"]
        end
    end

    JMX --> PROM --> GRAF
    KL --> ELK
    AL --> ELK
    OT --> JAEG
```

| M√©trique | Description | Seuil d'alerte |
| -------- | ----------- | -------------- |
| **consumer_lag** | Messages non consomm√©s | > 1000 |
| **request_latency_avg** | Latence moyenne | > 100ms |
| **bytes_in_per_sec** | D√©bit entrant | Selon capacit√© |
| **under_replicated_partitions** | Partitions sous-r√©pliqu√©es | > 0 |
| **active_controller_count** | Contr√¥leurs actifs | ‚â† 1 |

### Lab 3.4a ‚Äî Tableau de bord M√©triques

#### üìÇ Piste Java
> **[lab-3.4a ‚Äî Metrics Dashboard (Java)](./module-08-observability/java/README.md)**

**Objectifs du lab** :

1. Interroger la sant√© du cluster Kafka via `AdminClient`
2. Surveiller le **consumer lag** par groupe
3. Lister les topics avec m√©tadonn√©es (partitions, r√©plication)
4. Exposer des m√©triques **Prometheus** via Micrometer

**Concepts Java** :

```java
// AdminClient pour la sant√© du cluster
DescribeClusterResult cluster = adminClient.describeCluster();
Collection<Node> nodes = cluster.nodes().get();
Node controller = cluster.controller().get();

// Consumer lag
Map<TopicPartition, OffsetAndMetadata> offsets =
    adminClient.listConsumerGroupOffsets(groupId)
        .partitionsToOffsetAndMetadata().get();
```

---

## üèóÔ∏è Architecture Day 03

```mermaid
flowchart TB
    subgraph OpenShift["‚òÅÔ∏è OpenShift Sandbox (msellamitn-dev)"]
        subgraph Infra["Infrastructure"]
            K["üì¶ Kafka<br/>kafka-svc:9092"]
        end

        subgraph Bloc31["Bloc 3.1 - Kafka Streams"]
            STREAMS["üî∑ ebanking-streams-java<br/>:8080"]
        end

        subgraph Bloc34["Bloc 3.4 - Observabilit√©"]
            METRICS["üî∑ ebanking-metrics-java<br/>:8080"]
        end
    end

    subgraph Local["üñ•Ô∏è D√©veloppement Local"]
        subgraph Bloc32["Bloc 3.2 - Kafka Connect"]
            KC["üîå Kafka Connect<br/>:8083"]
        end

        subgraph Bloc33["Bloc 3.3 - Tests"]
            TESTS["üß™ mvn test / dotnet test"]
        end

        subgraph Docker["üê≥ Docker"]
            PROM["üìà Prometheus<br/>:9090"]
            GRAF["üìâ Grafana<br/>:3000"]
        end
    end

    STREAMS -->|"read/write topics"| K
    METRICS -->|"AdminClient"| K
    KC -->|"source/sink"| K
```

---

## üì¶ Modules & Labs

| Bloc | Module | Lab | Dur√©e | Description |
| ---- | ------ | --- | ----- | ----------- |
| 3.1 | [Kafka Streams](./module-05-kafka-streams-ksqldb/README.md) | Lab 3.1a | 1h10 | KStream, KTable, agr√©gations, fen√™trage |
| 3.2 | [Kafka Connect](./module-06-kafka-connect/README.md) | (d√©mo) | 15 min | Source/Sink connectors, REST API |
| 3.3 | [Tests Kafka](./module-07-testing/README.md) | Lab 3.3a | 45 min | MockProducer/Consumer, EmbeddedKafka |
| 3.4 | [Observabilit√©](./module-08-observability/README.md) | Lab 3.4a | 55 min | AdminClient, Prometheus, Consumer Lag |

---

## üöÄ Quick Start

### D√©marrer l'infrastructure

<details>
<summary>üê≥ Docker</summary>

```bash
# Depuis la racine du projet
cd day-01-foundations/module-01-cluster
./scripts/up.sh

# V√©rifier que Kafka est healthy
docker ps | grep kafka
```

</details>

<details>
<summary>‚òÅÔ∏è OpenShift Sandbox</summary>

```bash
oc login --token=<TOKEN> --server=<SERVER>
oc get pods -l app=kafka
```

</details>

### D√©ployer les labs Java sur OpenShift

<details>
<summary>üñ•Ô∏è PowerShell</summary>

```powershell
cd day-03-integration\scripts\powershell
.\deploy-all-labs.ps1 -Token "sha256~XXX" -Server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

<details>
<summary>üêß Bash</summary>

```bash
cd day-03-integration/scripts/bash
./deploy-all-labs.sh --token "sha256~XXX" --server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

### Tester toutes les APIs

<details>
<summary>üñ•Ô∏è PowerShell</summary>

```powershell
.\test-all-apis.ps1 -Token "sha256~XXX" -Server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

<details>
<summary>üêß Bash</summary>

```bash
./test-all-apis.sh --token "sha256~XXX" --server "https://api.rm3.7wse.p1.openshiftapps.com:6443"
```

</details>

### Lancer les tests locaux (Lab 3.3a)

```bash
# Piste Java
cd day-03-integration/module-07-testing/java
mvn test

# Piste .NET
cd day-03-integration/module-07-testing/dotnet
dotnet test
```

---

## üö¢ D√©ploiement ‚Äî 3 Environnements

Chaque lab Day 03 peut √™tre d√©ploy√© dans **4 environnements**, comme les labs Day 01 et Day 02 :

| Environnement | Outil | Kafka Bootstrap | Acc√®s API |
| ------------- | ----- | --------------- | --------- |
| **üê≥ Docker / Local** | `mvn spring-boot:run` / `dotnet run` | `localhost:9092` | `http://localhost:8080/` |
| **‚òÅÔ∏è OpenShift Sandbox** | Scripts automatis√©s | `kafka-svc:9092` | `https://{route}/` |
| **‚ò∏Ô∏è K8s / OKD** | `docker build` + `kubectl apply` | `kafka-svc:9092` | `http://localhost:8080/` (port-forward) |
| **üñ•Ô∏è Local (IDE)** | VS Code / IntelliJ | `localhost:9092` | `http://localhost:8080/` |

### Ports locaux Day 03

| Lab | API Name | Port Local | URL |
| --- | -------- | ---------- | --- |
| 3.1a | Kafka Streams API | `:8080` | `http://localhost:8080/api/v1/sales` |
| 3.4a | Metrics Dashboard API | `:8080` | `http://localhost:8080/api/v1/metrics/cluster` |

### R√©capitulatif des noms d'applications

| Lab | Piste | App Name (oc/kubectl) | Route OpenShift |
| --- | ----- | --------------------- | --------------- |
| 3.1a | Java | `ebanking-streams-java` | `ebanking-streams-java-secure` |
| 3.1a | .NET | `ebanking-streams-dotnet` | `ebanking-streams-dotnet-secure` |
| 3.1b | .NET | `banking-ksqldb-lab` | `banking-ksqldb-lab-secure` |
| 3.4a | Java | `ebanking-metrics-java` | `ebanking-metrics-java-secure` |

### D√©ploiement sur OpenShift (Sandbox ou CRC)

```bash
# ‚îÄ‚îÄ Piste Java (S2I avec java:openjdk-17-ubi8) ‚îÄ‚îÄ
cd day-03-integration/module-05-kafka-streams-ksqldb/java
oc new-build java:openjdk-17-ubi8 --binary=true --name=ebanking-streams-java
oc start-build ebanking-streams-java --from-dir=. --follow
oc new-app ebanking-streams-java
oc set env deployment/ebanking-streams-java SERVER_PORT=8080 KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092
oc create route edge ebanking-streams-java-secure --service=ebanking-streams-java --port=8080-tcp

# ‚îÄ‚îÄ Piste .NET (S2I avec dotnet:8.0-ubi8) ‚îÄ‚îÄ
cd day-03-integration/module-05-kafka-streams-ksqldb/dotnet/M05StreamsApi
oc new-build dotnet:8.0-ubi8 --binary=true --name=ebanking-streams-dotnet
oc start-build ebanking-streams-dotnet --from-dir=. --follow
oc new-app ebanking-streams-dotnet
oc set env deployment/ebanking-streams-dotnet Kafka__BootstrapServers=kafka-svc:9092 ASPNETCORE_URLS=http://0.0.0.0:8080
oc create route edge ebanking-streams-dotnet-secure --service=ebanking-streams-dotnet --port=8080-tcp
```

> **Scripts automatis√©s** : Utilisez les scripts dans `scripts/bash/` ou `scripts/powershell/` pour un d√©ploiement complet avec tests int√©gr√©s. Voir [scripts/README.md](scripts/README.md).

---

## üìã Endpoints API

### Lab 3.1a ‚Äî Kafka Streams Processing

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/` | Informations de l'application |
| GET | `/actuator/health` | V√©rification de sant√© |
| POST | `/api/v1/sales` | Produire un √©v√©nement de vente |
| GET | `/api/v1/stats/by-product` | Statistiques agr√©g√©es par produit |
| GET | `/api/v1/stats/per-minute` | Statistiques fen√™tr√©es par minute |
| GET | `/api/v1/stores/{name}/all` | Interroger un state store |
| GET | `/api/v1/stores/{name}/{key}` | Interroger un state store par cl√© |

### Lab 3.1a (.NET) ‚Äî Streams API

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/` | Informations de l'application |
| GET | `/swagger` | Swagger UI |
| GET | `/api/v1/health` | V√©rification de sant√© |
| POST | `/api/v1/sales` | Produire un √©v√©nement de vente |
| GET | `/api/v1/stats/by-product` | Statistiques agr√©g√©es par produit |
| POST | `/api/v1/transactions` | Produire une transaction bancaire |
| GET | `/api/v1/balances` | Soldes clients |
| GET | `/api/v1/stores/{name}/all` | Interroger un state store |

### Lab 3.1b (.NET) ‚Äî ksqlDB Lab

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/swagger` | Swagger UI |
| GET | `/api/TransactionStream/health` | V√©rification de sant√© |
| POST | `/api/TransactionStream/initialize` | Initialiser les streams ksqlDB |
| POST | `/api/TransactionStream/transactions/generate/{n}` | G√©n√©rer N transactions de test |
| GET | `/api/TransactionStream/account/{id}/balance` | Pull query ‚Äî solde compte |
| GET | `/api/TransactionStream/verified/stream` | Push query ‚Äî transactions v√©rifi√©es |
| GET | `/api/TransactionStream/fraud/stream` | Push query ‚Äî alertes fraude |

### Lab 3.4a ‚Äî Tableau de bord M√©triques

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| GET | `/` | Informations de l'application |
| GET | `/actuator/health` | V√©rification de sant√© |
| GET | `/actuator/prometheus` | M√©triques Prometheus (Micrometer) |
| GET | `/api/v1/metrics/cluster` | Sant√© du cluster Kafka (brokers, contr√¥leur) |
| GET | `/api/v1/metrics/topics` | M√©tadonn√©es des topics (partitions, r√©plication) |
| GET | `/api/v1/metrics/consumers` | Consumer lag par groupe |

---

## üß™ Tests API ‚Äî Sc√©narios de Validation

### Lab 3.1a (Java) ‚Äî Kafka Streams Processing

```bash
# Health check
curl -k https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/health

# Produire un √©v√©nement de vente
curl -k -X POST https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":2,"unitPrice":125.00}'

# Statistiques par produit
curl -k https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/stats/by-product
```

### Lab 3.1a (.NET) ‚Äî Streams API

```bash
# Health check
curl -k https://ebanking-streams-dotnet-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/health

# Produire un √©v√©nement de vente
curl -k -X POST https://ebanking-streams-dotnet-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":3,"unitPrice":99.50}'

# Produire une transaction bancaire
curl -k -X POST https://ebanking-streams-dotnet-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/transactions \
  -H "Content-Type: application/json" \
  -d '{"customerId":"CUST-001","amount":1500.00,"type":"TRANSFER"}'

# Statistiques par produit
curl -k https://ebanking-streams-dotnet-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/stats/by-product
```

### Lab 3.1b (.NET) ‚Äî ksqlDB Lab

```bash
# Health check
curl -k https://banking-ksqldb-lab-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/TransactionStream/health

# Initialiser les streams ksqlDB
curl -k -X POST https://banking-ksqldb-lab-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/TransactionStream/initialize

# G√©n√©rer 5 transactions de test
curl -k -X POST https://banking-ksqldb-lab-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/TransactionStream/transactions/generate/5

# Solde d'un compte (Pull query)
curl -k https://banking-ksqldb-lab-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/TransactionStream/account/CUST-001/balance
```

### Lab 3.4a (Java) ‚Äî Metrics Dashboard

```bash
# Health check
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/health

# Sant√© du cluster Kafka
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/cluster

# M√©tadonn√©es des topics
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/topics

# Consumer lag par groupe
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/consumers

# M√©triques Prometheus
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/prometheus
```

---

## ‚ö†Ô∏è Troubleshooting

| Erreur | Cause | Solution |
| ------ | ----- | -------- |
| `Connector not found` | Plugin non install√© | V√©rifier `/usr/share/java/` |
| `No tasks assigned` | Configuration invalide | Valider avec PUT validate |
| `Testcontainers timeout` | Docker lent | Augmenter timeout startup |
| `Prometheus scrape failed` | JMX non expos√© | V√©rifier KAFKA_JMX_OPTS |
| `Streams not ready (503)` | Kafka Streams en d√©marrage | Attendre state = RUNNING |
| `AdminClient timeout` | Broker Kafka inaccessible | V√©rifier KAFKA_BOOTSTRAP_SERVERS |
| `MockProducer history empty` | Mock non inject√© | V√©rifier l'injection dans le service |
| `dotnet build failed` | .NET 8 SDK manquant | Installer .NET 8 ou utiliser `dotnet:8.0-ubi8` |
| `ksqlDB initialize failed` | ksqlDB non d√©ploy√© | D√©ployer ksqlDB d'abord via le script 3.1b |

---

## ‚úÖ Validation Day 03

### Piste Java

- [ ] Lab 3.1a : Topologie Kafka Streams fonctionnelle, agr√©gations par produit, fen√™trage par minute
- [ ] Lab 3.1a : State stores accessibles via REST API
- [ ] Lab 3.3a : 9 tests unitaires passent (5 producer + 4 consumer) avec MockProducer/Consumer
- [ ] Lab 3.4a : Sant√© du cluster visible via `/api/v1/metrics/cluster`
- [ ] Lab 3.4a : Consumer lag calcul√© via `/api/v1/metrics/consumers`
- [ ] Lab 3.4a : M√©triques Prometheus expos√©es via `/actuator/prometheus`

### Piste .NET

- [ ] Lab 3.1a : Streams API d√©ploy√©e, POST /api/v1/sales accept√©, stats par produit accessibles
- [ ] Lab 3.1a : Transactions bancaires et soldes clients fonctionnels
- [ ] Lab 3.1a : Swagger UI accessible
- [ ] Lab 3.1b : ksqlDB initialis√©, streams cr√©√©s
- [ ] Lab 3.1b : Push/Pull queries fonctionnelles (soldes, transactions v√©rifi√©es, alertes fraude)

### Commun

- [ ] Lab 3.2 : Comprendre Source/Sink connectors et la REST API de Kafka Connect
- [ ] Comprendre les 3 piliers de l'observabilit√© (m√©triques, logs, traces)

---

## ‚û°Ô∏è Navigation

‚¨ÖÔ∏è **[Day 02 ‚Äî Patterns de Production & S√©rialisation](../day-02-development/README.md)** | üè† **[Overview](../README.md)**
