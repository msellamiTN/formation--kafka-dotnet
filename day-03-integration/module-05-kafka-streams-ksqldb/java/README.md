# LAB 3.1A (Java) : Kafka Streams - Traitement en Temps RÃ©el

## â±ï¸ DurÃ©e EstimÃ©e : 90-120 minutes

## ğŸ¦ Contexte Bancaire E-Banking

Dans une banque moderne, les transactions arrivent continuellement de multiples canaux (web, mobile, distributeur). Au-delÃ  du simple passage de messages, nous avons besoin du **traitement en temps rÃ©el** pour :

- âœ… **AgrÃ©ger les ventes** par produit en temps rÃ©el
- âœ… **Calculs fenÃªtrÃ©s** (par minute, par heure)  
- âœ… **Filtrer les Ã©vÃ©nements** (ex: ventes importantes > 100â‚¬)
- âœ… **Enrichir les donnÃ©es** en joignant les flux avec des donnÃ©es de rÃ©fÃ©rence
- âœ… **Maintenir l'Ã©tat** pour des requÃªtes Ã  faible latence

Dans ce laboratoire, vous implÃ©menterez une **topologie Kafka Streams** pour le traitement des ventes en temps rÃ©el avec des opÃ©rations avec Ã©tat.

---

## ğŸ“Š Architecture

### Pipeline de Traitement Kafka Streams

```mermaid
flowchart LR
    subgraph Sources["ğŸ“¥ Ã‰vÃ©nements de Ventes"]
        WEB["ğŸŒ Banque Web"]
        MOB["ğŸ“± Application Mobile"]
        POS["ğŸª Terminal POS"]
    end

    subgraph Streams["ğŸ”„ Topologie Kafka Streams"]
        IN["ğŸ“‹ sales-events (entrÃ©e)"]
        FILTER["âš¡ Filtrer >100â‚¬"]
        AGG["ğŸ“Š AgrÃ©ger par Produit"]
        WIN["â° FenÃªtre par Minute"]
        JOIN["ğŸ”— Joindre avec Produits"]
        OUT1["ğŸ“‹ large-sales"]
        OUT2["ğŸ“‹ sales-by-product"]
        OUT3["ğŸ“‹ sales-per-minute"]
        OUT4["ğŸ“‹ enriched-sales"]
    end

    subgraph Stores["ğŸ’¾ Magasins d'Ã‰tat"]
        PROD_STORE["ğŸ“¦ sales-by-product-store"]
        WIN_STORE["â° sales-per-minute-store"]
        PROD_REF["ğŸ“‹ products-store"]
    end

    subgraph API["ğŸš€ API REST"]
        POST["POST /api/v1/sales"]
        STATS["GET /api/v1/stats/*"]
        STORE["GET /api/v1/stores/*"]
    end

    WEB --> IN
    MOB --> IN
    POS --> IN
    IN --> FILTER
    FILTER --> OUT1
    IN --> AGG --> PROD_STORE --> OUT2
    IN --> WIN --> WIN_STORE --> OUT3
    AGG --> JOIN --> PROD_REF --> OUT4
    POST --> IN
    STATS --> PROD_STORE
    STATS --> WIN_STORE
    STORE --> PROD_STORE
```

---

## ğŸ—ï¸ Project Structure

```
java/
â”œâ”€â”€ src/main/java/com/data2ai/kafka/
â”‚   â”œâ”€â”€ Application.java                    # Spring Boot main class
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ KafkaStreamsConfig.java         # Streams & Producer config
â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”œâ”€â”€ RootController.java              # Root endpoint
â”‚   â”‚   â””â”€â”€ SalesController.java             # REST endpoints
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ Sale.java                        # Input event model
â”‚   â”‚   â””â”€â”€ SaleAggregate.java               # Aggregated result model
â”‚   â””â”€â”€ streams/
â”‚       â”œâ”€â”€ JsonSerde.java                   # Custom JSON serde
â”‚       â””â”€â”€ SalesTopology.java               # Kafka Streams topology
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.properties               # Configuration
â””â”€â”€ pom.xml                                 # Maven dependencies
```

---

## ğŸš€ Guide Complet Ã‰tape par Ã‰tape

### ğŸ“‹ PrÃ©requis

- **Java 17+** - [TÃ©lÃ©charger Java](https://adoptium.net/)
- **Maven 3.6+** - [TÃ©lÃ©charger Maven](https://maven.apache.org/download.cgi)
- **Cluster Kafka** - Docker Compose ou OpenShift Sandbox
- **IDE** - IntelliJ IDEA ou VS Code
- **Git** - Pour cloner le dÃ©pÃ´t

---

## ğŸ› ï¸ Ã‰TAPE 1 : Configuration du Projet & Codage

### 1.1 Cloner et Naviguer vers le Projet

```bash
# Cloner le dÃ©pÃ´t (si pas dÃ©jÃ  fait)
git clone <url-dÃ©pÃ´t>
cd formation-kafka-dotnet/day-03-integration/module-05-kafka-streams-ksqldb/java
```

### 1.2 Comprendre la Structure du Projet

```text
java/
â”œâ”€â”€ src/main/java/com/data2ai/kafka/
â”‚   â”œâ”€â”€ Application.java                    # Classe principale Spring Boot
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ KafkaStreamsConfig.java         # Configuration Streams & Producer
â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”œâ”€â”€ RootController.java              # Endpoint racine
â”‚   â”‚   â””â”€â”€ SalesController.java             # Endpoints REST
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ Sale.java                        # ModÃ¨le d'Ã©vÃ©nement d'entrÃ©e
â”‚   â”‚   â””â”€â”€ SaleAggregate.java               # ModÃ¨le de rÃ©sultat agrÃ©gÃ©
â”‚   â””â”€â”€ streams/
â”‚       â”œâ”€â”€ JsonSerde.java                   # Serde JSON personnalisÃ©
â”‚       â””â”€â”€ SalesTopology.java               # Topologie Kafka Streams
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.properties               # Configuration
â””â”€â”€ pom.xml                                 # DÃ©pendances Maven
```

### 1.3 Composants ClÃ©s du Code

#### Topologie de Streams (`streams/SalesTopology.java`)
```java
// FonctionnalitÃ©s clÃ©s :
// - Consomme du topic 'sales-events'
// - Filtre les ventes importantes (> 100â‚¬) vers 'large-sales'
// - AgrÃ¨ge par ID produit dans 'sales-by-product' store
// - AgrÃ©gation fenÃªtrÃ©e par minute vers 'sales-per-minute'
// - Maintient les magasins d'Ã©tat RocksDB
```

#### ContrÃ´leurs API
```java
// SalesController.java:
// - POST /api/v1/sales - Produire un nouvel Ã©vÃ©nement de vente
// - GET /api/v1/stats/by-product - Obtenir les statistiques agrÃ©gÃ©es par produit
// - GET /api/v1/stats/per-minute - Obtenir les statistiques fenÃªtrÃ©es par minute

// RootController.java:
// - GET / - Informations sur l'application
// - GET /api/v1/stores/* - Interroger les magasins d'Ã©tat
```

---

## ğŸ”¨ Ã‰TAPE 2 : Construction de l'Application

### 2.1 Build de DÃ©veloppement Local

```bash
# Restaurer les dÃ©pendances
mvn clean install

# Construire le projet
mvn compile

# Construire pour la production
mvn clean package -DskipTests
```

### 2.2 VÃ©rifier la SuccÃ¨s du Build

```bash
# ExÃ©cuter les tests
mvn test

# VÃ©rifier la sortie du build
ls target/
# Devrait contenir : module05-kafka-streams-1.0.0.jar
```

### 2.3 Build Docker (Optionnel)

```bash
# Construire l'image Docker
docker build -t m05-kafka-streams-java .

# ExÃ©cuter le conteneur localement
docker run -p 8080:8080 m05-kafka-streams-java
```

---

## ğŸƒâ€â™‚ï¸ Ã‰TAPE 3 : ExÃ©cution de l'Application

### 3.1 ExÃ©cution de DÃ©veloppement Local

```bash
# MÃ©thode 1 : ExÃ©cution simple
mvn spring-boot:run

# MÃ©thode 2 : Avec environnement spÃ©cifique
SPRING_PROFILES_ACTIVE=dev mvn spring-boot:run

# MÃ©thode 3 : Avec port personnalisÃ©
SERVER_PORT=9090 mvn spring-boot:run
```

### 3.2 VÃ©rifier le DÃ©marrage de l'Application

**Sortie Attendue :**
```
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ \| '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_) | | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v3.2.0)

2024-01-01 12:00:00.000  INFO 12345 --- [           main] c.d.kafka.Application        : Starting Application...
2024-01-01 12:00:01.000  INFO 12345 --- [           main] c.d.kafka.Application        : Started Application in 1.234 seconds
```

### 3.3 AccÃ©der Ã  Swagger UI

Ouvrez votre navigateur et naviguez vers :
- **Swagger UI** : http://localhost:8080/swagger-ui.html
- **Actuator Health** : http://localhost:8080/actuator/health

---

## ğŸ§ª Ã‰TAPE 4 : Test des APIs de Streaming

### 4.1 VÃ©rification de SantÃ©

```bash
# Tester l'endpoint de santÃ©
curl http://localhost:8080/actuator/health

# RÃ©ponse attendue :
# {"status":"UP","streamsState":"RUNNING"}
```

### 4.2 Tests de Streaming des Ventes

#### 4.2.1 Produire des Ã‰vÃ©nements de Vente

```bash
# Vente 1 - Petit montant
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":2,"unitPrice":25.00}'

# RÃ©ponse attendue :
# {"topic":"sales-events","status":"ACCEPTED","productId":"PROD-001","totalAmount":50.0}

# Vente 2 - Grand montant (> 100â‚¬)
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-002","quantity":5,"unitPrice":150.00}'

# RÃ©ponse attendue :
# {"topic":"sales-events","status":"ACCEPTED","productId":"PROD-002","totalAmount":750.0}

# Vente 3 - DiffÃ©rent produit
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-003","quantity":1,"unitPrice":99.99}'
```

#### 4.2.2 Interroger les Statistiques AgrÃ©gÃ©es

```bash
# Attendre 2-3 secondes pour le traitement des streams
sleep 3

# Obtenir les stats par produit
curl http://localhost:8080/api/v1/stats/by-product

# RÃ©ponse attendue :
# {
#   "PROD-001": {"totalAmount":50.0,"count":1,"totalQuantity":2},
#   "PROD-002": {"totalAmount":750.0,"count":1,"totalQuantity":5},
#   "PROD-003": {"totalAmount":99.99,"count":1,"totalQuantity":1}
# }

# Obtenir les stats par minute
curl http://localhost:8080/api/v1/stats/per-minute

# RÃ©ponse attendue :
# {
#   "streamsState":"RUNNING",
#   "message":"Check sales-per-minute topic in Kafka UI"
# }
```

### 4.3 Tests des Magasins d'Ã‰tat

```bash
# Interroger toutes les entrÃ©es du magasin sales-by-product
curl http://localhost:8080/api/v1/stores/sales-by-product-store/all

# Interroger un produit spÃ©cifique dans le magasin
curl http://localhost:8080/api/v1/stores/sales-by-product-store/PROD-001

# Interroger le magasin fenÃªtrÃ© par minute
curl http://localhost:8080/api/v1/stores/sales-per-minute-store/all
```

---

## ğŸ” Ã‰TAPE 5 : VÃ©rifier le Traitement des Streams dans Kafka

### 5.1 Utiliser Kafka UI (RecommandÃ©)

**AccÃ¨s** : http://localhost:8080 (si exÃ©cutant Docker Kafka)

#### VÃ©rifier les Topics d'EntrÃ©e
1. Naviguer vers **Topics**
2. Cliquer sur **sales-events**
3. Cliquer sur l'onglet **Messages**
4. VÃ©rifier que les Ã©vÃ©nements de vente sont produits

#### VÃ©rifier les Topics de Sortie
1. **large-sales** - Doit contenir les ventes > 100â‚¬
2. **sales-by-product** - DonnÃ©es de ventes agrÃ©gÃ©es
3. **sales-per-minute** - AgrÃ©gations fenÃªtrÃ©es
4. **enriched-sales** - Ventes enrichies avec donnÃ©es de rÃ©fÃ©rence

### 5.2 Utiliser Kafka CLI

```bash
# VÃ©rifier le topic sales-events
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic sales-events \
  --from-beginning \
  --max-messages 5

# VÃ©rifier le topic large-sales (ventes filtrÃ©es)
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic large-sales \
  --from-beginning \
  --max-messages 5

# VÃ©rifier les stats par produit
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic sales-by-product \
  --from-beginning \
  --max-messages 5
```

---

## ğŸ“Š Ã‰TAPE 6 : ScÃ©narios de Tests AvancÃ©s

### 6.1 Test de Charge

```bash
# Produire plusieurs ventes rapidement
for i in {1..10}; do
  curl -X POST http://localhost:8080/api/v1/sales \
    -H "Content-Type: application/json" \
    -d "{\"productId\":\"PROD-00$i\",\"quantity\":$((i*2)),\"unitPrice\":$((i*10))}"
  sleep 0.1
done

# VÃ©rifier les rÃ©sultats agrÃ©gÃ©s
curl http://localhost:8080/api/v1/stats/by-product
```

### 6.2 Tests de Gestion d'Erreurs

```bash
# Tester des donnÃ©es de vente invalides
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"","quantity":-1,"unitPrice":0}'

# Attendu : 400 Bad Request

# Tester JSON invalide
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{invalid json}'

# Attendu : 400 Bad Request
```

### 6.3 Tests de Concurrence

```bash
# Simuler la production de ventes concurrentes
for i in {1..5}; do
  curl -X POST http://localhost:8080/api/v1/sales \
    -H "Content-Type: application/json" \
    -d "{\"productId\":\"PROD-CONC-$i\",\"quantity\":1,\"unitPrice\":100.00}" &
done
wait

# VÃ©rifier que toutes les ventes ont Ã©tÃ© traitÃ©es
curl http://localhost:8080/api/v1/stats/by-product
```

---

## ğŸš€ Ã‰TAPE 7 : DÃ©ploiement OpenShift (Optionnel)

### 7.1 Utiliser les Scripts de DÃ©ploiement

```bash
# Naviguer vers le rÃ©pertoire des scripts
cd ../../scripts

# ExÃ©cuter le dÃ©ploiement (Bash)
./bash/deploy-and-test-3.1a-java.sh --token "sha256~XXX" --server "https://api..."

# Ou PowerShell
./powershell/deploy-and-test-3.1a-java.ps1 -Token "sha256~XXX" -Server "https://api..."
```

### 7.2 DÃ©ploiement OpenShift Manuel

```bash
# Construire et pousser
oc new-build --name ebanking-streams-java --binary --strategy=source \
  --image-stream=java:openjdk-17-ubi8

oc start-build ebanking-streams-java --from-dir=. --follow

# DÃ©ployer
oc new-app ebanking-streams-java

# Configurer l'environnement
oc set env deployment/ebanking-streams-java \
  KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092

# CrÃ©er la route
oc create route edge ebanking-streams-java-secure \
  --service=ebanking-streams-java --port=8080-tcp
```

### 7.3 Tester le DÃ©ploiement OpenShift

```bash
# Obtenir l'URL de la route
ROUTE=$(oc get route ebanking-streams-java-secure -o jsonpath='{.spec.host}')

# Tester la santÃ©
curl -k https://$ROUTE/actuator/health

# Tester l'API des ventes
curl -k -X POST https://$ROUTE/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":2,"unitPrice":125.00}'
```

---

## ğŸš¢ DÃ©ploiement â€” 4 Environnements

| Environnement | Outil | Kafka Bootstrap | AccÃ¨s API |
| -------------- | ----- | --------------- | --------- |
| **ğŸ³ Docker / Local** | `mvn spring-boot:run` | `localhost:9092` | `http://localhost:8080/` |
| **â˜ï¸ OpenShift Sandbox** | Scripts automatisÃ©s | `kafka-svc:9092` | `https://{route}/` |
| **â˜¸ï¸ K8s / OKD** | `docker build` + `kubectl apply` | `kafka-svc:9092` | `http://localhost:8080/` (port-forward) |
| **ğŸ–¥ï¸ Local (IDE)** | VS Code / IntelliJ | `localhost:9092` | `http://localhost:8080/` |

### DÃ©veloppement Local

```bash
# Construire et exÃ©cuter localement
mvn clean spring-boot:run

# Swagger UI
open http://localhost:8080/swagger-ui.html
```

### DÃ©ploiement OpenShift

```bash
# DÃ©ployer en utilisant les scripts (recommandÃ©)
cd ../../scripts
./bash/deploy-and-test-3.1a-java.sh --token "sha256~XXX" --server "https://api..."

# Ou PowerShell
./powershell/deploy-and-test-3.1a-java.ps1 -Token "sha256~XXX" -Server "https://api..."
```

> **Le script gÃ¨re automatiquement :**
> - âœ… Build avec S2I (java:openjdk-17-ubi8)
> - âœ… DÃ©ploiement vers OpenShift
> - âœ… Configuration des variables d'environnement
> - âœ… CrÃ©ation de la route sÃ©curisÃ©e edge
> - âœ… Attente de la disponibilitÃ© du pod
> - âœ… ExÃ©cution des tests de validation API

---

## ğŸ§ª Tests d'API â€” ScÃ©narios de Validation

### VÃ©rification de SantÃ©

```bash
# Local
curl http://localhost:8080/actuator/health

# OpenShift Sandbox
curl -k https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/health
```

### Produire un Ã‰vÃ©nement de Vente

```bash
# Local
curl -X POST http://localhost:8080/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":2,"unitPrice":125.00}'

# OpenShift Sandbox
curl -k -X POST https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/sales \
  -H "Content-Type: application/json" \
  -d '{"productId":"PROD-001","quantity":2,"unitPrice":125.00}'
```

### Interroger les Stats AgrÃ©gÃ©es

```bash
# Local
curl http://localhost:8080/api/v1/stats/by-product

# OpenShift Sandbox
curl -k https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/stats/by-product
```

### Stats FenÃªtrÃ©es par Minute

```bash
# Local
curl http://localhost:8080/api/v1/stats/per-minute

# OpenShift Sandbox
curl -k https://ebanking-streams-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/stats/per-minute
```

### Interroger le Magasin d'Ã‰tat

```bash
# Local - Toutes les entrÃ©es
curl http://localhost:8080/api/v1/stores/sales-by-product-store/all

# Local - Par clÃ©
curl http://localhost:8080/api/v1/stores/sales-by-product-store/PROD-001
```

---

## ğŸ“Š VÃ©rification dans Kafka

### Utiliser Kafka UI

**Docker** : <http://localhost:8080>

1. Aller Ã  **Topics** â†’ **sales-events**
2. Cliquer sur **Messages**
3. VÃ©rifier les Ã©vÃ©nements de vente avec format JSON correct

### Utiliser Kafka CLI

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic sales-events \
  --from-beginning \
  --max-messages 5

# OpenShift Sandbox
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server kafka-0.kafka-svc:9092 \
  --topic sales-events \
  --from-beginning \
  --max-messages 5
```

---

## ğŸ“‹ Endpoints API

| MÃ©thode | Endpoint | Description | Corps de la RequÃªte |
|--------|----------|-------------|-------------------|
| GET | `/` | Informations application | - |
| GET | `/actuator/health` | VÃ©rification santÃ© | - |
| POST | `/api/v1/sales` | Produire Ã©vÃ©nement vente | `{"productId":"...","quantity":N,"unitPrice":N.N}` |
| GET | `/api/v1/stats/by-product` | Stats agrÃ©gÃ©es par produit | - |
| GET | `/api/v1/stats/per-minute` | Stats fenÃªtrÃ©es par minute | - |
| GET | `/api/v1/stores/{storeName}/all` | Interroger magasin d'Ã©tat toutes entrÃ©es | - |
| GET | `/api/v1/stores/{storeName}/{key}` | Interroger magasin d'Ã©tat par clÃ© | - |

---

## ğŸ”§ Configuration

### application.properties

```properties
server.port=8080
spring.application.name=module05-kafka-streams

# Kafka Streams
spring.kafka.streams.application-id=sales-streams-app
spring.kafka.streams.bootstrap-servers=localhost:9092

# Actuator
management.endpoints.web.exposure.include=health,info
management.endpoint.health.show-details=always
```

### Variables d'Environnement (OpenShift)

| Variable | DÃ©faut | Description |
|----------|--------|-------------|
| `SERVER_PORT` | 8080 | Port serveur HTTP |
| `KAFKA_BOOTSTRAP_SERVERS` | localhost:9092 | Brokers Kafka |
| `INPUT_TOPIC` | sales-events | Nom topic d'entrÃ©e |
| `OUTPUT_TOPIC` | sales-by-product | Nom topic de sortie |
| `APPLICATION_ID` | sales-streams-app | ID application Streams |

---

## ğŸ”„ Topologie Kafka Streams

La `SalesTopology` implÃ©mente :

1. **Filtrer** : Ventes importantes (>100â‚¬) â†’ topic `large-sales`
2. **AgrÃ©ger** : Ventes par produit â†’ topic `sales-by-product` + magasin d'Ã©tat
3. **FenÃªtrer** : Ventes par minute â†’ topic `sales-per-minute` + magasin fenÃªtrÃ©
4. **Joindre** : Ventes avec rÃ©fÃ©rence produit â†’ topic `enriched-sales`

### OpÃ©rations ClÃ©s

```java
// Filtrer les ventes importantes
salesStream.filter((key, value) -> {
    Sale sale = objectMapper.readValue(value, Sale.class);
    return sale.getTotalAmount() > 100;
})

// AgrÃ©ger par produit
.groupByKey()
.aggregate(
    SaleAggregate::new,
    (key, value, aggregate) -> aggregate.add(sale),
    Materialized.as("sales-by-product-store")
)

// AgrÃ©gation fenÃªtrÃ©e
.windowedBy(TimeWindows.ofSizeWithNoGrace(Duration.ofMinutes(1)))
.aggregate(/* ... */)

// Jointure stream-table
salesStream.join(productsTable, (saleJson, productJson) -> {
    // Enrichir la vente avec donnÃ©es produit
})
```

---

## ğŸ§ª Tests

### Tests Unitaires

```bash
mvn test
```

### Tests d'IntÃ©gration

```bash
# Tester avec Kafka embarquÃ©
mvn test -Dtest=**/*IntegrationTest
```

### Tests Manuels

```bash
# Envoyer plusieurs ventes
for i in {1..5}; do
  curl -X POST http://localhost:8080/api/v1/sales \
    -H "Content-Type: application/json" \
    -d "{\"productId\":\"PROD-001\",\"quantity\":1,\"unitPrice\":$((i * 50))}"
  sleep 1
done

# VÃ©rifier l'agrÃ©gation
curl http://localhost:8080/api/v1/stats/by-product
```

---

## ğŸ“Š Magasins d'Ã‰tat

L'application maintient deux magasins d'Ã©tat clÃ©s :

| Magasin | Type | AccÃ¨s | Description |
|---------|------|--------|-------------|
| `sales-by-product-store` | KeyValue | API REST | Totaux courants par produit |
| `sales-per-minute-store` | Windowed | Interne | AgrÃ©gations fenÃªtrÃ©es temporelles |

### Interroger les Magasins d'Ã‰tat

```bash
# Tous les produits
curl http://localhost:8080/api/v1/stores/sales-by-product-store/all

# Produit spÃ©cifique
curl http://localhost:8080/api/v1/stores/sales-by-product-store/PROD-001
```

---

## ğŸ” Monitoring

### VÃ©rification de SantÃ©

```bash
curl http://localhost:8080/actuator/health
```

La rÃ©ponse inclut l'Ã©tat des Streams :
```json
{
  "status": "UP",
  "streamsState": "RUNNING"
}
```

### MÃ©triques

Disponibles via `/actuator/prometheus` :
- `kafka_streams_state`
- `kafka_consumer_records_consumed_total`
- MÃ©triques personnalisÃ©es de l'application

---

## ğŸ› DÃ©pannage

| ProblÃ¨me | Cause | Solution |
|---------|-------|----------|
| Ã‰tat Streams = `REBALANCING` | RÃ©Ã©quilibrage groupe consommateur | Attendre la complÃ©tion |
| Pas de donnÃ©es dans magasin d'Ã©tat | Aucun Ã©vÃ©nement traitÃ© | Envoyer des Ã©vÃ©nements via POST /api/v1/sales |
| `SerializationException` | JSON invalide | VÃ©rifier format corps requÃªte |
| `TaskCorruptedException` | Corruption magasin d'Ã©tat | Supprimer rÃ©pertoire Ã©tat et redÃ©marrer |

---

## ğŸ“š Concepts Couverts

- **Topologie Kafka Streams** : KStream, KTable, agrÃ©gation
- **Traitement avec Ã‰tat** : Magasins d'Ã©tat matÃ©rialisÃ©s
- **FenÃªtrage** : FenÃªtres temporelles pour agrÃ©gations temporelles
- **Jointures Stream-Table** : Enrichissement avec donnÃ©es de rÃ©fÃ©rence
- **RequÃªtes Interactives** : AccÃ¨s REST aux magasins d'Ã©tat
- **Serdes** : SÃ©rialisation JSON personnalisÃ©e
- **Gestion d'Erreurs** : Topics dead-letter, tentatives

---

## ğŸ† RÃ©sumÃ©

Ce guide complet vous a accompagnÃ© Ã  travers :

1. **ğŸ› ï¸ Configuration Projet** - Comprendre la structure du code
2. **ğŸ”¨ Construction** - Compiler et packager l'application
3. **ğŸƒâ€â™‚ï¸ ExÃ©cution** - DÃ©veloppement local et dÃ©ploiement
4. **ğŸ§ª Tests** - ScÃ©narios complets de validation API
5. **ğŸ” VÃ©rification** - IntÃ©gration Kafka et traitement des streams
6. **ğŸ“Š Tests AvancÃ©s** - Tests de charge et gestion d'erreurs
7. **ğŸš€ DÃ©ploiement** - DÃ©ploiement production OpenShift
8. **ğŸ› DÃ©pannage** - ProblÃ¨mes courants et solutions
9. **âœ… Monitoring** - MÃ©triques et optimisation des performances

### ğŸ¯ Points ClÃ©s Ã  Retenir

- **Traitement de Streams** : AgrÃ©gation et filtrage en temps rÃ©el des Ã©vÃ©nements Kafka
- **Magasins d'Ã‰tat** : Ã‰tat consultable en mÃ©moire pour des rÃ©ponses API rapides
- **Microservices** : Services de traitement des ventes dÃ©couplÃ©s
- **Production PrÃªte** : Docker, OpenShift, et capacitÃ©s de monitoring
- **ModÃ¨les Entreprise** : Architecture Ã©vÃ©nementielle avec CQRS

Vous avez maintenant une application Kafka Streams Java entiÃ¨rement fonctionnelle qui dÃ©montre :
- âœ… Traitement de streams en temps rÃ©el
- âœ… AgrÃ©gations avec Ã©tat
- âœ… Exposition API REST
- âœ… DÃ©ploiement production
- âœ… Tests complets

**ğŸš€ PrÃªt pour le dÃ©ploiement en production et amÃ©liorations futures !**
