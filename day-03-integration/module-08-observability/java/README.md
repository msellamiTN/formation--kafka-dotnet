# LAB 3.4A (Java) : Kafka Metrics Dashboard - Observability

## ‚è±Ô∏è Estimated Duration: 60-90 minutes

## üè¶ E-Banking Context

In a production banking system, **observability is critical** for:

- ‚ùå **Cluster health monitoring** - Are all brokers running?
- ‚ùå **Consumer lag tracking** - Are consumers keeping up?
- ‚ùå **Topic metadata** - Partition distribution, replication factors
- ‚ùå **Performance metrics** - Throughput, latency, error rates
- ‚ùå **Alerting** - Proactive issue detection

This lab builds a **metrics dashboard** that exposes Kafka cluster health via REST APIs and Prometheus metrics.

---

## üìä Architecture

### Metrics Collection Pipeline

```mermaid
flowchart TB
    subgraph Kafka["üî• Kafka Cluster"]
        B1["üì¶ Broker 1"]
        B2["üì¶ Broker 2"]
        B3["üì¶ Broker 3"]
        T1["üìã Topics"]
        CG["üë• Consumer Groups"]
    end

    subgraph MetricsApp["üöÄ Metrics Dashboard (Java)"]
        ADMIN["AdminClient"]
        CTRL["MetricsController"]
        SVC["KafkaMetricsService"]
        PROM["Micrometer + Prometheus"]
    end

    subgraph Consumers["üì• Monitoring Systems"]
        GRAF["üìâ Grafana"]
        PROM_SRV["üìà Prometheus Server"]
        ALERT["‚ö†Ô∏è AlertManager"]
        API["üîç REST API Clients"]
    end

    ADMIN --> B1
    ADMIN --> B2
    ADMIN --> B3
    ADMIN --> T1
    ADMIN --> CG
    
    SVC --> ADMIN
    CTRL --> SVC
    PROM --> SVC
    
    PROM --> PROM_SRV
    PROM_SRV --> GRAF
    PROM_SRV --> ALERT
    CTRL --> API
```

---

## üèóÔ∏è Project Structure

```
java/
‚îú‚îÄ‚îÄ src/main/java/com/data2ai/kafka/metrics/
‚îÇ   ‚îú‚îÄ‚îÄ MetricsDashboardApplication.java   # Spring Boot main class
‚îÇ   ‚îú‚îÄ‚îÄ controller/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RootController.java              # Root endpoint
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MetricsController.java           # REST endpoints
‚îÇ   ‚îî‚îÄ‚îÄ service/
‚îÇ       ‚îî‚îÄ‚îÄ KafkaMetricsService.java          # AdminClient operations
‚îú‚îÄ‚îÄ src/main/resources/
‚îÇ   ‚îî‚îÄ‚îÄ application.properties               # Configuration
‚îî‚îÄ‚îÄ pom.xml                                 # Maven dependencies
```

---

## üöÄ Quick Start

### Prerequisites

- Java 17+
- Maven 3.6+
- Kafka cluster running
- OpenShift Sandbox (for deployment)

---

## üö¢ Deployment ‚Äî 4 Environments

| Environment | Tool | Kafka Bootstrap | API Access |
| ----------- | ---- | --------------- | ---------- |
| **üê≥ Docker / Local** | `mvn spring-boot:run` | `localhost:9092` | `http://localhost:8080/` |
| **‚òÅÔ∏è OpenShift Sandbox** | Scripts automated | `kafka-svc:9092` | `https://{route}/` |
| **‚ò∏Ô∏è K8s / OKD** | `docker build` + `kubectl apply` | `kafka-svc:9092` | `http://localhost:8080/` (port-forward) |
| **üñ•Ô∏è Local (IDE)** | VS Code / IntelliJ | `localhost:9092` | `http://localhost:8080/` |

### Local Development

```bash
# Build and run locally
mvn clean spring-boot:run

# Swagger UI
open http://localhost:8080/swagger-ui.html
```

### OpenShift Deployment

```bash
# Deploy using scripts (recommended)
cd ../../scripts
./bash/deploy-and-test-3.4a-java.sh --token "sha256~XXX" --server "https://api..."

# Or PowerShell
./powershell/deploy-and-test-3.4a-java.ps1 -Token "sha256~XXX" -Server "https://api..."
```

> **The script handles automatically:**
> - ‚úÖ Build with S2I (java:openjdk-17-ubi8)
> - ‚úÖ Deploy to OpenShift
> - ‚úÖ Configure environment variables
> - ‚úÖ Create secure edge route
> - ‚úÖ Wait for pod readiness
> - ‚úÖ Run API validation tests

---

## üß™ API Tests ‚Äî Validation Scenarios

### Health Check

```bash
# Local
curl http://localhost:8080/actuator/health

# OpenShift Sandbox
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/health
```

### Cluster Health Metrics

```bash
# Local
curl http://localhost:8080/api/v1/metrics/cluster

# OpenShift Sandbox
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/cluster
```

### Topic Metadata

```bash
# Local
curl http://localhost:8080/api/v1/metrics/topics

# OpenShift Sandbox
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/topics
```

### Consumer Lag Monitoring

```bash
# Local
curl http://localhost:8080/api/v1/metrics/consumers

# OpenShift Sandbox
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/api/v1/metrics/consumers
```

### Prometheus Metrics

```bash
# Local
curl http://localhost:8080/actuator/prometheus

# OpenShift Sandbox
curl -k https://ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com/actuator/prometheus
```

---

## üìä Monitoring Setup

### Prometheus Configuration

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka-metrics'
    static_configs:
      - targets: ['ebanking-metrics-java-secure.apps.sandbox.x8i5.p1.openshiftapps.com']
    metrics_path: '/actuator/prometheus'
    scrape_interval: 10s
```

### Grafana Dashboard

Import the pre-configured dashboard from `grafana/dashboard.json`:

```bash
# Import dashboard to Grafana
curl -X POST http://localhost:3000/api/dashboards/db \
  -H "Content-Type: application/json" \
  -d @grafana/dashboard.json \
  -u admin:admin
```

---

## üîç Verification

### Check Metrics Collection

```bash
# Verify metrics are being collected
curl -s http://localhost:8080/actuator/prometheus | grep kafka_consumer

# Check consumer lag
curl -s http://localhost:8080/api/v1/metrics/consumers | jq '.consumerGroups[0].lag'
```

### Validate JMX Connection

```bash
# Check if JMX metrics are accessible
curl -s http://localhost:8080/api/v1/metrics/cluster | jq '.status'
```

---

## üìã API Endpoints

| Method | Endpoint | Description | Response |
|--------|----------|-------------|----------|
| GET | `/` | Application info | JSON with endpoints |
| GET | `/actuator/health` | Health check | UP/DOWN status |
| GET | `/actuator/prometheus` | Prometheus metrics | Text format |
| GET | `/api/v1/metrics/cluster` | Cluster health | Brokers, controller |
| GET | `/api/v1/metrics/topics` | Topic metadata | List with details |
| GET | `/api/v1/metrics/consumers` | Consumer groups | Lag information |

---

## üîß Configuration

### application.properties

```properties
server.port=8080
spring.application.name=ebanking-metrics-dashboard

# Kafka
spring.kafka.bootstrap-servers=localhost:9092

# Actuator - expose all endpoints including prometheus
management.endpoints.web.exposure.include=health,info,prometheus,metrics
management.endpoint.health.show-details=always
management.metrics.export.prometheus.enabled=true
```

### Environment Variables (OpenShift)

| Variable | Default | Description |
|----------|---------|-------------|
| `SERVER_PORT` | 8080 | HTTP server port |
| `KAFKA_BOOTSTRAP_SERVERS` | localhost:9092 | Kafka brokers |

---

## üìä API Responses

### Cluster Health

```bash
curl /api/v1/metrics/cluster
```

Response:
```json
{
  "status": "HEALTHY",
  "clusterId": "kafka-cluster-id",
  "brokerCount": 3,
  "controllerId": 1,
  "brokers": [
    {
      "id": 1,
      "host": "kafka-0.kafka-svc",
      "port": 9092,
      "rack": "none"
    }
  ]
}
```

### Topics

```bash
curl /api/v1/metrics/topics
```

Response:
```json
{
  "count": 5,
  "topics": [
    {
      "name": "banking.transactions",
      "partitions": 3,
      "replicationFactor": 1,
      "internal": false
    }
  ]
}
```

### Consumer Groups

```bash
curl /api/v1/metrics/consumers
```

Response:
```json
{
  "count": 2,
  "groups": [
    {
      "groupId": "fraud-detection-service",
      "isSimple": false,
      "totalLag": 0,
      "partitions": [
        {
          "topic": "banking.transactions",
          "partition": 0,
          "committedOffset": 1234,
          "endOffset": 1234,
          "lag": 0
        }
      ]
    }
  ]
}
```

---

## üìà Prometheus Metrics

The application exposes metrics at `/actuator/prometheus`:

### Application Metrics

```
# Application health status
application_health_status 1.0

# API request counts
http_requests_total{method="GET",uri="/api/v1/metrics/cluster",status="200"} 42.0

# AdminClient operation duration
kafka_admin_operation_duration_seconds{operation="describeCluster",success="true"} 0.125
```

### JVM Metrics

```
# Memory usage
jvm_memory_used_bytes{area="heap"} 134217728.0

# GC metrics
jvm_gc_pause_seconds{action="end of major GC"} 0.025
```

### Custom Metrics

You can add custom metrics:

```java
@Component
public class CustomMetrics {
    private final Counter consumerLagCounter;
    
    public CustomMetrics(MeterRegistry meterRegistry) {
        this.consumerLagCounter = Counter.builder("kafka_consumer_lag_total")
            .description("Total consumer lag")
            .register(meterRegistry);
    }
    
    public void recordLag(long lag) {
        consumerLagCounter.increment(lag);
    }
}
```

---

## üîç Monitoring Setup

### Prometheus Configuration

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'kafka-metrics'
    static_configs:
      - targets: ['ebanking-metrics-java-secure.apps.mycluster.com:443']
    scheme: https
    tls_config:
      insecure_skip_verify: true
```

### Grafana Dashboard

Create a dashboard with panels for:

1. **Cluster Health**: Broker count, controller status
2. **Consumer Lag**: Total lag per consumer group
3. **Topic Metrics**: Partition count, replication factors
4. **API Performance**: Request rate, error rate, latency

### Alerting Rules

```yaml
# alerts.yml
groups:
  - name: kafka
    rules:
      - alert: KafkaBrokerDown
        expr: kafka_broker_count < 3
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Kafka broker is down"
      
      - alert: HighConsumerLag
        expr: kafka_consumer_lag_total > 1000
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High consumer lag detected"
```

---

## üß™ Testing

### Unit Tests

```bash
mvn test
```

### Integration Tests

```bash
# Test with Testcontainers
mvn test -Dtest=**/*IntegrationTest
```

### Manual Testing

```bash
# Test all endpoints
for endpoint in cluster topics consumers; do
  echo "Testing /api/v1/metrics/$endpoint"
  curl -s "http://localhost:8080/api/v1/metrics/$endpoint" | jq .
done

# Test Prometheus format
curl -s http://localhost:8080/actuator/prometheus | head -20
```

---

## üîß AdminClient Operations

The `KafkaMetricsService` uses `AdminClient` for:

### Cluster Information

```java
DescribeClusterResult cluster = adminClient.describeCluster();
Collection<Node> nodes = cluster.nodes().get();
Node controller = cluster.controller().get();
String clusterId = cluster.clusterId().get();
```

### Topic Metadata

```java
Set<String> topicNames = adminClient.listTopics().names().get();
Map<String, TopicDescription> descriptions = 
    adminClient.describeTopics(topicNames).allTopicNames().get();
```

### Consumer Group Lag

```java
ListConsumerGroupsResult groups = adminClient.listConsumerGroups();
for (ConsumerGroupListing group : groups.all().get()) {
    Map<TopicPartition, OffsetAndMetadata> offsets = 
        adminClient.listConsumerGroupOffsets(group.groupId())
            .partitionsToOffsetAndMetadata().get();
    
    // Calculate lag by comparing with end offsets
}
```

---

## üêõ Troubleshooting

| Issue | Cause | Solution |
|-------|-------|----------|
| `TimeoutException` | Kafka broker unreachable | Check `KAFKA_BOOTSTRAP_SERVERS` |
| `AuthenticationException` | SASL/SSL misconfiguration | Verify security settings |
| Empty consumer groups | No active consumers | Check consumer applications |
| `AuthorizationException` | Insufficient permissions | Grant required ACLs |
| High AdminClient latency | Network issues or broker load | Increase timeouts |

---

## üìö Concepts Covered

- **AdminClient**: Kafka cluster management
- **Micrometer**: Metrics collection framework
- **Prometheus**: Metrics exposition and monitoring
- **Consumer Lag**: Offset tracking and calculation
- **REST APIs**: Exposing metrics via HTTP
- **Health Checks**: Application and cluster health
- **Observability**: The three pillars (logs, metrics, traces)
