# LAB 1.2A : Producer Synchrone Basique

## ‚è±Ô∏è Dur√©e estim√©e : 30 minutes

## üéØ Objectif

Cr√©er une application console .NET qui envoie des messages simples (string) √† Kafka avec gestion d'erreurs de base.

### Architecture du Lab

```mermaid
flowchart LR
    subgraph Producer["üì¶ .NET Producer"]
        A["Program.cs"] --> B["ProducerBuilder"]
        B --> C["ProduceAsync"]
    end
    
    subgraph Kafka["üî• Kafka Cluster"]
        D["Topic: orders.created"]
        E["Partition 0..5"]
    end
    
    C -->|Envoi message| D
    D -->|Distribution| E
    
    style Producer fill:#e1f5fe,stroke:#01579b
    style Kafka fill:#fff3e0,stroke:#e65100
```

Ce diagramme illustre le flux de donn√©es : votre application .NET cr√©e un producer, qui envoie des messages au topic Kafka qui les distribue sur ses partitions.

## üìö Ce que vous allez apprendre

- Configuration minimale d'un Producer Kafka
- Envoi de messages avec `ProduceAsync()`
- Gestion des `DeliveryResult` (partition, offset, timestamp)
- Error handlers et log handlers
- Importance du `Flush()` avant fermeture du producer
- Utilisation des headers pour m√©tadonn√©es

---

## üõ†Ô∏è Quick Start (5 minutes)

Pour une ex√©cution rapide sans lire tout le lab :

```bash
# 1. Cr√©er et configurer
cd lab-1.2a-producer-basic
dotnet new console -n KafkaProducerBasic
cd KafkaProducerBasic
dotnet add package Confluent.Kafka --version 2.3.0
```

**Commandes** :

```bash
# Naviguer vers le dossier du lab
cd lab-1.2a-producer-basic

# Cr√©er le projet console
dotnet new console -n KafkaProducerBasic

# Naviguer dans le projet
cd KafkaProducerBasic

# Ajouter le package Confluent.Kafka
dotnet add package Confluent.Kafka --version 2.3.0

# Ajouter les packages de logging
dotnet add package Microsoft.Extensions.Logging --version 8.0.0
dotnet add package Microsoft.Extensions.Logging.Console --version 8.0.0
```

---

## ÔøΩ Pr√©requis

### Cluster Kafka en fonctionnement

**Docker** :

```bash
cd ../../module-01-cluster
./scripts/up.sh
# V√©rifier : docker ps (kafka et kafka-ui doivent √™tre healthy)
```

**OKD/K3s** :

```bash
kubectl get kafka -n kafka
# Attendu : bhf-kafka avec status Ready
```

### Cr√©er le topic

**Docker** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic orders.created \
  --partitions 6 \
  --replication-factor 1
```

**OKD/K3s** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --create --if-not-exists --topic orders.created --partitions 6 --replication-factor 3
```

---

## üöÄ Instructions Pas √† Pas

### √âtape 1 : Cr√©er le projet

#### üíª Option A : Visual Studio Code (Recommand√© pour d√©butants)

Visual Studio Code est un √©diteur l√©ger, gratuit et multiplateforme. Id√©al pour les labs Kafka.

**Pr√©requis** :

- [Visual Studio Code](https://code.visualstudio.com/download) install√©
- [.NET 8.0 SDK](https://dotnet.microsoft.com/download/dotnet/8.0) install√©
- Extension C# Dev Kit (optionnel mais recommand√©)

```mermaid
flowchart TD
    A["üíª Visual Studio Code"] --> B["üìÅ Ouvrir le dossier lab-1.2a-producer-basic"]
    B --> C["‚ö° Terminal: dotnet new console -n KafkaProducerBasic"]
    C --> D["üì¶ dotnet add package Confluent.Kafka"]
    D --> E["‚ñ∂Ô∏è dotnet run"]
    
    style A fill:#007acc,color:#fff
    style E fill:#4caf50,color:#fff
```

**Commandes** :

```bash
# Naviguer vers le dossier du lab
cd lab-1.2a-producer-basic

# Cr√©er le projet console
dotnet new console -n KafkaProducerBasic

# Naviguer dans le projet
cd KafkaProducerBasic

# Ajouter le package Confluent.Kafka
dotnet add package Confluent.Kafka --version 2.3.0

# Ajouter les packages de logging
dotnet add package Microsoft.Extensions.Logging --version 8.0.0
dotnet add package Microsoft.Extensions.Logging.Console --version 8.0.0
```

**Dans VS Code** :
1. `Ctrl+J` pour ouvrir le terminal int√©gr√©
2. `F5` pour d√©boguer ou `Ctrl+F5` pour ex√©cuter sans d√©bogage
3. `Ctrl+Shift+P` ‚Üí ".NET: Generate Assets for Build and Debug" (pour cr√©er launch.json)

---

#### üé® Option B : Visual Studio 2022 (IDE complet)

Visual Studio 2022 offre une exp√©rience IDE compl√®te avec IntelliSense avanc√©, d√©bogage graphique et designers visuels.

**Pr√©requis** :
- [Visual Studio 2022](https://visualstudio.microsoft.com/vs/) install√©
- Workload **"D√©veloppement .NET Desktop"** s√©lectionn√© lors de l'installation

```mermaid
flowchart TD
    A["üé® Visual Studio 2022"] --> B["üìÅ Fichier ‚Üí Nouveau ‚Üí Projet"]
    B --> C["üìã S√©lectionner 'Application console'"]
    C --> D["‚öôÔ∏è Framework: .NET 8.0"]
    D --> E["üì¶ G√©rer les packages NuGet"]
    E --> F["‚ñ∂Ô∏è F5 pour ex√©cuter"]
    
    style A fill:#5c2d91,color:#fff
    style F fill:#4caf50,color:#fff
```

**Instructions d√©taill√©es** :

1.  **Fichier** ‚Üí **Nouveau** ‚Üí **Projet** (`Ctrl+Shift+N`)

2.  S√©lectionner **Application console** (pas "Application console (.NET Framework)")

    ```
    Mod√®les > C# > Application console
    ```

3.  Configuration du projet :

    | Param√®tre | Valeur |
    |-----------|--------|
    | Nom du projet | `KafkaProducerBasic` |
    | Emplacement | `lab-1.2a-producer-basic` |
    | Framework | **.NET 8.0** |

4.  Ajouter les packages NuGet :

    - Clic droit sur le projet ‚Üí **G√©rer les packages NuGet**
    - Onglet **Parcourir**, rechercher et installer :
      - ‚úÖ `Confluent.Kafka` version **2.3.0**
      - ‚úÖ `Microsoft.Extensions.Logging` version **8.0.0**
      - ‚úÖ `Microsoft.Extensions.Logging.Console` version **8.0.0**

5.  Ex√©cuter le projet :

    - **F5** : Ex√©cuter avec d√©bogage (breakpoints, inspection variables)
    - **Ctrl+F5** : Ex√©cuter sans d√©bogage (plus rapide)

---

#### üìä Comparaison VS Code vs Visual Studio

| Crit√®re | VS Code | Visual Studio 2022 |
|---------|---------|---------------------|
| **Poids** | L√©ger (~300MB) | Lourd (~2-3GB) |
| **Prix** | Gratuit | Gratuit (Community) |
| **D√©bogage** | Basique | Avanc√© (points d'arr√™t conditionnels, visualization) |
| **IntelliSense** | Bon | Excellent |
| **Id√©al pour** | Labs, scripts | Projets complexes, √©quipes |
| **Multiplateforme** | ‚úÖ Windows/Mac/Linux | ‚ö†Ô∏è Windows uniquement |

---

### √âtape 2 : Copier le code

Remplacez le contenu de `Program.cs` par le code fourni dans ce dossier.

**Fichiers fournis** :
- ‚úÖ `Program.cs` - Code principal du producer
- ‚úÖ `KafkaProducerBasic.csproj` - Configuration du projet
- ‚úÖ `appsettings.json` - Configuration (optionnel)

---

### √âtape 3 : Comprendre le code

#### üéØ Concepts Fondamentaux du Producer

##### 3.1 Architecture du Producer

```mermaid
flowchart TB
    subgraph Producer["üì§ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["bootstrap.servers<br/>localhost:9092"]
            AC["acks<br/>all"]
            RE["retries<br/>3"]
            RT["request.timeout.ms<br/>30000"]
        end
        
        subgraph Pipeline["Pipeline d'envoi"]
            SER["üîÑ Serializer<br/>Key + Value"]
            ACC["üì¶ RecordAccumulator<br/>Batching"]
            SND["üåê Sender Thread<br/>Network I/O"]
        end
        
        SER --> ACC --> SND
    end
    
    SND -->|"ProduceRequest"| K["üì¶ Kafka Broker"]
    K -->|"ACK"| SND
    
    style Config fill:#e3f2fd
    style Pipeline fill:#f3e5f5
```

##### 3.2 Niveaux de Confirmation (ACK Levels)

```mermaid
flowchart TB
    subgraph acks0["acks=0 (Fire & Forget)"]
        P0["Producer"] -->|"Envoie"| B0["Broker"]
        P0 -.->|"N'attend pas"| X0["‚ùå"]
        Note0["‚ö° Latence minimale<br/>‚ùå Aucune garantie"]
    end
    
    subgraph acks1["acks=1 (Leader Only)"]
        P1["Producer"] -->|"Envoie"| L1["Leader"]
        L1 -->|"ACK"| P1
        L1 -.->|"R√©plique apr√®s"| F1["Follower"]
        Note1["‚ö° Latence faible<br/>‚ö†Ô∏è Fiabilit√© moyenne"]
    end
    
    subgraph acksAll["acks=all (Toutes les ISR)"]
        P2["Producer"] -->|"Envoie"| L2["Leader"]
        L2 -->|"R√©plique"| F2["Follower 1"]
        L2 -->|"R√©plique"| F3["Follower 2"]
        F2 -->|"ACK"| L2
        F3 -->|"ACK"| L2
        L2 -->|"ACK"| P2
        Note2["üê• Latence √©lev√©e<br/>‚úÖ Fiabilit√© maximale"]
    end
    
    style acks0 fill:#ffebee
    style acks1 fill:#fff3e0
    style acksAll fill:#e8f5e8
```

**Dans notre code** : `Acks = Acks.All` pour une fiabilit√© maximale.

##### 3.3 Idempotence : Garantie d'Exact-Once

```mermaid
sequenceDiagram
    participant P as Producer
    participant K as Kafka Broker
    participant R as Replica
    
    Note over P: Envoi Message (PID:123, Seq:1)
    P->>K: Envoi Message (PID:123, Seq:1)
    K->>R: Replication
    R-->>K: ACK
    
    Note over P: Timeout ! R√©essai
    P->>K: Envoi Message (PID:123, Seq:1)
    K->>K: D√©tection duplicata
    K-->>P: ACK (sans duplication)
    
    Note over K: ‚úÖ 1 seul message
```

**Configuration pour idempotence** (non activ√©e dans ce lab) :
```csharp
EnableIdempotence = true,  // Active d√©duplication automatique
Acks = Acks.All,           // Requis pour idempotence
MaxInFlight = 5             // Max 5 requ√™tes simultan√©es
```

##### 3.4 Cycle de vie d'un message

```mermaid
sequenceDiagram
    participant App as Application
    participant Prod as Producer
    participant Ser as Serializer
    participant Batch as RecordAccumulator
    participant Net as NetworkClient
    participant Broker as Kafka Broker
    
    App->>Prod: send(record)
    Prod->>Ser: serialize(key, value)
    Ser-->>Prod: byte[]
    Prod->>Batch: append to batch
    Note over Batch: Attend linger.ms ou batch.size
    Batch->>Net: send batch
    Net->>Broker: ProduceRequest
    Broker->>Broker: Write to log
    Broker-->>Net: ProduceResponse (offset)
    Net-->>Prod: RecordMetadata
    Prod-->>App: Future/Callback
```

#### Configuration du Producer

```csharp
var config = new ProducerConfig
{
    // Adresse du cluster Kafka
    BootstrapServers = "localhost:9092",  // Docker
    // BootstrapServers = "bhf-kafka-kafka-bootstrap:9092",  // OKD/K3s
    
    // Identification du client (pour logs et monitoring)
    ClientId = "dotnet-basic-producer",
    
    // Garantie de livraison : attendre confirmation de tous les ISR
    Acks = Acks.All,
    
    // Retry automatique en cas d'erreur retriable
    MessageSendMaxRetries = 3,
    RetryBackoffMs = 1000,
    RequestTimeoutMs = 30000
};
```

**Points cl√©s** :
- `BootstrapServers` : Adresse du cluster (adapter selon votre environnement)
- `Acks.All` : Garantie maximale (tous les r√©plicas synchronis√©s)
- Retry automatique pour erreurs transientes

#### Cr√©ation du Producer avec Handlers

```csharp
using var producer = new ProducerBuilder<Null, string>(config)
    .SetErrorHandler((_, e) => 
    {
        // Gestion des erreurs fatales et non-fatales
        logger.LogError("Producer error: Code={Code}, Reason={Reason}", 
            e.Code, e.Reason);
        if (e.IsFatal)
        {
            Environment.Exit(1);  // Arr√™t si erreur fatale
        }
    })
    .SetLogHandler((_, logMessage) => 
    {
        // Logs internes de Kafka
        logger.Log(logLevel, "Kafka internal log: {Message}", logMessage.Message);
    })
    .Build();
```

**Points cl√©s** :
- `<Null, string>` : Type de la cl√© (Null = pas de cl√©) et valeur (string)
- `SetErrorHandler` : Callback pour erreurs
- `SetLogHandler` : Logs internes de librdkafka

#### Envoi de Messages

```mermaid
sequenceDiagram
    participant App as Application .NET
    participant Producer as Kafka Producer
    participant Buffer as Buffer M√©moire
    participant Broker as Kafka Broker
    participant Topic as Topic orders.created

    App->>Producer: ProduceAsync(message)
    Producer->>Buffer: Queue message
    Producer-->>App: Task (async)
    
    Note over Buffer: Batch & Linger.ms
    
    Buffer->>Broker: Send batch
    Broker->>Topic: Write to partition
    Broker-->>Buffer: Ack (partition, offset)
    Buffer-->>App: DeliveryResult
    
    App->>App: Log Partition + Offset
```

Ce diagramme montre le flux asynchrone : l'application envoie un message, il est mis en buffer, envoy√© au broker, et la confirmation arrive avec les m√©tadonn√©es (partition, offset).

```csharp
var deliveryResult = await producer.ProduceAsync(topicName, new Message<Null, string>
{
    Value = messageValue,
    Headers = new Headers
    {
        { "correlation-id", Encoding.UTF8.GetBytes(Guid.NewGuid().ToString()) },
        { "source", Encoding.UTF8.GetBytes("dotnet-producer") }
    }
});

// Confirmation de livraison
logger.LogInformation(
    "‚úì Message delivered ‚Üí Partition: {Partition}, Offset: {Offset}",
    deliveryResult.Partition.Value,
    deliveryResult.Offset.Value
);
```

**Points cl√©s** :
- `ProduceAsync` : Envoi asynchrone (non-bloquant)
- `DeliveryResult` : Confirmation avec partition, offset, timestamp
- `Headers` : M√©tadonn√©es optionnelles (correlation ID, tracing)

#### Fermeture Propre

```csharp
finally
{
    // IMPORTANT : Flush des messages en attente
    producer.Flush(TimeSpan.FromSeconds(10));
    logger.LogInformation("Producer closed gracefully.");
}
```

**Points cl√©s** :
- `Flush()` : Envoie tous les messages en buffer avant fermeture
- Timeout de 10 secondes pour √©viter blocage infini

---

### √âtape 4 : Configurer l'environnement

#### Docker (localhost)

Modifier `Program.cs` ligne 11 :

```csharp
BootstrapServers = "localhost:9092"
```

#### OKD/K3s

Modifier `Program.cs` ligne 11 :

```csharp
BootstrapServers = "bhf-kafka-kafka-bootstrap:9092"
```

Ou utiliser une variable d'environnement :

```csharp
BootstrapServers = Environment.GetEnvironmentVariable("KAFKA_BOOTSTRAP_SERVERS") 
                   ?? "localhost:9092"
```

---

### √âtape 5 : Ex√©cuter le producer

#### Avec Visual Studio Code

```bash
dotnet run
```

#### Avec Visual Studio 2022

1.  Appuyer sur **F5** (ou **Ctrl+F5** sans debugger)
2.  Observer les logs dans la console

---

### √âtape 6 : Observer les r√©sultats

#### Logs attendus

```
info: Program[0]
      Producer started. Connecting to localhost:9092
info: Program[0]
      Sending message 1: {"orderId": "ORD-0001", "timestamp": "2026-02-05T11:30:00Z", "amount": 110}
info: Program[0]
      ‚úì Message 1 delivered ‚Üí Topic: orders.created, Partition: 3, Offset: 0, Timestamp: 2026-02-05 11:30:00
info: Program[0]
      Sending message 2: {"orderId": "ORD-0002", "timestamp": "2026-02-05T11:30:01Z", "amount": 120}
info: Program[0]
      ‚úì Message 2 delivered ‚Üí Topic: orders.created, Partition: 1, Offset: 0, Timestamp: 2026-02-05 11:30:01
...
info: Program[0]
      All messages sent successfully!
info: Program[0]
      Flushing pending messages...
info: Program[0]
      Producer closed gracefully.
```

**Points √† noter** :
- ‚úÖ Messages r√©partis sur les 6 partitions (round-robin car pas de cl√©)
- ‚úÖ Offset commence √† 0 pour chaque partition (si topic vide)
- ‚úÖ Pas d'erreurs de connexion
- ‚úÖ Latence d'envoi : ~5-10ms par message

---

### √âtape 7 : V√©rifier dans Kafka

#### Avec Kafka UI

**Docker** : http://localhost:8080  
**OKD/K3s** : http://<NODE_IP>:30808

1. Aller dans **Topics** ‚Üí **orders.created**
2. Cliquer sur **Messages**
3. Vous devez voir les 10 messages produits

#### Avec CLI Kafka

**Docker** :

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic orders.created \
  --from-beginning \
  --max-messages 10
```

**OKD/K3s** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-console-consumer.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic orders.created --from-beginning --max-messages 10
```

**R√©sultat attendu** :

```json
{"orderId": "ORD-0001", "timestamp": "2026-02-05T11:30:00Z", "amount": 110}
{"orderId": "ORD-0002", "timestamp": "2026-02-05T11:30:01Z", "amount": 120}
...
```

---

## üß™ Exercices Pratiques

### Exercice 1 : Modifier le nombre de messages

**Objectif** : Envoyer 50 messages au lieu de 10.

**Instructions** :

1.  Modifier la ligne `for (int i = 1; i <= 10; i++)` ‚Üí `for (int i = 1; i <= 50; i++)`
2.  Relancer le producer
3.  Observer la distribution sur les partitions

**Question** : Combien de messages par partition en moyenne ?

<details>
<summary>üí° Solution</summary>

Avec 50 messages et 6 partitions, distribution attendue : ~8-9 messages par partition (peut varier l√©g√®rement avec sticky partitioner).

</details>

---

### Exercice 2 : Ajouter un header personnalis√©

**Objectif** : Ajouter un header `environment` avec la valeur `dev`.

**Instructions** :

1.  Ajouter dans les headers :

    ```csharp
    { "environment", Encoding.UTF8.GetBytes("dev") }
    ```

2.  Relancer et v√©rifier dans Kafka UI (onglet Headers)

---

### Exercice 3 : Tester la gestion d'erreurs

**Objectif** : Observer le comportement en cas d'erreur de connexion.

**Instructions** :

1.  Arr√™ter Kafka : `docker stop kafka` (Docker) ou `kubectl scale kafka bhf-kafka --replicas=0 -n kafka` (K8s)
2.  Relancer le producer
3.  Observer les logs d'erreur et les retries

**Question** : Combien de retries avant √©chec final ?

<details>
<summary>üí° Solution</summary>

Le producer tentera 3 retries (configur√© via `MessageSendMaxRetries = 3`) avec 1 seconde entre chaque (`RetryBackoffMs = 1000`).

</details>

4.  Red√©marrer Kafka : `docker start kafka` ou `kubectl scale kafka bhf-kafka --replicas=3 -n kafka`

---

### Exercice 4 : Activer l'Idempotence (Avanc√©)

**Objectif** : Activer l'idempotence pour garantir exactly-once semantics.

**Instructions** :

1.  Modifier la configuration pour activer l'idempotence :

    ```csharp
    var config = new ProducerConfig
    {
        BootstrapServers = Environment.GetEnvironmentVariable("KAFKA_BOOTSTRAP_SERVERS") 
                           ?? "localhost:9092",
        ClientId = "dotnet-idempotent-producer",
        Acks = Acks.All,
        
        // üîë Activation de l'idempotence
        EnableIdempotence = true,
        MaxInFlight = 5,  // Requis pour idempotence
        
        MessageSendMaxRetries = 3,
        RetryBackoffMs = 1000,
        RequestTimeoutMs = 30000
    };
    ```

2.  Envoyer le m√™me message deux fois avec le m√™me cl√© :

    ```csharp
    for (int i = 1; i <= 2; i++)
    {
        var messageValue = $"{{\"orderId\": \"ORD-123\", \"attempt\": {i}}}";
        var deliveryResult = await producer.ProduceAsync(topicName, new Message<string, string>
        {
            Key = "customer-123",  // M√™me cl√©
            Value = messageValue
        });
        
        logger.LogInformation("Attempt {Index}: Partition {Partition}, Offset {Offset}", 
            i, deliveryResult.Partition.Value, deliveryResult.Offset.Value);
    }
    ```

3.  Observer que seul le premier message est √©crit (le second est d√©tect√© comme duplicata).

<details>
<summary>üí° Explication</summary>

Avec l'idempotence activ√©e, Kafka utilise un PID (Producer ID) et des num√©ros de s√©quence pour d√©tecter les doublons. Le second envoi avec le m√™me PID et num√©ro de s√©quence est ignor√©.

</details>

---

### Exercice 5 : Optimisation Performance (Production-Ready)

**Objectif** : Optimiser le producer pour haute performance.

**Instructions** :

1.  Ajouter les param√®tres de performance :

    ```csharp
    var config = new ProducerConfig
    {
        BootstrapServers = Environment.GetEnvironmentVariable("KAFKA_BOOTSTRAP_SERVERS") 
                           ?? "localhost:9092",
        ClientId = "dotnet-optimized-producer",
        Acks = Acks.All,
        
        // üöÄ Optimisations performance
        BatchSize = 32768,              // 32KB batch size
        LingerMs = 5,                     // Attendre 5ms pour batcher
        CompressionType = CompressionType.Snappy,  // Compression
        
        MessageSendMaxRetries = 3,
        RetryBackoffMs = 1000,
        RequestTimeoutMs = 30000
    };
    ```

2.  Envoyer 1000 messages et mesurer le temps total :

    ```csharp
    var stopwatch = System.Diagnostics.Stopwatch.StartNew();

    for (int i = 1; i <= 1000; i++)
    {
        var messageValue = $"{{\"orderId\": \"ORD-{i:D4}\", \"timestamp\": \"{DateTime.UtcNow:o}\"}}";
        await producer.ProduceAsync(topicName, new Message<Null, string>
        {
            Value = messageValue
        });
    }

    stopwatch.Stop();
    logger.LogInformation("Sent 1000 messages in {ElapsedMs}ms", stopwatch.ElapsedMilliseconds);
    logger.LogInformation("Throughput: {Throughput:F2} messages/sec", 1000.0 / stopwatch.Elapsed.TotalSeconds);
    ```

3.  Comparer avec la version non optimis√©e.

<details>
<summary>üí° R√©sultats attendus</summary>

Avec optimisation :
- **Batch size 32KB** : Groupement plus efficace
- **Linger 5ms** : Meilleur batching sans trop de latence  
- **Compression Snappy** : R√©duction bande passante
- **Expected** : 2-5x plus rapide que la version basique

</details>

---

### Exercice 6 : Circuit Breaker Pattern (Expert)

**Objectif** : Impl√©menter un circuit breaker pour √©viter les cascades d'√©checs.

**Instructions** :

1.  Ajouter une classe CircuitBreaker :

    ```csharp
    public class CircuitBreakerProducer
    {
        private int _failureCount = 0;
        private DateTime _lastFailure = DateTime.MinValue;
        private readonly int _threshold = 5;
        private readonly TimeSpan _timeout = TimeSpan.FromMinutes(1);
        
        public async Task<DeliveryResult<Null, string>> SendAsync(
            IProducer<Null, string> producer, 
            string topic,
            Message<Null, string> message)
        {
            if (IsCircuitOpen())
                throw new InvalidOperationException("Circuit breaker is open");
                
            try
            {
                var result = await producer.ProduceAsync(topic, message);
                ResetCircuit();
                return result;
            }
            catch (Exception ex)
            {
                RecordFailure();
                throw;
            }
        }
        
        private bool IsCircuitOpen() => 
            _failureCount >= _threshold && 
            DateTime.UtcNow - _lastFailure < _timeout;
            
        private void RecordFailure()
        {
            _failureCount++;
            _lastFailure = DateTime.UtcNow;
        }
        
        private void ResetCircuit() => _failureCount = 0;
    }
    ```

2.  Utiliser le circuit breaker dans le producer principal.

<details>
<summary>üí° Pattern avanc√©</summary>

Le circuit breaker prot√®ge contre les pannes en cascade :
- **5 √©checs cons√©cutifs** ‚Üí Circuit ouvert
- **1 minute** ‚Üí Tentative de r√©tablissement
- **Succ√®s** ‚Üí Circuit ferm√© imm√©diatement

Id√©al pour les environnements de production o√π Kafka peut √™tre temporairement indisponible.

</details>

---

## üîß Troubleshooting

### Probl√®mes courants

| Sympt√¥me | Cause probable | Solution |
|----------|---------------|----------|
| ‚ùå `Kafka Error: Local: Broker transport failure` | Kafka non d√©marr√© | `cd ../../module-01-cluster && ./scripts/up.sh` |
| ‚ùå `UnknownTopicOrPartitionException` | Topic non cr√©√© | Cr√©er le topic `orders.created` (voir √âtape 1) |
| ‚ùå Timeout apr√®s 30 secondes | Mauvais `BootstrapServers` | V√©rifier Docker vs OKD configuration |
| ‚ùå `No such file or directory` | Mauvais dossier de travail | `cd lab-1.2a-producer-basic/KafkaProducerBasic` |

### Commandes de diagnostic

```bash
# V√©rifier Kafka (Docker)
docker ps | grep kafka

# V√©rifier le topic
docker exec kafka /opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list

# Tester connectivit√©
docker exec kafka /opt/kafka/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test
```

---

## üìä Performance Comparison

| Configuration | Latence | Throughput | Use Case |
|---------------|---------|------------|----------|
| **Default** | 5-10ms | ~100 msg/s | D√©veloppement, debugging |
| **Optimized** | 2-5ms | ~500 msg/s | Production, haute performance |
| **Batch Mode** | 10-50ms | ~2000 msg/s | Bulk processing |

---

## ‚úÖ Validation du Lab

Vous avez r√©ussi ce lab si :

- [ ] **‚úÖ Connexion r√©ussie** : Le producer se connecte √† Kafka sans erreur
- [ ] **‚úÖ Messages envoy√©s** : Les 10 messages sont envoy√©s avec succ√®s
- [ ] **‚úÖ Visibilit√©** : Les messages sont visibles dans Kafka UI ou via CLI
- [ ] **‚úÖ M√©tadonn√©es** : Les logs affichent partition et offset pour chaque message
- [ ] **‚úÖ Fermeture propre** : Le producer se ferme avec `Flush()`
- [ ] **‚úÖ Compr√©hension** : Vous comprenez le r√¥le de `Acks`, `ProduceAsync`, et `DeliveryResult`
- [ ] **üöÄ Bonus** : Vous avez test√© les exercices de performance

### üéØ Points Cl√©s √† Retenir

1.  **ProduceAsync est non-bloquant** : Le message est mis en buffer et envoy√© de mani√®re asynchrone
2.  **Flush() est obligatoire** : Avant fermeture pour √©viter perte de messages en attente
3.  **DeliveryResult contient les m√©tadonn√©es** : Partition, offset, timestamp de livraison
4.  **Acks.All garantit durabilit√©** : Tous les r√©plicas synchronis√©s avant confirmation
5.  **Retry automatique** : Kafka g√®re les erreurs transientes automatiquement
6.  **Headers pour m√©tadonn√©es** : Correlation ID, tracing, source, etc.

---

## üìñ Concepts Th√©oriques

### Sticky Partitioner (Kafka 2.4+)

Sans cl√©, Kafka utilise le **sticky partitioner** au lieu du round-robin classique :
- Messages group√©s par batch sur la m√™me partition
- Meilleure performance (moins de requ√™tes r√©seau)
- Distribution reste √©quilibr√©e sur le long terme

### Acks : Garanties de Livraison

| Acks | Garantie | Latence | Cas d'usage |
|------|----------|---------|-------------|
| `None (0)` | Aucune | Tr√®s faible | M√©triques, logs non-critiques |
| `Leader (1)` | Leader uniquement | Faible | Logs applicatifs |
| `All (-1)` | Tous les ISR | Plus √©lev√©e | Transactions, commandes |

**ISR** (In-Sync Replicas) : R√©plicas synchronis√©s avec le leader.

---

## üöÄ Prochaine √âtape

Vous ma√Ætrisez maintenant les bases du Producer Kafka !

üëâ **Passez au [LAB 1.2B : Producer avec Cl√©](../lab-1.2b-producer-keyed/README.md)**

Dans le prochain lab, vous apprendrez :
- Comment utiliser une cl√© pour contr√¥ler le partitionnement
- Garantir l'ordre des messages pour une m√™me entit√©
- √âviter les hot partitions
