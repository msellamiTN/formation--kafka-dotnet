# LAB 1.2A : Producer Synchrone Basique

## ‚è±Ô∏è Dur√©e estim√©e : 30 minutes

## üéØ Objectif

Cr√©er une application console .NET qui envoie des messages simples (string) √† Kafka avec gestion d'erreurs de base.

### Architecture du Lab

```mermaid
flowchart LR
    subgraph Producer["üì¶ .NET Producer"]
        A["Program.cs"] --> B["ProducerBuilder"]
        B --> C["ProduceAsync"]
    end
    
    subgraph Kafka["üî• Kafka Cluster"]
        D["Topic: orders.created"]
        E["Partition 0..5"]
    end
    
    C -->|Envoi message| D
    D -->|Distribution| E
    
    style Producer fill:#e1f5fe,stroke:#01579b
    style Kafka fill:#fff3e0,stroke:#e65100
```

Ce diagramme illustre le flux de donn√©es : votre application .NET cr√©e un producer, qui envoie des messages au topic Kafka qui les distribue sur ses partitions.

## üìö Ce que vous allez apprendre

- Configuration minimale d'un Producer Kafka
- Envoi de messages avec `ProduceAsync()`
- Gestion des `DeliveryResult` (partition, offset, timestamp)
- Error handlers et log handlers
- Importance du `Flush()` avant fermeture du producer
- Utilisation des headers pour m√©tadonn√©es

---

## üìã Pr√©requis

### Cluster Kafka en fonctionnement

**Docker** :
```bash
cd ../../module-01-cluster
./scripts/up.sh
# V√©rifier : docker ps (kafka et kafka-ui doivent √™tre healthy)
```

**OKD/K3s** :
```bash
kubectl get kafka -n kafka
# Attendu : bhf-kafka avec status Ready
```

### Cr√©er le topic

**Docker** :
```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic orders.created \
  --partitions 6 \
  --replication-factor 1
```

**OKD/K3s** :
```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --create --if-not-exists --topic orders.created --partitions 6 --replication-factor 3
```

---

## üöÄ Instructions Pas √† Pas

### √âtape 1 : Cr√©er le projet

#### üíª Option A : Visual Studio Code (Recommand√© pour d√©butants)

Visual Studio Code est un √©diteur l√©ger, gratuit et multiplateforme. Id√©al pour les labs Kafka.

**Pr√©requis** :
- [Visual Studio Code](https://code.visualstudio.com/download) install√©
- [.NET 8.0 SDK](https://dotnet.microsoft.com/download/dotnet/8.0) install√©
- Extension C# Dev Kit (optionnel mais recommand√©)

```mermaid
flowchart TD
    A["üíª Visual Studio Code"] --> B["üìÅ Ouvrir le dossier lab-1.2a-producer-basic"]
    B --> C["‚ö° Terminal: dotnet new console -n KafkaProducerBasic"]
    C --> D["üì¶ dotnet add package Confluent.Kafka"]
    D --> E["‚ñ∂Ô∏è dotnet run"]
    
    style A fill:#007acc,color:#fff
    style E fill:#4caf50,color:#fff
```

**Commandes** :
```bash
# Naviguer vers le dossier du lab
cd lab-1.2a-producer-basic

# Cr√©er le projet console
dotnet new console -n KafkaProducerBasic

# Naviguer dans le projet
cd KafkaProducerBasic

# Ajouter le package Confluent.Kafka
dotnet add package Confluent.Kafka --version 2.3.0

# Ajouter les packages de logging
dotnet add package Microsoft.Extensions.Logging --version 8.0.0
dotnet add package Microsoft.Extensions.Logging.Console --version 8.0.0
```

**Dans VS Code** :
1. `Ctrl+J` pour ouvrir le terminal int√©gr√©
2. `F5` pour d√©boguer ou `Ctrl+F5` pour ex√©cuter sans d√©bogage
3. `Ctrl+Shift+P` ‚Üí ".NET: Generate Assets for Build and Debug" (pour cr√©er launch.json)

---

#### üé® Option B : Visual Studio 2022 (IDE complet)

Visual Studio 2022 offre une exp√©rience IDE compl√®te avec IntelliSense avanc√©, d√©bogage graphique et designers visuels.

**Pr√©requis** :
- [Visual Studio 2022](https://visualstudio.microsoft.com/vs/) install√©
- Workload **"D√©veloppement .NET Desktop"** s√©lectionn√© lors de l'installation

```mermaid
flowchart TD
    A["üé® Visual Studio 2022"] --> B["üìÅ Fichier ‚Üí Nouveau ‚Üí Projet"]
    B --> C["üìã S√©lectionner 'Application console'"]
    C --> D["‚öôÔ∏è Framework: .NET 8.0"]
    D --> E["üì¶ G√©rer les packages NuGet"]
    E --> F["‚ñ∂Ô∏è F5 pour ex√©cuter"]
    
    style A fill:#5c2d91,color:#fff
    style F fill:#4caf50,color:#fff
```

**Instructions d√©taill√©es** :

1. **Fichier** ‚Üí **Nouveau** ‚Üí **Projet** (`Ctrl+Shift+N`)

2. S√©lectionner **Application console** (pas "Application console (.NET Framework)")
   ```
   Mod√®les > C# > Application console
   ```

3. Configuration du projet :
   | Param√®tre | Valeur |
   |-----------|--------|
   | Nom du projet | `KafkaProducerBasic` |
   | Emplacement | `lab-1.2a-producer-basic` |
   | Framework | **.NET 8.0** |

4. Ajouter les packages NuGet :
   - Clic droit sur le projet ‚Üí **G√©rer les packages NuGet**
   - Onglet **Parcourir**, rechercher et installer :
     - ‚úÖ `Confluent.Kafka` version **2.3.0**
     - ‚úÖ `Microsoft.Extensions.Logging` version **8.0.0**
     - ‚úÖ `Microsoft.Extensions.Logging.Console` version **8.0.0**

5. Ex√©cuter le projet :
   - **F5** : Ex√©cuter avec d√©bogage (breakpoints, inspection variables)
   - **Ctrl+F5** : Ex√©cuter sans d√©bogage (plus rapide)

---

#### üìä Comparaison VS Code vs Visual Studio

| Crit√®re | VS Code | Visual Studio 2022 |
|---------|---------|---------------------|
| **Poids** | L√©ger (~300MB) | Lourd (~2-3GB) |
| **Prix** | Gratuit | Gratuit (Community) |
| **D√©bogage** | Basique | Avanc√© (points d'arr√™t conditionnels, visualization) |
| **IntelliSense** | Bon | Excellent |
| **Id√©al pour** | Labs, scripts | Projets complexes, √©quipes |
| **Multiplateforme** | ‚úÖ Windows/Mac/Linux | ‚ö†Ô∏è Windows uniquement |

---

### √âtape 2 : Copier le code

Remplacez le contenu de `Program.cs` par le code fourni dans ce dossier.

**Fichiers fournis** :
- ‚úÖ `Program.cs` - Code principal du producer
- ‚úÖ `KafkaProducerBasic.csproj` - Configuration du projet
- ‚úÖ `appsettings.json` - Configuration (optionnel)

---

### √âtape 3 : Comprendre le code

#### Configuration du Producer

```csharp
var config = new ProducerConfig
{
    // Adresse du cluster Kafka
    BootstrapServers = "localhost:9092",  // Docker
    // BootstrapServers = "bhf-kafka-kafka-bootstrap:9092",  // OKD/K3s
    
    // Identification du client (pour logs et monitoring)
    ClientId = "dotnet-basic-producer",
    
    // Garantie de livraison : attendre confirmation de tous les ISR
    Acks = Acks.All,
    
    // Retry automatique en cas d'erreur retriable
    MessageSendMaxRetries = 3,
    RetryBackoffMs = 1000,
    RequestTimeoutMs = 30000
};
```

**Points cl√©s** :
- `BootstrapServers` : Adresse du cluster (adapter selon votre environnement)
- `Acks.All` : Garantie maximale (tous les r√©plicas synchronis√©s)
- Retry automatique pour erreurs transientes

#### Cr√©ation du Producer avec Handlers

```csharp
using var producer = new ProducerBuilder<Null, string>(config)
    .SetErrorHandler((_, e) => 
    {
        // Gestion des erreurs fatales et non-fatales
        logger.LogError("Producer error: Code={Code}, Reason={Reason}", 
            e.Code, e.Reason);
        if (e.IsFatal)
        {
            Environment.Exit(1);  // Arr√™t si erreur fatale
        }
    })
    .SetLogHandler((_, logMessage) => 
    {
        // Logs internes de Kafka
        logger.Log(logLevel, "Kafka internal log: {Message}", logMessage.Message);
    })
    .Build();
```

**Points cl√©s** :
- `<Null, string>` : Type de la cl√© (Null = pas de cl√©) et valeur (string)
- `SetErrorHandler` : Callback pour erreurs
- `SetLogHandler` : Logs internes de librdkafka

#### Envoi de Messages

```mermaid
sequenceDiagram
    participant App as Application .NET
    participant Producer as Kafka Producer
    participant Buffer as Buffer M√©moire
    participant Broker as Kafka Broker
    participant Topic as Topic orders.created

    App->>Producer: ProduceAsync(message)
    Producer->>Buffer: Queue message
    Producer-->>App: Task (async)
    
    Note over Buffer: Batch & Linger.ms
    
    Buffer->>Broker: Send batch
    Broker->>Topic: Write to partition
    Broker-->>Buffer: Ack (partition, offset)
    Buffer-->>App: DeliveryResult
    
    App->>App: Log Partition + Offset
```

Ce diagramme montre le flux asynchrone : l'application envoie un message, il est mis en buffer, envoy√© au broker, et la confirmation arrive avec les m√©tadonn√©es (partition, offset).

```csharp
var deliveryResult = await producer.ProduceAsync(topicName, new Message<Null, string>
{
    Value = messageValue,
    Headers = new Headers
    {
        { "correlation-id", Encoding.UTF8.GetBytes(Guid.NewGuid().ToString()) },
        { "source", Encoding.UTF8.GetBytes("dotnet-producer") }
    }
});

// Confirmation de livraison
logger.LogInformation(
    "‚úì Message delivered ‚Üí Partition: {Partition}, Offset: {Offset}",
    deliveryResult.Partition.Value,
    deliveryResult.Offset.Value
);
```

**Points cl√©s** :
- `ProduceAsync` : Envoi asynchrone (non-bloquant)
- `DeliveryResult` : Confirmation avec partition, offset, timestamp
- `Headers` : M√©tadonn√©es optionnelles (correlation ID, tracing)

#### Fermeture Propre

```csharp
finally
{
    // IMPORTANT : Flush des messages en attente
    producer.Flush(TimeSpan.FromSeconds(10));
    logger.LogInformation("Producer closed gracefully.");
}
```

**Points cl√©s** :
- `Flush()` : Envoie tous les messages en buffer avant fermeture
- Timeout de 10 secondes pour √©viter blocage infini

---

### √âtape 4 : Configurer l'environnement

#### Docker (localhost)

Modifier `Program.cs` ligne 11 :
```csharp
BootstrapServers = "localhost:9092"
```

#### OKD/K3s

Modifier `Program.cs` ligne 11 :
```csharp
BootstrapServers = "bhf-kafka-kafka-bootstrap:9092"
```

Ou utiliser une variable d'environnement :
```csharp
BootstrapServers = Environment.GetEnvironmentVariable("KAFKA_BOOTSTRAP_SERVERS") 
                   ?? "localhost:9092"
```

---

### √âtape 5 : Ex√©cuter le producer

#### Avec Visual Studio Code

```bash
dotnet run
```

#### Avec Visual Studio 2022

1. Appuyer sur **F5** (ou **Ctrl+F5** sans debugger)
2. Observer les logs dans la console

---

### √âtape 6 : Observer les r√©sultats

#### Logs attendus

```
info: Program[0]
      Producer started. Connecting to localhost:9092
info: Program[0]
      Sending message 1: {"orderId": "ORD-0001", "timestamp": "2026-02-05T11:30:00Z", "amount": 110}
info: Program[0]
      ‚úì Message 1 delivered ‚Üí Topic: orders.created, Partition: 3, Offset: 0, Timestamp: 2026-02-05 11:30:00
info: Program[0]
      Sending message 2: {"orderId": "ORD-0002", "timestamp": "2026-02-05T11:30:01Z", "amount": 120}
info: Program[0]
      ‚úì Message 2 delivered ‚Üí Topic: orders.created, Partition: 1, Offset: 0, Timestamp: 2026-02-05 11:30:01
...
info: Program[0]
      All messages sent successfully!
info: Program[0]
      Flushing pending messages...
info: Program[0]
      Producer closed gracefully.
```

**Points √† noter** :
- ‚úÖ Messages r√©partis sur les 6 partitions (round-robin car pas de cl√©)
- ‚úÖ Offset commence √† 0 pour chaque partition (si topic vide)
- ‚úÖ Pas d'erreurs de connexion
- ‚úÖ Latence d'envoi : ~5-10ms par message

---

### √âtape 7 : V√©rifier dans Kafka

#### Avec Kafka UI

**Docker** : http://localhost:8080  
**OKD/K3s** : http://<NODE_IP>:30808

1. Aller dans **Topics** ‚Üí **orders.created**
2. Cliquer sur **Messages**
3. Vous devez voir les 10 messages produits

#### Avec CLI Kafka

**Docker** :
```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic orders.created \
  --from-beginning \
  --max-messages 10
```

**OKD/K3s** :
```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-console-consumer.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic orders.created --from-beginning --max-messages 10
```

**R√©sultat attendu** :
```json
{"orderId": "ORD-0001", "timestamp": "2026-02-05T11:30:00Z", "amount": 110}
{"orderId": "ORD-0002", "timestamp": "2026-02-05T11:30:01Z", "amount": 120}
...
```

---

## üß™ Exercices Pratiques

### Exercice 1 : Modifier le nombre de messages

**Objectif** : Envoyer 50 messages au lieu de 10.

**Instructions** :
1. Modifier la ligne `for (int i = 1; i <= 10; i++)` ‚Üí `for (int i = 1; i <= 50; i++)`
2. Relancer le producer
3. Observer la distribution sur les partitions

**Question** : Combien de messages par partition en moyenne ?

<details>
<summary>üí° Solution</summary>

Avec 50 messages et 6 partitions, distribution attendue : ~8-9 messages par partition (peut varier l√©g√®rement avec sticky partitioner).

</details>

---

### Exercice 2 : Ajouter un header personnalis√©

**Objectif** : Ajouter un header `environment` avec la valeur `dev`.

**Instructions** :
1. Ajouter dans les headers :
```csharp
{ "environment", Encoding.UTF8.GetBytes("dev") }
```
2. Relancer et v√©rifier dans Kafka UI (onglet Headers)

---

### Exercice 3 : Tester la gestion d'erreurs

**Objectif** : Observer le comportement en cas d'erreur de connexion.

**Instructions** :
1. Arr√™ter Kafka : `docker stop kafka` (Docker) ou `kubectl scale kafka bhf-kafka --replicas=0 -n kafka` (K8s)
2. Relancer le producer
3. Observer les logs d'erreur et les retries

**Question** : Combien de retries avant √©chec final ?

<details>
<summary>üí° Solution</summary>

Le producer tentera 3 retries (configur√© via `MessageSendMaxRetries = 3`) avec 1 seconde entre chaque (`RetryBackoffMs = 1000`).

</details>

4. Red√©marrer Kafka : `docker start kafka` ou `kubectl scale kafka bhf-kafka --replicas=3 -n kafka`

---

## ‚úÖ Validation du Lab

Vous avez r√©ussi ce lab si :

- [ ] Le producer se connecte √† Kafka sans erreur
- [ ] Les 10 messages sont envoy√©s avec succ√®s
- [ ] Les messages sont visibles dans Kafka UI ou via CLI
- [ ] Les logs affichent partition et offset pour chaque message
- [ ] Le producer se ferme proprement avec `Flush()`
- [ ] Vous comprenez le r√¥le de `Acks`, `ProduceAsync`, et `DeliveryResult`

---

## üéØ Points Cl√©s √† Retenir

1. **ProduceAsync est non-bloquant** : Le message est mis en buffer et envoy√© de mani√®re asynchrone
2. **Flush() est obligatoire** : Avant fermeture pour √©viter perte de messages en attente
3. **DeliveryResult contient les m√©tadonn√©es** : Partition, offset, timestamp de livraison
4. **Acks.All garantit durabilit√©** : Tous les r√©plicas synchronis√©s avant confirmation
5. **Retry automatique** : Kafka g√®re les erreurs transientes automatiquement
6. **Headers pour m√©tadonn√©es** : Correlation ID, tracing, source, etc.

---

## üìñ Concepts Th√©oriques

### Sticky Partitioner (Kafka 2.4+)

Sans cl√©, Kafka utilise le **sticky partitioner** au lieu du round-robin classique :
- Messages group√©s par batch sur la m√™me partition
- Meilleure performance (moins de requ√™tes r√©seau)
- Distribution reste √©quilibr√©e sur le long terme

### Acks : Garanties de Livraison

| Acks | Garantie | Latence | Cas d'usage |
|------|----------|---------|-------------|
| `None (0)` | Aucune | Tr√®s faible | M√©triques, logs non-critiques |
| `Leader (1)` | Leader uniquement | Faible | Logs applicatifs |
| `All (-1)` | Tous les ISR | Plus √©lev√©e | Transactions, commandes |

**ISR** (In-Sync Replicas) : R√©plicas synchronis√©s avec le leader.

---

## üöÄ Prochaine √âtape

Vous ma√Ætrisez maintenant les bases du Producer Kafka !

üëâ **Passez au [LAB 1.2B : Producer avec Cl√©](../lab-1.2b-producer-keyed/README.md)**

Dans le prochain lab, vous apprendrez :
- Comment utiliser une cl√© pour contr√¥ler le partitionnement
- Garantir l'ordre des messages pour une m√™me entit√©
- √âviter les hot partitions
