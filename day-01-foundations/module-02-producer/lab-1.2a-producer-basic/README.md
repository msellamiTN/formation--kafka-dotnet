# LAB 1.2A : API Producer Basique - E-Banking Transactions

## ‚è±Ô∏è Dur√©e estim√©e : 45 minutes

## üè¶ Contexte E-Banking

Dans une banque moderne, chaque op√©ration client (virement, paiement carte, retrait DAB, pr√©l√®vement) doit √™tre **captur√©e en temps r√©el** pour alimenter les syst√®mes de d√©tection de fraude, de calcul de solde, de conformit√© r√©glementaire et de notification client.

Dans ce lab, vous allez cr√©er une **API Web ASP.NET Core** qui expose des endpoints REST pour traiter des **transactions bancaires** et les publier vers Apache Kafka. Chaque transaction sera un message Kafka, simulant le **c≈ìur du syst√®me de traitement transactionnel** d'une banque.

### Architecture Globale

```mermaid
flowchart LR
    subgraph Clients["üè¶ Clients Bancaires"]
        Web["üåê Web Banking"]
        Mobile["üì± Mobile App"]
        Swagger["üß™ Swagger/OpenAPI"]
    end

    subgraph API["üöÄ ASP.NET Core Web API"]
        TC["TransactionsController"]
        KPS["KafkaProducerService"]
    end

    subgraph Kafka["üî• Kafka"]
        T["üìã banking.transactions"]
    end

    subgraph Consumers["üì• Consumers en aval"]
        FR["üîç D√©tection Fraude"]
        BAL["üí∞ Calcul Solde"]
        NOT["üìß Notifications"]
        AUD["üìã Audit / Conformit√©"]
    end

    Web --> TC
    Mobile --> TC
    Swagger --> TC
    TC --> KPS
    KPS --> T
    T --> FR
    T --> BAL
    T --> NOT
    T --> AUD

    style Clients fill:#e3f2fd,stroke:#1976d2
    style API fill:#e8f5e8,stroke:#388e3c
    style Kafka fill:#fff3e0,stroke:#f57c00
    style Consumers fill:#fce4ec,stroke:#c62828
```

### Cycle de Vie d'une Transaction Bancaire

```mermaid
sequenceDiagram
    actor Client as üßë‚Äçüíº Client Bancaire
    participant App as üì± App Mobile / Web
    participant API as üöÄ E-Banking API
    participant Valid as ‚úÖ Validation
    participant Kafka as üî• Kafka Broker
    participant Fraud as üîç Anti-Fraude
    participant Ledger as üí∞ Grand Livre

    Client->>App: Initier un virement de 250‚Ç¨
    App->>API: POST /api/transactions
    API->>Valid: Valider IBAN, montant, devise
    Valid-->>API: ‚úÖ Transaction valide
    API->>Kafka: Publier message (TransactionId comme cl√©)
    Kafka-->>API: ACK (partition 3, offset 42)
    API-->>App: 201 Created + m√©tadonn√©es Kafka
    App-->>Client: "Virement en cours de traitement"

    Note over Kafka,Fraud: Traitement asynchrone en aval
    Kafka->>Fraud: Analyser le risque (score: 5/100)
    Fraud-->>Kafka: ‚úÖ Transaction approuv√©e
    Kafka->>Ledger: D√©biter FR76...789, Cr√©diter FR76...321
    Ledger-->>Client: üìß Notification: "Virement de 250‚Ç¨ effectu√©"
```

### Sc√©narios E-Banking Couverts

| Sc√©nario | Type | Montant | Risque | Description |
| -------- | ---- | ------- | ------ | ----------- |
| **Virement mensuel** | Transfer | 250‚Ç¨ - 2000‚Ç¨ | Faible (5) | Loyer, √©pargne, entre comptes |
| **Paiement facture** | BillPayment | 30‚Ç¨ - 500‚Ç¨ | Faible (2) | EDF, t√©l√©phone, assurance |
| **Paiement carte** | CardPayment | 5‚Ç¨ - 300‚Ç¨ | Moyen (15) | Restaurant, courses, shopping |
| **Virement international** | InternationalTransfer | 1000‚Ç¨ - 50000‚Ç¨ | √âlev√© (75) | SWIFT, conformit√© AML requise |
| **D√©p√¥t salaire** | Deposit | 1500‚Ç¨ - 5000‚Ç¨ | Faible (1) | Virement employeur mensuel |
| **Retrait DAB** | Withdrawal | 20‚Ç¨ - 500‚Ç¨ | Moyen (10) | Retrait esp√®ces distributeur |

---

## üéØ Objectifs

√Ä la fin de ce lab, vous serez capable de :

1. Cr√©er une **API Web ASP.NET Core** avec int√©gration Kafka
2. Configurer un **Kafka Producer** avec `ProducerConfig`
3. Envoyer des **transactions bancaires** via `ProduceAsync()`
4. Exploiter les **m√©tadonn√©es de livraison** (partition, offset, timestamp)
5. Tester tous les endpoints via **Swagger/OpenAPI**
6. G√©rer les **erreurs de base** et le cycle de vie du producer

---

## üìã Pr√©requis

### Cluster Kafka en fonctionnement

**Docker** :

```bash
cd ../../module-01-cluster
./scripts/up.sh
# V√©rifier : docker ps (kafka et kafka-ui doivent √™tre healthy)
```

**OKD/K3s** :

```bash
kubectl get kafka -n kafka
# Attendu : bhf-kafka avec status Ready
```

**OpenShift Sandbox** :

> ‚ö†Ô∏è Assurez-vous d'avoir configur√© l'acc√®s externe (port-forward) comme d√©crit dans le README du module.

```bash
# V√©rifiez les pods
oc get pods -l app=kafka
# Configurez les tunnels (dans 3 terminaux) :
# oc port-forward kafka-0 9094:9094
# oc port-forward kafka-1 9095:9094
# oc port-forward kafka-2 9096:9094
```

### Cr√©er le topic

**Docker** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions \
  --partitions 6 \
  --replication-factor 1
```

**OKD/K3s** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --create --if-not-exists --topic banking.transactions --partitions 6 --replication-factor 3
```

**OpenShift Sandbox** :

```bash
oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions \
  --partitions 3 \
  --replication-factor 3
```

---

## üöÄ Instructions Pas √† Pas

### √âtape 1 : Cr√©er le projet API Web

#### üíª Option A : Visual Studio Code

```bash
cd lab-1.2a-producer-basic
dotnet new webapi -n EBankingProducerAPI
cd EBankingProducerAPI
dotnet add package Confluent.Kafka --version 2.3.0
dotnet add package Swashbuckle.AspNetCore --version 6.5.0
```

#### üé® Option B : Visual Studio 2022

1. **Fichier** ‚Üí **Nouveau** ‚Üí **Projet** (`Ctrl+Shift+N`)
2. S√©lectionner **API Web ASP.NET Core**
3. Nom : `EBankingProducerAPI`, Framework : **.NET 8.0**
4. Clic droit projet ‚Üí **G√©rer les packages NuGet** :
   - `Confluent.Kafka` version **2.3.0**
   - `Swashbuckle.AspNetCore` version **6.5.0**

---

### √âtape 2 : Cr√©er le mod√®le Transaction

Cr√©er le fichier `Models/Transaction.cs` :

```csharp
using System.ComponentModel.DataAnnotations;

namespace EBankingProducerAPI.Models;

public class Transaction
{
    [Required]
    public string TransactionId { get; set; } = Guid.NewGuid().ToString();

    [Required]
    [StringLength(20, MinimumLength = 10)]
    public string FromAccount { get; set; } = string.Empty;

    [Required]
    [StringLength(20, MinimumLength = 10)]
    public string ToAccount { get; set; } = string.Empty;

    [Required]
    [Range(0.01, 1_000_000.00)]
    public decimal Amount { get; set; }

    [Required]
    [StringLength(3, MinimumLength = 3)]
    public string Currency { get; set; } = "EUR";

    [Required]
    public TransactionType Type { get; set; }

    [StringLength(500)]
    public string? Description { get; set; }

    [Required]
    public string CustomerId { get; set; } = string.Empty;

    public DateTime Timestamp { get; set; } = DateTime.UtcNow;

    [Range(0, 100)]
    public int RiskScore { get; set; } = 0;

    public TransactionStatus Status { get; set; } = TransactionStatus.Pending;
}

public enum TransactionType
{
    Transfer = 1,
    Payment = 2,
    Deposit = 3,
    Withdrawal = 4,
    CardPayment = 5,
    InternationalTransfer = 6,
    BillPayment = 7
}

public enum TransactionStatus
{
    Pending = 1,
    Processing = 2,
    Completed = 3,
    Failed = 4,
    Rejected = 5
}
```

---

### √âtape 3 : Cr√©er le service Kafka Producer

Cr√©er le fichier `Services/KafkaProducerService.cs` :

```csharp
using Confluent.Kafka;
using System.Text.Json;
using EBankingProducerAPI.Models;

namespace EBankingProducerAPI.Services;

public class KafkaProducerService : IDisposable
{
    private readonly IProducer<string, string> _producer;
    private readonly ILogger<KafkaProducerService> _logger;
    private readonly string _topic;

    public KafkaProducerService(IConfiguration config, ILogger<KafkaProducerService> logger)
    {
        _logger = logger;
        _topic = config["Kafka:Topic"] ?? "banking.transactions";

        var producerConfig = new ProducerConfig
        {
            BootstrapServers = config["Kafka:BootstrapServers"] ?? "localhost:9092",
            ClientId = config["Kafka:ClientId"] ?? "ebanking-producer-api",
            Acks = Acks.All,
            EnableIdempotence = true,
            MessageSendMaxRetries = 3,
            RetryBackoffMs = 1000,
            LingerMs = 10,
            BatchSize = 16384,
            CompressionType = CompressionType.Snappy
        };

        _producer = new ProducerBuilder<string, string>(producerConfig)
            .SetErrorHandler((_, error) =>
                _logger.LogError("Kafka Error: {Reason} (Code: {Code})", error.Reason, error.Code))
            .SetLogHandler((_, msg) =>
            {
                if (msg.Level >= SyslogLevel.Warning)
                    _logger.LogWarning("Kafka Log: {Message}", msg.Message);
            })
            .Build();

        _logger.LogInformation("Kafka Producer initialized ‚Üí {Servers}, Topic: {Topic}",
            producerConfig.BootstrapServers, _topic);
    }

    public async Task<DeliveryResult<string, string>> SendTransactionAsync(
        Transaction transaction, CancellationToken ct = default)
    {
        var json = JsonSerializer.Serialize(transaction, new JsonSerializerOptions
        {
            PropertyNamingPolicy = JsonNamingPolicy.CamelCase
        });

        var message = new Message<string, string>
        {
            Key = transaction.TransactionId,
            Value = json,
            Headers = new Headers
            {
                { "correlation-id", System.Text.Encoding.UTF8.GetBytes(Guid.NewGuid().ToString()) },
                { "event-type", System.Text.Encoding.UTF8.GetBytes("transaction.created") },
                { "source", System.Text.Encoding.UTF8.GetBytes("ebanking-api") },
                { "customer-id", System.Text.Encoding.UTF8.GetBytes(transaction.CustomerId) },
                { "transaction-type", System.Text.Encoding.UTF8.GetBytes(transaction.Type.ToString()) }
            },
            Timestamp = new Timestamp(transaction.Timestamp)
        };

        var result = await _producer.ProduceAsync(_topic, message, ct);

        _logger.LogInformation(
            "‚úÖ Transaction {Id} ‚Üí Partition: {P}, Offset: {O}, Type: {Type}, Amount: {Amt} {Cur}",
            transaction.TransactionId, result.Partition.Value, result.Offset.Value,
            transaction.Type, transaction.Amount, transaction.Currency);

        return result;
    }

    public void Dispose()
    {
        _producer?.Flush(TimeSpan.FromSeconds(10));
        _producer?.Dispose();
        _logger.LogInformation("Kafka Producer disposed");
    }
}
```

---

### √âtape 4 : Cr√©er le contr√¥leur API

Cr√©er le fichier `Controllers/TransactionsController.cs` :

```csharp
using Microsoft.AspNetCore.Mvc;
using EBankingProducerAPI.Models;
using EBankingProducerAPI.Services;

namespace EBankingProducerAPI.Controllers;

[ApiController]
[Route("api/[controller]")]
[Produces("application/json")]
public class TransactionsController : ControllerBase
{
    private readonly KafkaProducerService _kafka;
    private readonly ILogger<TransactionsController> _logger;

    public TransactionsController(KafkaProducerService kafka, ILogger<TransactionsController> logger)
    {
        _kafka = kafka;
        _logger = logger;
    }

    /// <summary>
    /// Cr√©er une transaction bancaire et l'envoyer √† Kafka
    /// </summary>
    /// <remarks>
    /// Exemple de requ√™te :
    ///
    ///     POST /api/transactions
    ///     {
    ///         "fromAccount": "FR76300010001234567890",
    ///         "toAccount":   "FR76300010009876543210",
    ///         "amount": 250.00,
    ///         "currency": "EUR",
    ///         "type": 1,
    ///         "description": "Virement mensuel loyer",
    ///         "customerId": "CUST-001"
    ///     }
    ///
    /// </remarks>
    [HttpPost]
    [ProducesResponseType(typeof(TransactionResponse), StatusCodes.Status201Created)]
    [ProducesResponseType(typeof(ProblemDetails), StatusCodes.Status400BadRequest)]
    [ProducesResponseType(typeof(ProblemDetails), StatusCodes.Status500InternalServerError)]
    public async Task<ActionResult<TransactionResponse>> CreateTransaction(
        [FromBody] Transaction transaction, CancellationToken ct)
    {
        if (string.IsNullOrEmpty(transaction.TransactionId))
            transaction.TransactionId = Guid.NewGuid().ToString();

        var result = await _kafka.SendTransactionAsync(transaction, ct);

        var response = new TransactionResponse
        {
            TransactionId = transaction.TransactionId,
            Status = "Processing",
            KafkaPartition = result.Partition.Value,
            KafkaOffset = result.Offset.Value,
            Timestamp = result.Timestamp.UtcDateTime
        };

        return CreatedAtAction(nameof(GetTransaction),
            new { transactionId = transaction.TransactionId }, response);
    }

    /// <summary>
    /// Envoyer un lot de transactions bancaires
    /// </summary>
    [HttpPost("batch")]
    [ProducesResponseType(typeof(BatchResponse), StatusCodes.Status201Created)]
    [ProducesResponseType(typeof(ProblemDetails), StatusCodes.Status400BadRequest)]
    public async Task<ActionResult<BatchResponse>> CreateBatch(
        [FromBody] List<Transaction> transactions, CancellationToken ct)
    {
        var results = new List<TransactionResponse>();

        foreach (var tx in transactions)
        {
            if (string.IsNullOrEmpty(tx.TransactionId))
                tx.TransactionId = Guid.NewGuid().ToString();

            var dr = await _kafka.SendTransactionAsync(tx, ct);
            results.Add(new TransactionResponse
            {
                TransactionId = tx.TransactionId,
                Status = "Processing",
                KafkaPartition = dr.Partition.Value,
                KafkaOffset = dr.Offset.Value,
                Timestamp = dr.Timestamp.UtcDateTime
            });
        }

        return Created("", new BatchResponse
        {
            ProcessedCount = results.Count,
            Transactions = results
        });
    }

    /// <summary>
    /// Obtenir le statut d'une transaction (placeholder)
    /// </summary>
    [HttpGet("{transactionId}")]
    [ProducesResponseType(typeof(TransactionResponse), StatusCodes.Status200OK)]
    public ActionResult<TransactionResponse> GetTransaction(string transactionId)
    {
        return Ok(new TransactionResponse
        {
            TransactionId = transactionId,
            Status = "Processing",
            Timestamp = DateTime.UtcNow
        });
    }

    /// <summary>
    /// Health check du service
    /// </summary>
    [HttpGet("health")]
    [ProducesResponseType(typeof(object), StatusCodes.Status200OK)]
    public ActionResult GetHealth()
    {
        return Ok(new { Status = "Healthy", Service = "EBanking Producer API", Timestamp = DateTime.UtcNow });
    }
}

// --- Response DTOs ---

public class TransactionResponse
{
    public string TransactionId { get; set; } = string.Empty;
    public string Status { get; set; } = string.Empty;
    public int KafkaPartition { get; set; }
    public long KafkaOffset { get; set; }
    public DateTime Timestamp { get; set; }
}

public class BatchResponse
{
    public int ProcessedCount { get; set; }
    public List<TransactionResponse> Transactions { get; set; } = new();
}
```

---

### √âtape 5 : Configurer Program.cs

Remplacer le contenu de `Program.cs` :

```csharp
using EBankingProducerAPI.Services;
using Microsoft.OpenApi.Models;
using System.Reflection;

var builder = WebApplication.CreateBuilder(args);

builder.Services.AddControllers();
builder.Services.AddSingleton<KafkaProducerService>();

builder.Services.AddEndpointsApiExplorer();
builder.Services.AddSwaggerGen(options =>
{
    options.SwaggerDoc("v1", new OpenApiInfo
    {
        Title = "E-Banking Producer API",
        Version = "v1",
        Description = "API de traitement de transactions bancaires avec Apache Kafka.\n\n"
            + "**Endpoints disponibles :**\n"
            + "- `POST /api/transactions` ‚Äî Cr√©er une transaction\n"
            + "- `POST /api/transactions/batch` ‚Äî Envoyer un lot\n"
            + "- `GET /api/transactions/{id}` ‚Äî Statut d'une transaction\n"
            + "- `GET /api/transactions/health` ‚Äî Health check",
        Contact = new OpenApiContact { Name = "E-Banking Team" }
    });

    var xmlFile = $"{Assembly.GetExecutingAssembly().GetName().Name}.xml";
    var xmlPath = Path.Combine(AppContext.BaseDirectory, xmlFile);
    if (File.Exists(xmlPath))
        options.IncludeXmlComments(xmlPath);
});

var app = builder.Build();

app.UseSwagger();
app.UseSwaggerUI(c =>
{
    c.SwaggerEndpoint("/swagger/v1/swagger.json", "E-Banking Producer API v1");
    c.RoutePrefix = "swagger";
});

app.MapControllers();

var logger = app.Services.GetRequiredService<ILogger<Program>>();
logger.LogInformation("========================================");
logger.LogInformation("  E-Banking Producer API");
logger.LogInformation("  Swagger UI : https://localhost:5001/swagger");
logger.LogInformation("  Kafka      : {Servers}", builder.Configuration["Kafka:BootstrapServers"] ?? "localhost:9092");
logger.LogInformation("  Topic      : {Topic}", builder.Configuration["Kafka:Topic"] ?? "banking.transactions");
logger.LogInformation("========================================");

app.Run();
```

---

### √âtape 6 : Configurer appsettings.json

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "Topic": "banking.transactions",
    "ClientId": "ebanking-producer-api"
  }
}
```

> **OKD/K3s** : Remplacer `localhost:9092` par `bhf-kafka-kafka-bootstrap:9092`

> **OpenShift Sandbox (Localis√©)** : Utilisez `localhost:9094` et assurez-vous que les tunnels sont actifs.

---

### √âtape 7 : Ex√©cuter et tester

#### Lancer l'API

```bash
dotnet run
```

L'API d√©marre sur `https://localhost:5001` (ou le port configur√©).

#### Ouvrir Swagger UI

Naviguer vers : **<https://localhost:5001/swagger>**

Vous verrez l'interface OpenAPI avec tous les endpoints document√©s.

---

## üß™ Tests OpenAPI (Swagger)

### Test 1 : Cr√©er un virement bancaire

Dans Swagger UI, cliquer sur **POST /api/transactions** ‚Üí **Try it out** :

```json
{
  "fromAccount": "FR7630001000123456789",
  "toAccount": "FR7630001000987654321",
  "amount": 250.00,
  "currency": "EUR",
  "type": 1,
  "description": "Virement mensuel loyer",
  "customerId": "CUST-001",
  "riskScore": 5
}
```

**R√©ponse attendue** (201 Created) :

```json
{
  "transactionId": "a1b2c3d4-...",
  "status": "Processing",
  "kafkaPartition": 3,
  "kafkaOffset": 0,
  "timestamp": "2026-02-06T00:00:00Z"
}
```

### Test 2 : Paiement de facture

```json
{
  "fromAccount": "FR7630001000123456789",
  "toAccount": "FR7630001000111222333",
  "amount": 89.99,
  "currency": "EUR",
  "type": 7,
  "description": "Facture √©lectricit√© EDF",
  "customerId": "CUST-001",
  "riskScore": 2
}
```

### Test 3 : Virement international (risque √©lev√©)

```json
{
  "fromAccount": "FR7630001000123456789",
  "toAccount": "GB29NWBK60161331926819",
  "amount": 15000.00,
  "currency": "EUR",
  "type": 6,
  "description": "International transfer to UK",
  "customerId": "CUST-002",
  "riskScore": 75
}
```

### Test 4 : Lot de transactions (batch)

Cliquer sur **POST /api/transactions/batch** ‚Üí **Try it out** :

```json
[
  {
    "fromAccount": "FR7630001000123456789",
    "toAccount": "FR7630001000111111111",
    "amount": 50.00,
    "currency": "EUR",
    "type": 2,
    "description": "Paiement abonnement Netflix",
    "customerId": "CUST-001"
  },
  {
    "fromAccount": "FR7630001000123456789",
    "toAccount": "FR7630001000222222222",
    "amount": 120.00,
    "currency": "EUR",
    "type": 2,
    "description": "Paiement assurance auto",
    "customerId": "CUST-001"
  },
  {
    "fromAccount": "FR7630001000123456789",
    "toAccount": "FR7630001000333333333",
    "amount": 35.00,
    "currency": "EUR",
    "type": 5,
    "description": "Paiement carte restaurant",
    "customerId": "CUST-001"
  }
]
```

### Test 5 : Health check

Cliquer sur **GET /api/transactions/health** ‚Üí **Try it out** ‚Üí **Execute**

**R√©ponse attendue** :

```json
{
  "status": "Healthy",
  "service": "EBanking Producer API",
  "timestamp": "2026-02-06T00:00:00Z"
}
```

---

## üìä V√©rifier dans Kafka

### Avec Kafka UI

**Docker** : <http://localhost:8080>

1. Aller dans **Topics** ‚Üí **banking.transactions**
2. Cliquer sur **Messages**
3. V√©rifier les transactions envoy√©es avec leurs headers

### Avec CLI Kafka

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning \
  --max-messages 10
```

**OpenShift Sandbox** :

```bash
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning \
  --max-messages 10
```

**R√©sultat attendu** :

```json
{"transactionId":"a1b2c3d4-...","fromAccount":"FR7630001000123456789","toAccount":"FR7630001000987654321","amount":250.00,"currency":"EUR","type":1,"description":"Virement mensuel loyer","customerId":"CUST-001","timestamp":"2026-02-06T00:00:00Z","riskScore":5,"status":1}
```

---

## ‚òÅÔ∏è D√©ploiement sur OpenShift Sandbox

> **üéØ Objectif** : Ce d√©ploiement ne se limite pas √† mettre l'API en ligne. L'objectif est de **valider les concepts fondamentaux du Producer Kafka** dans un environnement cloud r√©el :
> - **Envoi de messages** vers un topic Kafka depuis une API REST
> - **Partition et Offset** : chaque message re√ßoit une partition (round-robin) et un offset s√©quentiel
> - **Acknowledgment (acks)** : le broker confirme la r√©ception du message
> - **V√©rification via Kafka CLI** : consommer les messages produits pour confirmer le flux de bout en bout

### üöÄ D√©ploiement Automatis√© (Recommand√©)

> [!TIP]
> Utilisez les scripts de d√©ploiement automatis√© pour un d√©ploiement complet avec validation des objectifs du lab.

**Option 1 : Script Bash (Linux/macOS/WSL)**
```bash
# Depuis la racine du repository
cd day-01-foundations/scripts
./deploy-and-test-1.2a.sh
```

**Option 2 : Script PowerShell (Windows)**
```powershell
# Depuis la racine du repository
cd day-01-foundations/scripts
.\deploy-and-test-1.2a.ps1
```

Ces scripts effectuent automatiquement :
- ‚úÖ Build de l'application
- ‚úÖ D√©ploiement sur OpenShift
- ‚úÖ Configuration des variables d'environnement
- ‚úÖ Cr√©ation de la route s√©curis√©e
- ‚úÖ Tests d'accessibilit√© (Health, Swagger)
- ‚úÖ Validation des objectifs du lab (production, s√©rialisation, partition, batch)
- ‚úÖ V√©rification du topic Kafka

---

### D√©ploiement Manuel (√âtape par √âtape)

Si vous pr√©f√©rez d√©ployer manuellement pour comprendre chaque √©tape :

### 1. Pr√©parer le d√©ploiement

Assurez-vous d'√™tre dans le dossier du projet :
```bash
cd EBankingProducerAPI
```

### 2. D√©ployer avec `oc new-app`

Nous allons utiliser la strat√©gie "Source-to-Image" (S2I) ou "Binary Build" de OpenShift.

```bash
# Cr√©er une build binaire pour .NET
oc new-build dotnet:8.0-ubi8 --binary=true --name=ebanking-producer-api

# Lancer la build en envoyant le dossier courant
oc start-build ebanking-producer-api --from-dir=. --follow

# Cr√©er l'application
oc new-app ebanking-producer-api
```

### 3. Configurer les variables d'environnement

L'API doit savoir o√π se trouve Kafka (interne au cluster).

```bash
oc set env deployment/ebanking-producer-api \
  Kafka__BootstrapServers=kafka-svc:9092 \
  Kafka__Topic=banking.transactions \
  ASPNETCORE_URLS=http://0.0.0.0:8080 \
  ASPNETCORE_ENVIRONMENT=Development
```

### 4. Exposer publiquement (Secure Edge Route)

> [!IMPORTANT]
> Standard routes may hang on the Sandbox. Use an **edge route** for reliable public access.

```bash
oc create route edge ebanking-producer-api --service=ebanking-producer-api --port=8080-tcp
```

### 5. Obtenir l'URL publique

```bash
HOST=$(oc get route ebanking-producer-api -o jsonpath='{.spec.host}')
echo "Swagger UI : https://$HOST/swagger"
```

Ouvrez cette URL dans votre navigateur pour acc√©der √† Swagger UI.

### 5.1 ‚úÖ V√©rification du D√©ploiement

Apr√®s avoir ex√©cut√© les √©tapes ci-dessus, v√©rifiez que tout fonctionne correctement :

#### √âtape 1 : V√©rifier le build
```bash
# Le build doit afficher "Build successful!" √† la fin
oc start-build ebanking-producer-api --from-dir=. --follow
```
**R√©sultat attendu** : `Build successful! Now deploying the application:`

#### √âtape 2 : V√©rifier le d√©ploiement
```bash
# V√©rifier que le pod est en cours d'ex√©cution
oc get pod -l app=ebanking-producer-api
```
**R√©sultat attendu** : Pod avec status `Running` et `1/1` dans la colonne `READY`

#### √âtape 3 : V√©rifier la configuration
```bash
# V√©rifier les variables d'environnement
oc env deployment/ebanking-producer-api --list
```
**R√©sultat attendu** : Doit contenir `Kafka__BootstrapServers=kafka-svc:9092`

#### √âtape 4 : V√©rifier la route
```bash
# V√©rifier que la route a √©t√© cr√©√©e
oc get route ebanking-producer-api-secure
```
**R√©sultat attendu** : Route avec le bon HOST et service `ebanking-producer-api`

#### √âtape 5 : V√©rifier le health endpoint
```bash
# Tester le endpoint de sant√©
curl -k -s "https://$HOST/api/Transactions/health"
```
**R√©sultat attendu** :
```json
{
  "status": "Healthy",
  "service": "EBanking Producer API",
  "timestamp": "2026-02-08T23:38:25.2965637Z"
}
```

#### √âtape 6 : Envoyer une transaction de test
```bash
# Cr√©er un fichier de test
cat > test-transaction.json << EOF
{
  "fromAccount": "FR7630001000123456",
  "toAccount": "FR7630001000987654",
  "amount": 1500.00,
  "currency": "EUR",
  "type": 1,
  "description": "Test transaction",
  "customerId": "CUST-001"
}
EOF

# Envoyer la transaction
curl -k -s -X POST "https://$HOST/api/Transactions" \
  -H "Content-Type: application/json" \
  -d @test-transaction.json
```
**R√©sultat attendu** :
```json
{
  "transactionId": "b4692c60-873c-4c43-83d1-586dbeda75b9",
  "status": "Processing",
  "kafkaPartition": 1,
  "kafkaOffset": 1,
  "timestamp": "2026-02-08T23:39:11.109Z"
}
```

#### √âtape 7 : V√©rifier dans Kafka
```bash
# V√©rifier que le message est bien dans Kafka
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning \
  --max-messages 1
```
**R√©sultat attendu** : Le message JSON de la transaction doit appara√Ætre

### üìä R√©sum√© du D√©ploiement R√©ussi

‚úÖ **Build completed** - .NET 8 application built successfully  
‚úÖ **Deployment created** - Pod is running on OpenShift  
‚úÖ **Environment configured** - Kafka connection set to `kafka-svc:9092`  
‚úÖ **Route created** - API accessible at: `https://ebanking-producer-api-secure-msellamitn-dev.apps.rm3.7wse.p1.openshiftapps.com`  
‚úÖ **Health check passed** - API responding correctly  
‚úÖ **Transaction sent** - Successfully sent to Kafka topic `banking.transactions`  
‚úÖ **Message verified** - Confirmed in Kafka with partition 1, offset 1

### 7. üß™ Sc√©narios de Test et Validation des Concepts

#### Sc√©nario 1 : Envoyer une transaction simple (POST /api/Transactions)

Dans Swagger UI, cliquer sur **POST /api/Transactions** ‚Üí **Try it out** :

```json
{
  "fromAccount": "FR7630001000123456789",
  "toAccount": "FR7630001000987654321",
  "amount": 1500.00,
  "currency": "EUR",
  "type": 1,
  "description": "Virement salaire janvier",
  "customerId": "CUST-001"
}
```

Ou via `curl` :

```bash
curl -k -s -X POST "https://$HOST/api/Transactions" \
  -H "Content-Type: application/json" \
  -d '{
    "fromAccount": "FR7630001000123456789",
    "toAccount": "FR7630001000987654321",
    "amount": 1500.00,
    "currency": "EUR",
    "type": 1,
    "description": "Virement salaire janvier",
    "customerId": "CUST-001"
  }' | jq .
```

**R√©ponse attendue (201 Created)** :

```json
{
  "transactionId": "a1b2c3d4-...",
  "status": "Processing",
  "kafkaPartition": 3,
  "kafkaOffset": 0,
  "timestamp": "2026-02-08T22:00:00Z"
}
```

**üìñ Concepts observ√©s** :

| Champ | Concept Kafka |
| ----- | ------------- |
| `kafkaPartition: 3` | Le broker assigne une partition via **round-robin** (pas de cl√© sp√©cifi√©e) |
| `kafkaOffset: 0` | Offset s√©quentiel ‚Äî premier message de cette partition |
| `status: "Processing"` | Envoi **fire-and-forget** ‚Äî le producer n'attend pas le traitement |

#### Sc√©nario 3 : Envoyer un lot de transactions (POST /api/Transactions/batch)

```bash
curl -k -s -X POST "https://$HOST/api/Transactions/batch" \
  -H "Content-Type: application/json" \
  -d '[
    {"fromAccount": "FR7630001000111111111", "toAccount": "FR7630001000222222222", "amount": 100.00, "currency": "EUR", "type": 1, "description": "Virement 1", "customerId": "CUST-001"},
    {"fromAccount": "FR7630001000333333333", "toAccount": "FR7630001000444444444", "amount": 250.00, "currency": "EUR", "type": 2, "description": "Paiement facture", "customerId": "CUST-002"},
    {"fromAccount": "FR7630001000555555555", "toAccount": "GB29NWBK60161331926819", "amount": 5000.00, "currency": "EUR", "type": 6, "description": "Transfert international", "customerId": "CUST-003"}
  ]' | jq .
```

**üìñ Concepts observ√©s** :
- Les 3 transactions arrivent sur des **partitions potentiellement diff√©rentes** (round-robin sans cl√©)
- Chaque message re√ßoit un **offset s√©quentiel** au sein de sa partition
- Le batch n'est **pas atomique** : chaque message est produit ind√©pendamment

#### Sc√©nario 4 : V√©rifier les messages dans Kafka (CLI)

```bash
# Consommer les messages du topic depuis le d√©but
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning \
  --max-messages 10
```

**V√©rification** : Vous devez voir les transactions envoy√©es en format JSON, confirmant que le Producer a bien √©crit dans le topic.

```bash
# V√©rifier les offsets par partition
oc exec kafka-0 -- /opt/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic banking.transactions
```

**Sortie attendue** (exemple avec 6 partitions) :

```text
banking.transactions:0:2
banking.transactions:1:1
banking.transactions:2:0
banking.transactions:3:1
banking.transactions:4:0
banking.transactions:5:0
```

Chaque ligne montre `topic:partition:dernier_offset`. Cela confirme la **distribution round-robin** des messages sans cl√©.

#### Sc√©nario 5 : Health Check et monitoring

```bash
curl -k -s "https://$HOST/api/Transactions/health" | jq .
```

**R√©ponse attendue** :

```json
{
  "status": "Healthy",
  "service": "EBanking Producer API",
  "timestamp": "2026-02-08T22:05:00Z"
}
```

#### R√©capitulatif des Endpoints

| M√©thode | Endpoint | Objectif p√©dagogique |
| ------- | -------- | -------------------- |
| `POST` | `/api/Transactions` | Produire un message Kafka (fire-and-forget) |
| `POST` | `/api/Transactions/batch` | Produire plusieurs messages en s√©quence |
| `GET` | `/api/Transactions/{id}` | Obtenir le statut d'une transaction |
| `GET` | `/api/Transactions/health` | V√©rifier la disponibilit√© du service |

### 8. Stability Warning

For Sandbox environments, use `Acks = Acks.Leader` and `EnableIdempotence = false` in `ProducerConfig` to avoid `Coordinator load in progress` hangs.

### 9. Troubleshooting (Sandbox)

- **503 Service Unavailable** :
    - V√©rifiez que le pod est `Running` : `oc get pods -l deployment=ebanking-producer-api`
    - V√©rifiez les logs : `oc logs -l deployment=ebanking-producer-api`
    - Assurez-vous que l'application √©coute sur le port 8080. Si elle √©coute sur 5000/5001 (d√©faut local), mettez √† jour la variable d'environnement :
      ```bash
      oc set env deployment/ebanking-producer-api ASPNETCORE_URLS="http://0.0.0.0:8080"
      ```

- **Kafka Error: Coordinator load in progress** :
    - Cela signifie que le cluster Kafka est en train d'√©lire les leaders pour les transactions internes. Cela peut prendre quelques minutes sur un cluster Sandbox frais.
    - Solution : Attendez 5 minutes et r√©√©ssayez. Ou red√©marrez les pods Kafka : `oc delete pods -l app=kafka`.

---

## üñ•Ô∏è D√©ploiement Local OpenShift (CRC / OpenShift Local)

Si vous disposez d'un cluster **OpenShift Local** (anciennement CRC ‚Äî CodeReady Containers), vous pouvez d√©ployer l'API directement depuis votre machine.

### 1. Pr√©requis

```bash
# V√©rifier que le cluster est d√©marr√©
crc status

# Se connecter au cluster
oc login -u developer https://api.crc.testing:6443
oc project ebanking-labs
```

### 2. Build et D√©ploiement (Binary Build)

```bash
cd EBankingProducerAPI

# Cr√©er la build config et lancer le build
oc new-build dotnet:8.0-ubi8 --binary=true --name=ebanking-producer-api
oc start-build ebanking-producer-api --from-dir=. --follow

# Cr√©er l'application
oc new-app ebanking-producer-api
```

### 3. Configurer les variables d'environnement

```bash
oc set env deployment/ebanking-producer-api \
  Kafka__BootstrapServers=kafka-svc:9092 \
  Kafka__Topic=banking.transactions \
  ASPNETCORE_URLS=http://0.0.0.0:8080 \
  ASPNETCORE_ENVIRONMENT=Development
```

### 4. Exposer et tester

```bash
# Cr√©er une route edge
oc create route edge ebanking-producer-api-secure --service=ebanking-producer-api --port=8080-tcp

# Obtenir l'URL
URL=$(oc get route ebanking-producer-api-secure -o jsonpath='{.spec.host}')
echo "https://$URL/swagger"

# Tester
curl -k -i "https://$URL/api/Transactions/health"
```

### 5. üß™ Validation des concepts (CRC)

```bash
# Obtenir l'URL
URL=$(oc get route ebanking-producer-api-secure -o jsonpath='{.spec.host}')

# Envoyer une transaction
curl -k -s -X POST "https://$URL/api/Transactions" \
  -H "Content-Type: application/json" \
  -d '{"fromAccount":"FR7630001000123456789","toAccount":"FR7630001000987654321","amount":1500.00,"currency":"EUR","type":1,"description":"Test CRC","customerId":"CUST-001"}' | jq .

# V√©rifier les messages dans Kafka
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning --max-messages 5

# V√©rifier la distribution des offsets par partition
oc exec kafka-0 -- /opt/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 --topic banking.transactions
```

### 6. Alternative : D√©ploiement par manifeste YAML

```bash
sed "s/\${NAMESPACE}/ebanking-labs/g" deployment/openshift-deployment.yaml | oc apply -f -
```

---

## ‚ò∏Ô∏è D√©ploiement Kubernetes / OKD (K3s, K8s, OKD)

Pour un cluster **Kubernetes standard** (K3s, K8s, Minikube) ou **OKD**, utilisez les manifestes YAML fournis dans le dossier `deployment/`.

### 1. Construire l'image Docker

```bash
cd EBankingProducerAPI

# Build de l'image
docker build -t ebanking-producer-api:latest .

# Pour un registry distant (adapter l'URL du registry)
docker tag ebanking-producer-api:latest <registry>/ebanking-producer-api:latest
docker push <registry>/ebanking-producer-api:latest
```

> **K3s / Minikube** : Si vous utilisez un cluster local, l'image locale suffit avec `imagePullPolicy: IfNotPresent`.

### 2. D√©ployer les manifestes

```bash
# Appliquer le Deployment + Service + Ingress
kubectl apply -f deployment/k8s-deployment.yaml

# V√©rifier le d√©ploiement
kubectl get pods -l app=ebanking-producer-api
kubectl get svc ebanking-producer-api
```

### 3. Configurer le Kafka Bootstrap (si diff√©rent)

```bash
kubectl set env deployment/ebanking-producer-api \
  Kafka__BootstrapServers=<kafka-bootstrap>:9092
```

### 4. Acc√©der √† l'API

```bash
# Port-forward pour acc√®s local
kubectl port-forward svc/ebanking-producer-api 8080:8080

# Tester
curl http://localhost:8080/api/Transactions/health
curl http://localhost:8080/swagger/index.html
```

> **Ingress** : Si vous avez un Ingress Controller (nginx, traefik), ajoutez `ebanking-producer-api.local` √† votre fichier `/etc/hosts` pointant vers l'IP du cluster.

### 5. üß™ Validation des concepts (K8s)

```bash
# Envoyer une transaction
curl -s -X POST "http://localhost:8080/api/Transactions" \
  -H "Content-Type: application/json" \
  -d '{"fromAccount":"FR7630001000123456789","toAccount":"FR7630001000987654321","amount":1500.00,"currency":"EUR","type":1,"description":"Test K8s","customerId":"CUST-001"}' | jq .

# V√©rifier les messages dans Kafka (adapter le pod Kafka selon votre installation)
kubectl exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic banking.transactions \
  --from-beginning --max-messages 5

# V√©rifier la distribution des offsets par partition
kubectl exec kafka-0 -- /opt/kafka/bin/kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 --topic banking.transactions
```

> **Docker Compose** : Si Kafka tourne via Docker Compose, utilisez `docker exec kafka ...` au lieu de `kubectl exec kafka-0 ...`.

### 6. OKD : Utiliser les manifestes OpenShift

```bash
sed "s/\${NAMESPACE}/$(oc project -q)/g" deployment/openshift-deployment.yaml | oc apply -f -
```

---

## üéØ Concepts Cl√©s Expliqu√©s

### Architecture du Producer Kafka

```mermaid
flowchart TB
    subgraph Producer["üì§ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["bootstrap.servers"]
            AC["acks = all"]
            ID["enable.idempotence = true"]
        end

        subgraph Pipeline["Pipeline d'envoi"]
            SER["üîÑ Serializer"]
            ACC["üì¶ RecordAccumulator"]
            SND["üåê Sender Thread"]
        end

        SER --> ACC --> SND
    end

    SND -->|"ProduceRequest"| K["üì¶ Kafka Broker"]
    K -->|"ACK"| SND

    style Config fill:#e3f2fd
    style Pipeline fill:#f3e5f5
```

### Niveaux de Confirmation (ACK)

| Acks | Garantie | Latence | Cas d'usage E-Banking |
| ---- | -------- | ------- | --------------------- |
| `0` | Aucune | Tr√®s faible | Logs d'audit non-critiques |
| `1` | Leader | Faible | Notifications push |
| `all` | Tous ISR | Plus √©lev√©e | **Transactions financi√®res** |

### S√©quence D√©taill√©e : API ‚Üí Kafka (Code Expliqu√©)

Ce diagramme montre exactement ce que fait chaque composant du code :

```mermaid
sequenceDiagram
    participant C as üåê Client (Swagger)
    participant Ctrl as ÔøΩ TransactionsController
    participant Svc as ‚öôÔ∏è KafkaProducerService
    participant Ser as ÔøΩ JSON Serializer
    participant Acc as üì¶ RecordAccumulator
    participant Net as üåê Sender Thread
    participant B as üî• Kafka Broker

    C->>Ctrl: POST /api/transactions {fromAccount, toAccount, amount...}
    Ctrl->>Ctrl: ModelState.IsValid? (DataAnnotations)
    Ctrl->>Svc: SendTransactionAsync(transaction)

    Note over Svc: √âtape 1 - S√©rialisation
    Svc->>Ser: JsonSerializer.Serialize(transaction)
    Ser-->>Svc: JSON string

    Note over Svc: √âtape 2 - Construction du Message
    Svc->>Svc: new Message<string,string> { Key, Value, Headers, Timestamp }
    Svc->>Svc: Ajout Headers: correlation-id, event-type, source, customer-id

    Note over Svc,B: √âtape 3 - Pipeline d'envoi Kafka
    Svc->>Acc: ProduceAsync() ‚Üí message dans le buffer
    Acc->>Acc: Batch par partition (LingerMs=10, BatchSize=16384)
    Acc->>Net: Batch pr√™t ‚Üí envoi r√©seau
    Net->>B: ProduceRequest (Snappy compressed)
    B->>B: √âcriture log + r√©plication ISR
    B-->>Net: ACK (Acks.All = tous les ISR)
    Net-->>Svc: DeliveryResult {Partition, Offset, Timestamp}

    Note over Ctrl: √âtape 4 - R√©ponse API
    Svc-->>Ctrl: DeliveryResult
    Ctrl->>Ctrl: Construire TransactionResponse
    Ctrl-->>C: 201 Created {transactionId, kafkaPartition, kafkaOffset}
```

### S√©quence Batch : Traitement de Plusieurs Transactions

```mermaid
sequenceDiagram
    participant C as üåê Client
    participant Ctrl as üìã Controller
    participant Svc as ‚öôÔ∏è KafkaProducer
    participant K as üî• Kafka

    C->>Ctrl: POST /api/transactions/batch [tx1, tx2, tx3]

    loop Pour chaque transaction
        Ctrl->>Svc: SendTransactionAsync(tx)
        Svc->>K: ProduceAsync()
        K-->>Svc: DeliveryResult
        Svc-->>Ctrl: R√©sultat ajout√© √† la liste
    end

    Ctrl-->>C: 201 Created {processedCount: 3, transactions: [...]}

    Note over K: Les 3 messages sont dans le topic
    Note over K: Chaque message a sa propre partition et offset
```

---

## üîß Troubleshooting

| Sympt√¥me | Cause probable | Solution |
| -------- | -------------- | -------- |
| `Broker transport failure` | Kafka non d√©marr√© | `cd ../../module-01-cluster && ./scripts/up.sh` |
| `UnknownTopicOrPartition` | Topic non cr√©√© | Cr√©er `banking.transactions` (voir Pr√©requis) |
| Swagger ne s'affiche pas | Mauvais URL | V√©rifier le port dans la console de d√©marrage |
| 400 Bad Request | Validation √©chou√©e | V√©rifier les champs requis dans le body JSON |
| Timeout 30s | Mauvais bootstrap servers | V√©rifier `appsettings.json` |

---

## ‚úÖ Validation du Lab

- [ ] L'API d√©marre sans erreur et Swagger UI est accessible
- [ ] `POST /api/transactions` retourne 201 avec les m√©tadonn√©es Kafka
- [ ] `POST /api/transactions/batch` traite un lot de 3+ transactions
- [ ] `GET /api/transactions/health` retourne "Healthy"
- [ ] Les messages sont visibles dans Kafka UI / CLI
- [ ] Les headers Kafka contiennent `correlation-id`, `event-type`, `customer-id`
- [ ] Vous comprenez le r√¥le de `Acks.All`, `ProduceAsync()`, et `DeliveryResult`

---

## üöÄ Prochaine √âtape

üëâ **[LAB 1.2B : API Producer avec Cl√© - Partitionnement par Client](../lab-1.2b-producer-keyed/README.md)**

Dans le prochain lab :

- Partitionnement d√©terministe par `CustomerId`
- Garantie d'ordre des transactions par client
- D√©tection et pr√©vention des hot partitions
