# LAB 1.3A (Java) : Consumer Basique ‚Äî D√©tection de Fraude E-Banking

## ‚è±Ô∏è Dur√©e estim√©e : 45 minutes

## üè¶ Contexte E-Banking

Dans une banque, chaque transaction publi√©e par l'API Producer (Module 02) doit √™tre **analys√©e en temps r√©el** par un service de d√©tection de fraude. Ce service consomme les messages du topic `banking.transactions`, √©value un **score de risque** pour chaque transaction, et d√©clenche des alertes si le risque est √©lev√©.

## üéØ Objectifs

√Ä la fin de ce lab, vous serez capable de :

1. Cr√©er un **Consumer Kafka** dans une API Web Spring Boot
2. Impl√©menter un **@KafkaListener** pour la consommation continue de messages
3. Comprendre l'**auto-commit** des offsets (comportement et risques)
4. D√©s√©rialiser les **transactions JSON** produites par le Module 02
5. Impl√©menter un **moteur de scoring de risque** pour la d√©tection de fraude
6. Exposer des **m√©triques et alertes** via des endpoints REST

---

## üìä Architecture

### Producer ‚Üí Kafka ‚Üí Consumer Fraude

```mermaid
flowchart LR
    subgraph Producer["üì§ Module 02 (d√©j√† fait)"]
        API["üöÄ E-Banking API"]
    end

    subgraph Kafka["üî• Kafka"]
        T["üìã banking.transactions"]
    end

    subgraph Consumer["üì• Ce LAB"]
        FD["üîç Fraud Detection API"]
        RS["‚öôÔ∏è FraudDetectionService"]
        SC["üìä Risk Scoring Engine"]
    end

    API --> T
    T --> RS
    RS --> SC
    SC --> FD

    style Producer fill:#e8f5e8,stroke:#388e3c
    style Kafka fill:#fff3e0,stroke:#f57c00
    style Consumer fill:#e3f2fd,stroke:#1976d2
```

### S√©quence : Consommation avec Auto-Commit

```mermaid
sequenceDiagram
    participant App as üöÄ Spring Boot App
    participant Listener as ‚öôÔ∏è @KafkaListener
    participant Broker as üî• Kafka Broker
    participant Coord as üëë Group Coordinator

    App->>Listener: D√©marrage FraudDetectionService
    Listener->>Broker: Subscribe("banking.transactions")
    Listener->>Coord: JoinGroup(groupId: "fraud-detection-service-java")
    Coord-->>Listener: Assignment: [P0, P1, P2, P3, P4, P5]

    loop Consommation continue
        Broker-->>Listener: ConsumerRecord {Key, Value, Partition, Offset}
        Listener->>Listener: D√©s√©rialiser JSON ‚Üí Transaction
        Listener->>Listener: calculateRiskScore(tx)
        Listener->>Listener: si score >= 40 ‚Üí cr√©er FraudAlert
        Listener->>Listener: Mettre √† jour m√©triques (AtomicLong thread-safe)
    end

    Note over Listener: ‚è∞ Toutes les 5s : Auto-commit offsets
    Listener->>Coord: CommitOffsets
```

---

## üèóÔ∏è Diagramme de Classes

```mermaid
classDiagram
    class FraudDetectionService {
        -ObjectMapper objectMapper
        -CopyOnWriteArrayList~FraudAlert~ alerts
        -AtomicLong messagesConsumed
        -AtomicLong fraudAlerts
        -AtomicLong processingErrors
        +onMessage(ConsumerRecord) void
        -calculateRiskScore(Transaction) int
        -determineRiskLevel(int) String
        +getAlerts() List~FraudAlert~
        +getMetrics() FraudMetrics
    }

    class FraudController {
        -FraudDetectionService service
        +alerts() ResponseEntity
        +stats() ResponseEntity
    }

    class Transaction {
        +String transactionId
        +String customerId
        +String fromAccount
        +String toAccount
        +BigDecimal amount
        +String currency
        +String type
        +String description
        +Instant timestamp
    }

    class FraudAlert {
        +String transactionId
        +String customerId
        +BigDecimal amount
        +int riskScore
        +String riskLevel
        +String reason
        +Instant detectedAt
        +int kafkaPartition
        +long kafkaOffset
    }

    class FraudMetrics {
        +long messagesConsumed
        +long fraudAlertsGenerated
        +long processingErrors
        +Instant startedAt
        +Instant lastMessageAt
    }

    FraudDetectionService --> Transaction : consomme
    FraudDetectionService --> FraudAlert : cr√©e
    FraudDetectionService --> FraudMetrics : expose
    FraudController --> FraudDetectionService : utilise
```

---

## Auto-Commit : Fonctionnement et Risques

```mermaid
sequenceDiagram
    participant Consumer as üì• Consumer (auto-commit)
    participant Kafka as üî• Kafka
    participant Engine as üìä Risk Scoring

    Consumer->>Kafka: Poll ‚Üí 100 transactions
    Consumer->>Engine: Traiter tx 1..80

    Note over Consumer: ‚è∞ Timer 5s ‚Üí Auto-commit offset = 100
    Consumer->>Kafka: Commit offset 100

    Consumer->>Engine: Traiter tx 81..100

    Note over Consumer: üí• CRASH !
    Note over Engine: tx 81-100 NON trait√©es !

    Consumer->>Kafka: Red√©marrage ‚Üí Reprend depuis offset 100
    Note over Consumer: ‚ö†Ô∏è Messages 81-100 PERDUS (commit√©s mais pas trait√©s)
```

> **‚ö†Ô∏è Important** : L'auto-commit est acceptable pour la d√©tection de fraude car rater une transaction n'a pas d'impact financier direct. Pour l'audit r√©glementaire (LAB 1.3C), nous utiliserons le manual commit.

---

## üöÄ Pr√©requis

### Topic Kafka

Le topic `banking.transactions` doit exister (cr√©√© dans le Module 02) :

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions

# Si le topic n'existe pas, cr√©ez-le :
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions \
  --partitions 6 \
  --replication-factor 1
```

### Messages dans le topic

Lancez l'API Producer du Module 02 et envoyez quelques transactions via Swagger pour avoir des messages √† consommer.

### JDK 17+ et Maven 3.9+

```bash
java -version
# Attendu : 17.x ou sup√©rieur

mvn -version
# Attendu : 3.9.x ou sup√©rieur
```

---

## üìù Instructions Pas √† Pas

### √âtape 1 : Structure du projet

```text
java/
‚îú‚îÄ‚îÄ pom.xml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄ src/main/
    ‚îú‚îÄ‚îÄ resources/
    ‚îÇ   ‚îî‚îÄ‚îÄ application.properties
    ‚îî‚îÄ‚îÄ java/com/data2ai/kafka/consumer/fraud/
        ‚îú‚îÄ‚îÄ FraudConsumerApplication.java
        ‚îú‚îÄ‚îÄ model/
        ‚îÇ   ‚îú‚îÄ‚îÄ Transaction.java
        ‚îÇ   ‚îú‚îÄ‚îÄ FraudAlert.java
        ‚îÇ   ‚îî‚îÄ‚îÄ FraudMetrics.java       (DTO)
        ‚îú‚îÄ‚îÄ service/
        ‚îÇ   ‚îî‚îÄ‚îÄ FraudDetectionService.java
        ‚îî‚îÄ‚îÄ controller/
            ‚îî‚îÄ‚îÄ FraudController.java
```

### √âtape 1 : Configuration Maven (`pom.xml`)

> **‚ö†Ô∏è Important** : Assurez-vous que le plugin Spring Boot Maven est correctement configur√© pour cr√©er un JAR ex√©cutable :

```xml
<plugin>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-maven-plugin</artifactId>
    <version>${spring-boot.version}</version>
    <executions>
        <execution>
            <goals>
                <goal>repackage</goal>
            </goals>
        </execution>
    </executions>
</plugin>
```

> **üìù Note** : Sans la configuration `repackage`, le JAR n'aura pas de manifest principal et ne pourra pas √™tre ex√©cut√©.

### √âtape 2 : D√©pendances Maven (`pom.xml`)

```xml
<dependencies>
    <!-- Spring Boot Web -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Spring Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <!-- Actuator (health checks) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>

    <!-- Jackson pour la d√©s√©rialisation JSON -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
    </dependency>
</dependencies>
```

### √âtape 3 : Configuration de l'application (`application.properties`)

```properties
server.port=${SERVER_PORT:8080}

spring.application.name=lab-1-3a-fraud-consumer

# Kafka
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
app.kafka.topic=${KAFKA_TOPIC:banking.transactions}
app.kafka.group-id=${KAFKA_GROUP_ID:fraud-detection-service-java}

# Consumer (auto-commit ‚Äî fonctionnalit√© cl√© de ce lab)
spring.kafka.consumer.group-id=${app.kafka.group-id}
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.properties.auto.commit.interval.ms=5000

# Actuator
management.endpoints.web.exposure.include=health,info
management.endpoint.health.show-details=always
```

**Points de configuration cl√©s :**

| Propri√©t√© | Valeur | R√¥le |
| --------- | ------ | ---- |
| `enable-auto-commit` | `true` | Offsets commit√©s automatiquement toutes les 5s |
| `auto-offset-reset` | `earliest` | Commencer depuis le d√©but si aucun offset committ√© |
| `group-id` | `fraud-detection-service-java` | Identit√© du consumer group |

### √âtape 4 : Mod√®le Transaction (`model/Transaction.java`)

```java
package com.data2ai.kafka.consumer.fraud.model;

import java.math.BigDecimal;
import java.time.Instant;

public class Transaction {
    private String transactionId;
    private String customerId;
    private String fromAccount;
    private String toAccount;
    private BigDecimal amount;
    private String currency;
    private String type;
    private String description;
    private Instant timestamp;
    private int riskScore;

    // Getters et setters omis pour la lisibilit√© ‚Äî voir le code source complet
}
```

### √âtape 5 : Mod√®le Alerte Fraude (`model/FraudAlert.java`)

```java
package com.data2ai.kafka.consumer.fraud.model;

import java.math.BigDecimal;
import java.time.Instant;

public class FraudAlert {
    private String transactionId;
    private String customerId;
    private BigDecimal amount;
    private String currency;
    private int riskScore;
    private String riskLevel;   // Low, Medium, High, Critical
    private String reason;
    private Instant detectedAt;
    private int kafkaPartition;
    private long kafkaOffset;

    // Getters et setters omis pour la lisibilit√© ‚Äî voir le code source complet
}
```

### √âtape 6 : Service Consumer Kafka (`service/FraudDetectionService.java`)

C'est le **c≈ìur du lab** ‚Äî la m√©thode `@KafkaListener` qui traite chaque message :

```java
@Service
public class FraudDetectionService {

    private static final Logger log = LoggerFactory.getLogger(FraudDetectionService.class);
    private final ObjectMapper objectMapper;

    // Stockage en m√©moire thread-safe
    private final CopyOnWriteArrayList<FraudAlert> alerts = new CopyOnWriteArrayList<>();
    private final AtomicLong messagesConsumed = new AtomicLong();
    private final AtomicLong fraudAlerts = new AtomicLong();
    private final AtomicLong processingErrors = new AtomicLong();

    @KafkaListener(topics = "${app.kafka.topic}")
    public void onMessage(ConsumerRecord<String, String> record) {
        messagesConsumed.incrementAndGet();

        try {
            Transaction tx = objectMapper.readValue(record.value(), Transaction.class);

            // Calculer le score de risque
            int riskScore = calculateRiskScore(tx);
            String riskLevel = determineRiskLevel(riskScore);

            log.info("Transaction {} | Client: {} | {} {} | Risque: {}/100 ({}) | P{}:O{}",
                    tx.getTransactionId(), tx.getCustomerId(),
                    tx.getAmount(), tx.getCurrency(),
                    riskScore, riskLevel,
                    record.partition(), record.offset());

            // Cr√©er une alerte si risque √©lev√© (score >= 40)
            if (riskScore >= 40) {
                FraudAlert alert = new FraudAlert();
                alert.setTransactionId(tx.getTransactionId());
                alert.setRiskScore(riskScore);
                alert.setRiskLevel(riskLevel);
                // ... autres champs
                alerts.add(alert);
                fraudAlerts.incrementAndGet();

                log.warn("üö® ALERTE FRAUDE: {} | Score: {} | {}",
                        tx.getTransactionId(), riskScore, alert.getReason());
            }
        } catch (Exception ex) {
            processingErrors.incrementAndGet();
            log.error("Erreur de traitement. partition={} offset={} erreur={}",
                    record.partition(), record.offset(), ex.getMessage());
        }
    }

    private int calculateRiskScore(Transaction tx) {
        int score = 0;
        // R√®gle 1 : Montant √©lev√©
        if (tx.getAmount() != null && tx.getAmount().doubleValue() > 10000) score += 40;
        else if (tx.getAmount() != null && tx.getAmount().doubleValue() > 5000) score += 20;

        // R√®gle 2 : Type de transaction √† risque
        if ("InternationalTransfer".equalsIgnoreCase(tx.getType())) score += 30;
        else if ("Withdrawal".equalsIgnoreCase(tx.getType())
                 && tx.getAmount() != null && tx.getAmount().doubleValue() > 300) score += 15;

        // R√®gle 3 : Transaction hors heures
        if (tx.getTimestamp() != null) {
            int hour = tx.getTimestamp().atZone(java.time.ZoneOffset.UTC).getHour();
            if (hour < 6 || hour > 22) score += 15;
        }

        return Math.min(score, 100);
    }
}
```

**Concepts cl√©s d√©montr√©s :**

- **`@KafkaListener`** ‚Äî Annotation Spring Kafka qui remplace le poll loop manuel
- **`ConsumerRecord`** ‚Äî Fournit l'acc√®s √† la cl√©, valeur, partition, offset
- **Collections thread-safe** ‚Äî `CopyOnWriteArrayList`, `AtomicLong` pour l'acc√®s concurrent
- **Auto-commit** ‚Äî Les offsets sont commit√©s automatiquement toutes les 5 secondes par Spring Kafka

### √âtape 7 : Contr√¥leur REST (`controller/FraudController.java`)

```java
@RestController
@RequestMapping("/api/v1")
public class FraudController {

    private final FraudDetectionService service;

    public FraudController(FraudDetectionService service) {
        this.service = service;
    }

    @GetMapping("/alerts")
    public ResponseEntity<List<FraudAlert>> alerts() {
        return ResponseEntity.ok(service.getAlerts());
    }

    @GetMapping("/stats")
    public ResponseEntity<FraudMetrics> stats() {
        return ResponseEntity.ok(service.getMetrics());
    }
}
```

### √âtape 8 : Classe principale Spring Boot

```java
@SpringBootApplication
public class FraudConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(FraudConsumerApplication.class, args);
    }
}
```

---

## üöÄ D√©ploiement

### D√©veloppement Local

#### 1. D√©marrer Kafka (si pas d√©j√† fait)

```bash
cd ../../module-01-cluster
docker compose up -d
```

#### 2. Produire des messages (Module 02)

Lancez l'API Producer du Module 02 et envoyez des transactions via Swagger.

#### 3. D√©marrer le Consumer

```bash
cd java
mvn spring-boot:run
```

#### 4. Observer les logs

```text
INFO  FraudDetectionService : Transaction TX-001 | Client: CUST-001 | 250.00 EUR | Risque: 5/100 (Low) | P0:O42
WARN  FraudDetectionService : üö® ALERTE FRAUDE: TX-002 | Score: 60 | Montant √©lev√©: 15000.00EUR
```

#### 5. V√©rifier via l'API

- `GET http://localhost:8080/api/v1/alerts` ‚Äî Toutes les alertes fraude
- `GET http://localhost:8080/api/v1/stats` ‚Äî M√©triques du consumer
- `GET http://localhost:8080/actuator/health` ‚Äî Health check

### Docker

```bash
cd java
docker build -t ebanking-fraud-consumer-java .
docker run -p 8080:8080 \
  -e KAFKA_BOOTSTRAP_SERVERS=host.docker.internal:9092 \
  ebanking-fraud-consumer-java
```

### OpenShift Sandbox ‚Äî Option A : Build S2I Binaire

> **üéØ Objectif** : Ce d√©ploiement valide les concepts fondamentaux du **Consumer Kafka** dans un environnement cloud :
> - **@KafkaListener** : le consumer re√ßoit les messages via le listener container de Spring Kafka
> - **Auto-commit** : les offsets sont commit√©s automatiquement toutes les 5 secondes
> - **Partition assignment** : le consumer re√ßoit les 6 partitions du topic
> - **Health check** : l'API expose l'√©tat du consumer via `/actuator/health`

#### 1. Build et D√©ploiement

```bash
cd module-03-consumer/lab-1.3a-consumer-basic/java

# Cr√©er le BuildConfig (avec image stream explicite)
oc new-build --image-stream="openshift/java:openjdk-17-ubi8" --binary=true --name=ebanking-fraud-consumer-java

# Build depuis le source local
oc start-build ebanking-fraud-consumer-java --from-dir=. --follow

# D√©ployer
oc new-app ebanking-fraud-consumer-java
```

#### 2. Configurer les variables d'environnement

```bash
oc set env deployment/ebanking-fraud-consumer-java \
  SERVER_PORT=8080 \
  KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092 \
  KAFKA_TOPIC=banking.transactions
```

#### 3. Cr√©er la route Edge

```bash
oc create route edge ebanking-fraud-consumer-java-secure \
  --service=ebanking-fraud-consumer-java --port=8080-tcp
```

#### 4. V√©rifier le d√©ploiement

```bash
# Obtenir l'URL publique
URL=$(oc get route ebanking-fraud-consumer-java-secure -o jsonpath='{.spec.host}')

# Health check
curl -k "https://$URL/actuator/health"

# M√©triques du consumer
curl -k -s "https://$URL/api/v1/stats"

# Alertes fraude
curl -k -s "https://$URL/api/v1/alerts"
```

> **üìù Note** : Sur PowerShell, utilisez :
> ```powershell
> $URL = oc get route ebanking-fraud-consumer-java-secure -o jsonpath='{.spec.host}'
> [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]::Tls12
> (New-Object System.Net.WebClient).DownloadString("https://$URL/api/v1/stats")
> ```

#### 5. ‚úÖ Crit√®res de succ√®s

```bash
# Pod en cours d'ex√©cution ?
oc get pod -l deployment=ebanking-fraud-consumer-java
# Attendu : STATUS=Running, READY=1/1

# Consumer actif ?
curl -k -s "https://$URL/actuator/health"
# Attendu : {"status":"UP"}
```

#### 6. Script automatis√©

```bash
# Bash
./scripts/bash/deploy-and-test-1.3a-java.sh

# PowerShell
.\scripts\powershell\deploy-and-test-1.3a-java.ps1
```

---

## üß™ Tests

### Sc√©narios de test

```bash
URL=$(oc get route ebanking-fraud-consumer-java-secure -o jsonpath='{.spec.host}')

# 1. Health check
curl -k -s "https://$URL/actuator/health"

# 2. V√©rifier les stats (messagesConsumed doit augmenter)
curl -k -s "https://$URL/api/v1/stats"

# 3. V√©rifier les alertes fraude (montants √©lev√©s d√©clenchent des alertes)
curl -k -s "https://$URL/api/v1/alerts"
```

---

## üìã Endpoints API

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| `GET` | `/api/v1/alerts` | Toutes les alertes fraude d√©tect√©es |
| `GET` | `/api/v1/stats` | M√©triques du consumer (messages consomm√©s, alertes, erreurs) |
| `GET` | `/actuator/health` | Health check |

---

## üéØ Concepts Cl√©s Expliqu√©s

### Spring Kafka vs Confluent.Kafka (.NET)

| Aspect | Java (Spring Kafka) | .NET (Confluent.Kafka) |
| ------ | ------------------- | ---------------------- |
| **Configuration consumer** | `@KafkaListener` annotation | `BackgroundService` + poll loop |
| **D√©s√©rialisation** | Jackson `ObjectMapper` | `System.Text.Json` |
| **Thread safety** | `AtomicLong`, `CopyOnWriteArrayList` | `Interlocked`, `ConcurrentBag` |
| **Configuration** | `application.properties` | `appsettings.json` + `ConsumerConfig` |
| **Health check** | Spring Actuator `/actuator/health` | Custom `/api/FraudDetection/health` |
| **Auto-commit** | `enable-auto-commit=true` (d√©faut) | `EnableAutoCommit = true` |

### R√®gles de Scoring de Risque

| R√®gle | Condition | Score ajout√© |
| ----- | --------- | ------------ |
| Montant √©lev√© | `amount > 10 000` | +40 |
| Montant notable | `amount > 5 000` | +20 |
| Virement international | `type = InternationalTransfer` | +30 |
| Retrait √©lev√© | `type = Withdrawal && amount > 300` | +15 |
| Hors heures | `hour < 6 ou hour > 22` | +15 |

### Niveaux de Risque

| Score | Niveau | Action |
| ----- | ------ | ------ |
| 0-24 | Low | Aucune action |
| 25-49 | Medium | Alerte cr√©√©e |
| 50-74 | High | Alerte + revue requise |
| 75-100 | Critical | Alerte + blocage imm√©diat |

---

## üîß Troubleshooting

| Sympt√¥me | Cause probable | Solution |
| -------- | -------------- | -------- |
| Aucun message consomm√© | Mauvais bootstrap servers ou topic | V√©rifier les variables `KAFKA_BOOTSTRAP_SERVERS` et `KAFKA_TOPIC` |
| Health retourne DOWN | Consumer non connect√© √† Kafka | V√©rifier que Kafka est d√©marr√© et accessible |
| `messagesConsumed` reste √† 0 | Pas de messages dans le topic | Envoyer des transactions via l'API Producer |
| Erreurs de d√©s√©rialisation | Format JSON incompatible | V√©rifier que le producer envoie le bon sch√©ma JSON |
| Pod CrashLoopBackOff | Variables d'environnement manquantes | V√©rifier : `oc set env deployment/ebanking-fraud-consumer-java --list` |

---

## ‚úÖ Validation

- [ ] Le consumer d√©marre et se connecte √† Kafka
- [ ] Les messages sont consomm√©s depuis `banking.transactions`
- [ ] Le score de risque est calcul√© pour chaque transaction
- [ ] Des alertes sont cr√©√©es pour les transactions avec score >= 40
- [ ] `/api/v1/alerts` retourne les alertes fraude d√©tect√©es
- [ ] `/api/v1/stats` montre `messagesConsumed > 0`
- [ ] `/actuator/health` retourne `UP`
- [ ] L'auto-commit est activ√© (offsets commit√©s toutes les 5s)

---

## üèÅ √âtape Suivante

Passez au **[LAB 1.3B (Java) : Consumer Group ‚Äî Calcul de Solde](../../lab-1.3b-consumer-group/java/README.md)** pour apprendre les consumer groups, l'assignation de partitions et le rebalancing.
