# LAB 1.3A (Java) : Consumer Basique â€” DÃ©tection de Fraude E-Banking

## â±ï¸ DurÃ©e estimÃ©e : 45 minutes

## ğŸ¦ Contexte E-Banking

Dans une banque, chaque transaction publiÃ©e par l'API Producer (Module 02) doit Ãªtre **analysÃ©e en temps rÃ©el** par un service de dÃ©tection de fraude. Ce service consomme les messages du topic `banking.transactions`, Ã©value un **score de risque** pour chaque transaction, et dÃ©clenche des alertes si le risque est Ã©levÃ©.

## ğŸ¯ Objectifs

Ã€ la fin de ce lab, vous serez capable de :

1. CrÃ©er un **Consumer Kafka** dans une API Web Spring Boot
2. ImplÃ©menter un **@KafkaListener** pour la consommation continue de messages
3. Comprendre l'**auto-commit** des offsets (comportement et risques)
4. DÃ©sÃ©rialiser les **transactions JSON** produites par le Module 02
5. ImplÃ©menter un **moteur de scoring de risque** pour la dÃ©tection de fraude
6. Exposer des **mÃ©triques et alertes** via des endpoints REST

---

## ğŸ“Š Architecture

### Producer â†’ Kafka â†’ Consumer Fraude

```mermaid
flowchart LR
    subgraph Producer["ğŸ“¤ Module 02 (dÃ©jÃ  fait)"]
        API["ğŸš€ E-Banking API"]
    end

    subgraph Kafka["ğŸ”¥ Kafka"]
        T["ğŸ“‹ banking.transactions"]
    end

    subgraph Consumer["ğŸ“¥ Ce LAB"]
        FD["ğŸ” Fraud Detection API"]
        RS["âš™ï¸ FraudDetectionService"]
        SC["ğŸ“Š Risk Scoring Engine"]
    end

    API --> T
    T --> RS
    RS --> SC
    SC --> FD

    style Producer fill:#e8f5e8,stroke:#388e3c
    style Kafka fill:#fff3e0,stroke:#f57c00
    style Consumer fill:#e3f2fd,stroke:#1976d2
```

### SÃ©quence : Consommation avec Auto-Commit

```mermaid
sequenceDiagram
    participant App as ğŸš€ Spring Boot App
    participant Listener as âš™ï¸ @KafkaListener
    participant Broker as ğŸ”¥ Kafka Broker
    participant Coord as ğŸ‘‘ Group Coordinator

    App->>Listener: DÃ©marrage FraudDetectionService
    Listener->>Broker: Subscribe("banking.transactions")
    Listener->>Coord: JoinGroup(groupId: "fraud-detection-service-java")
    Coord-->>Listener: Assignment: [P0, P1, P2, P3, P4, P5]

    loop Consommation continue
        Broker-->>Listener: ConsumerRecord {Key, Value, Partition, Offset}
        Listener->>Listener: DÃ©sÃ©rialiser JSON â†’ Transaction
        Listener->>Listener: calculateRiskScore(tx)
        Listener->>Listener: si score >= 40 â†’ crÃ©er FraudAlert
        Listener->>Listener: Mettre Ã  jour mÃ©triques (AtomicLong thread-safe)
    end

    Note over Listener: â° Toutes les 5s : Auto-commit offsets
    Listener->>Coord: CommitOffsets
```

---

## ğŸ—ï¸ Diagramme de Classes

```mermaid
classDiagram
    class FraudDetectionService {
        -ObjectMapper objectMapper
        -CopyOnWriteArrayList~FraudAlert~ alerts
        -AtomicLong messagesConsumed
        -AtomicLong fraudAlerts
        -AtomicLong processingErrors
        +onMessage(ConsumerRecord) void
        -calculateRiskScore(Transaction) int
        -determineRiskLevel(int) String
        +getAlerts() List~FraudAlert~
        +getMetrics() FraudMetrics
    }

    class FraudController {
        -FraudDetectionService service
        +alerts() ResponseEntity
        +stats() ResponseEntity
    }

    class Transaction {
        +String transactionId
        +String customerId
        +String fromAccount
        +String toAccount
        +BigDecimal amount
        +String currency
        +String type
        +String description
        +Instant timestamp
    }

    class FraudAlert {
        +String transactionId
        +String customerId
        +BigDecimal amount
        +int riskScore
        +String riskLevel
        +String reason
        +Instant detectedAt
        +int kafkaPartition
        +long kafkaOffset
    }

    class FraudMetrics {
        +long messagesConsumed
        +long fraudAlertsGenerated
        +long processingErrors
        +Instant startedAt
        +Instant lastMessageAt
    }

    FraudDetectionService --> Transaction : consomme
    FraudDetectionService --> FraudAlert : crÃ©e
    FraudDetectionService --> FraudMetrics : expose
    FraudController --> FraudDetectionService : utilise
```

---

## Auto-Commit : Fonctionnement et Risques

```mermaid
sequenceDiagram
    participant Consumer as ğŸ“¥ Consumer (auto-commit)
    participant Kafka as ğŸ”¥ Kafka
    participant Engine as ğŸ“Š Risk Scoring

    Consumer->>Kafka: Poll â†’ 100 transactions
    Consumer->>Engine: Traiter tx 1..80

    Note over Consumer: â° Timer 5s â†’ Auto-commit offset = 100
    Consumer->>Kafka: Commit offset 100

    Consumer->>Engine: Traiter tx 81..100

    Note over Consumer: ğŸ’¥ CRASH !
    Note over Engine: tx 81-100 NON traitÃ©es !

    Consumer->>Kafka: RedÃ©marrage â†’ Reprend depuis offset 100
    Note over Consumer: âš ï¸ Messages 81-100 PERDUS (commitÃ©s mais pas traitÃ©s)
```

> **âš ï¸ Important** : L'auto-commit est acceptable pour la dÃ©tection de fraude car rater une transaction n'a pas d'impact financier direct. Pour l'audit rÃ©glementaire (LAB 1.3C), nous utiliserons le manual commit.

---

## ğŸš€ PrÃ©requis

### Topic Kafka

Le topic `banking.transactions` doit exister (crÃ©Ã© dans le Module 02) :

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions

# Si le topic n'existe pas, crÃ©ez-le :
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions \
  --partitions 6 \
  --replication-factor 1
```

### Messages dans le topic

Lancez l'API Producer du Module 02 et envoyez quelques transactions via Swagger pour avoir des messages Ã  consommer.

### JDK 17+ et Maven 3.9+

```bash
java -version
# Attendu : 17.x ou supÃ©rieur

mvn -version
# Attendu : 3.9.x ou supÃ©rieur
```

---

## ğŸ“ Instructions Pas Ã  Pas

### Ã‰tape 1 : Structure du projet

```text
java/
â”œâ”€â”€ pom.xml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â””â”€â”€ src/main/
    â”œâ”€â”€ resources/
    â”‚   â””â”€â”€ application.properties
    â””â”€â”€ java/com/data2ai/kafka/consumer/fraud/
        â”œâ”€â”€ FraudConsumerApplication.java
        â”œâ”€â”€ model/
        â”‚   â”œâ”€â”€ Transaction.java
        â”‚   â”œâ”€â”€ FraudAlert.java
        â”‚   â””â”€â”€ FraudMetrics.java       (DTO)
        â”œâ”€â”€ service/
        â”‚   â””â”€â”€ FraudDetectionService.java
        â””â”€â”€ controller/
            â””â”€â”€ FraudController.java
```

### Ã‰tape 2 : DÃ©pendances Maven (`pom.xml`)

```xml
<dependencies>
    <!-- Spring Boot Web -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Spring Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <!-- Actuator (health checks) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>

    <!-- Jackson pour la dÃ©sÃ©rialisation JSON -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
    </dependency>
</dependencies>
```

### Ã‰tape 3 : Configuration de l'application (`application.properties`)

```properties
server.port=${SERVER_PORT:8080}

spring.application.name=lab-1-3a-fraud-consumer

# Kafka
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
app.kafka.topic=${KAFKA_TOPIC:banking.transactions}
app.kafka.group-id=${KAFKA_GROUP_ID:fraud-detection-service-java}

# Consumer (auto-commit â€” fonctionnalitÃ© clÃ© de ce lab)
spring.kafka.consumer.group-id=${app.kafka.group-id}
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.properties.auto.commit.interval.ms=5000

# Actuator
management.endpoints.web.exposure.include=health,info
management.endpoint.health.show-details=always
```

**Points de configuration clÃ©s :**

| PropriÃ©tÃ© | Valeur | RÃ´le |
| --------- | ------ | ---- |
| `enable-auto-commit` | `true` | Offsets commitÃ©s automatiquement toutes les 5s |
| `auto-offset-reset` | `earliest` | Commencer depuis le dÃ©but si aucun offset committÃ© |
| `group-id` | `fraud-detection-service-java` | IdentitÃ© du consumer group |

### Ã‰tape 4 : ModÃ¨le Transaction (`model/Transaction.java`)

```java
package com.data2ai.kafka.consumer.fraud.model;

import java.math.BigDecimal;
import java.time.Instant;

public class Transaction {
    private String transactionId;
    private String customerId;
    private String fromAccount;
    private String toAccount;
    private BigDecimal amount;
    private String currency;
    private String type;
    private String description;
    private Instant timestamp;
    private int riskScore;

    // Getters et setters omis pour la lisibilitÃ© â€” voir le code source complet
}
```

### Ã‰tape 5 : ModÃ¨le Alerte Fraude (`model/FraudAlert.java`)

```java
package com.data2ai.kafka.consumer.fraud.model;

import java.math.BigDecimal;
import java.time.Instant;

public class FraudAlert {
    private String transactionId;
    private String customerId;
    private BigDecimal amount;
    private String currency;
    private int riskScore;
    private String riskLevel;   // Low, Medium, High, Critical
    private String reason;
    private Instant detectedAt;
    private int kafkaPartition;
    private long kafkaOffset;

    // Getters et setters omis pour la lisibilitÃ© â€” voir le code source complet
}
```

### Ã‰tape 6 : Service Consumer Kafka (`service/FraudDetectionService.java`)

C'est le **cÅ“ur du lab** â€” la mÃ©thode `@KafkaListener` qui traite chaque message :

```java
@Service
public class FraudDetectionService {

    private static final Logger log = LoggerFactory.getLogger(FraudDetectionService.class);
    private final ObjectMapper objectMapper;

    // Stockage en mÃ©moire thread-safe
    private final CopyOnWriteArrayList<FraudAlert> alerts = new CopyOnWriteArrayList<>();
    private final AtomicLong messagesConsumed = new AtomicLong();
    private final AtomicLong fraudAlerts = new AtomicLong();
    private final AtomicLong processingErrors = new AtomicLong();

    @KafkaListener(topics = "${app.kafka.topic}")
    public void onMessage(ConsumerRecord<String, String> record) {
        messagesConsumed.incrementAndGet();

        try {
            Transaction tx = objectMapper.readValue(record.value(), Transaction.class);

            // Calculer le score de risque
            int riskScore = calculateRiskScore(tx);
            String riskLevel = determineRiskLevel(riskScore);

            log.info("Transaction {} | Client: {} | {} {} | Risque: {}/100 ({}) | P{}:O{}",
                    tx.getTransactionId(), tx.getCustomerId(),
                    tx.getAmount(), tx.getCurrency(),
                    riskScore, riskLevel,
                    record.partition(), record.offset());

            // CrÃ©er une alerte si risque Ã©levÃ© (score >= 40)
            if (riskScore >= 40) {
                FraudAlert alert = new FraudAlert();
                alert.setTransactionId(tx.getTransactionId());
                alert.setRiskScore(riskScore);
                alert.setRiskLevel(riskLevel);
                // ... autres champs
                alerts.add(alert);
                fraudAlerts.incrementAndGet();

                log.warn("ğŸš¨ ALERTE FRAUDE: {} | Score: {} | {}",
                        tx.getTransactionId(), riskScore, alert.getReason());
            }
        } catch (Exception ex) {
            processingErrors.incrementAndGet();
            log.error("Erreur de traitement. partition={} offset={} erreur={}",
                    record.partition(), record.offset(), ex.getMessage());
        }
    }

    private int calculateRiskScore(Transaction tx) {
        int score = 0;
        // RÃ¨gle 1 : Montant Ã©levÃ©
        if (tx.getAmount() != null && tx.getAmount().doubleValue() > 10000) score += 40;
        else if (tx.getAmount() != null && tx.getAmount().doubleValue() > 5000) score += 20;

        // RÃ¨gle 2 : Type de transaction Ã  risque
        if ("InternationalTransfer".equalsIgnoreCase(tx.getType())) score += 30;
        else if ("Withdrawal".equalsIgnoreCase(tx.getType())
                 && tx.getAmount() != null && tx.getAmount().doubleValue() > 300) score += 15;

        // RÃ¨gle 3 : Transaction hors heures
        if (tx.getTimestamp() != null) {
            int hour = tx.getTimestamp().atZone(java.time.ZoneOffset.UTC).getHour();
            if (hour < 6 || hour > 22) score += 15;
        }

        return Math.min(score, 100);
    }
}
```

**Concepts clÃ©s dÃ©montrÃ©s :**

- **`@KafkaListener`** â€” Annotation Spring Kafka qui remplace le poll loop manuel
- **`ConsumerRecord`** â€” Fournit l'accÃ¨s Ã  la clÃ©, valeur, partition, offset
- **Collections thread-safe** â€” `CopyOnWriteArrayList`, `AtomicLong` pour l'accÃ¨s concurrent
- **Auto-commit** â€” Les offsets sont commitÃ©s automatiquement toutes les 5 secondes par Spring Kafka

### Ã‰tape 7 : ContrÃ´leur REST (`controller/FraudController.java`)

```java
@RestController
@RequestMapping("/api/v1")
public class FraudController {

    private final FraudDetectionService service;

    public FraudController(FraudDetectionService service) {
        this.service = service;
    }

    @GetMapping("/alerts")
    public ResponseEntity<List<FraudAlert>> alerts() {
        return ResponseEntity.ok(service.getAlerts());
    }

    @GetMapping("/stats")
    public ResponseEntity<FraudMetrics> stats() {
        return ResponseEntity.ok(service.getMetrics());
    }
}
```

### Ã‰tape 8 : Classe principale Spring Boot

```java
@SpringBootApplication
public class FraudConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(FraudConsumerApplication.class, args);
    }
}
```

---

## ğŸš€ DÃ©ploiement

### DÃ©veloppement Local

#### 1. DÃ©marrer Kafka (si pas dÃ©jÃ  fait)

```bash
cd ../../module-01-cluster
docker compose up -d
```

#### 2. Produire des messages (Module 02)

Lancez l'API Producer du Module 02 et envoyez des transactions via Swagger.

#### 3. DÃ©marrer le Consumer

```bash
cd java
mvn spring-boot:run
```

#### 4. Observer les logs

```text
INFO  FraudDetectionService : Transaction TX-001 | Client: CUST-001 | 250.00 EUR | Risque: 5/100 (Low) | P0:O42
WARN  FraudDetectionService : ğŸš¨ ALERTE FRAUDE: TX-002 | Score: 60 | Montant Ã©levÃ©: 15000.00EUR
```

#### 5. VÃ©rifier via l'API

- `GET http://localhost:8080/api/v1/alerts` â€” Toutes les alertes fraude
- `GET http://localhost:8080/api/v1/stats` â€” MÃ©triques du consumer
- `GET http://localhost:8080/actuator/health` â€” Health check

### Docker

```bash
cd java
docker build -t ebanking-fraud-consumer-java .
docker run -p 8080:8080 \
  -e KAFKA_BOOTSTRAP_SERVERS=host.docker.internal:9092 \
  ebanking-fraud-consumer-java
```

### OpenShift Sandbox â€” Option A : Build S2I Binaire

> **ğŸ¯ Objectif** : Ce dÃ©ploiement valide les concepts fondamentaux du **Consumer Kafka** dans un environnement cloud :
> - **@KafkaListener** : le consumer reÃ§oit les messages via le listener container de Spring Kafka
> - **Auto-commit** : les offsets sont commitÃ©s automatiquement toutes les 5 secondes
> - **Partition assignment** : le consumer reÃ§oit les 6 partitions du topic
> - **Health check** : l'API expose l'Ã©tat du consumer via `/actuator/health`

#### 1. Build et DÃ©ploiement

```bash
cd module-03-consumer/lab-1.3a-consumer-basic/java

# CrÃ©er le BuildConfig
oc new-build java:17 --binary=true --name=ebanking-fraud-consumer-java

# Build depuis le source local
oc start-build ebanking-fraud-consumer-java --from-dir=. --follow

# DÃ©ployer
oc new-app ebanking-fraud-consumer-java
```

#### 2. Configurer les variables d'environnement

```bash
oc set env deployment/ebanking-fraud-consumer-java \
  SERVER_PORT=8080 \
  KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092 \
  KAFKA_TOPIC=banking.transactions
```

#### 3. CrÃ©er la route Edge

```bash
oc create route edge ebanking-fraud-consumer-java-secure \
  --service=ebanking-fraud-consumer-java --port=8080-tcp
```

#### 4. VÃ©rifier le dÃ©ploiement

```bash
# Obtenir l'URL publique
URL=$(oc get route ebanking-fraud-consumer-java-secure -o jsonpath='{.spec.host}')

# Health check
curl -k "https://$URL/actuator/health"

# MÃ©triques du consumer
curl -k -s "https://$URL/api/v1/stats"

# Alertes fraude
curl -k -s "https://$URL/api/v1/alerts"
```

#### 5. âœ… CritÃ¨res de succÃ¨s

```bash
# Pod en cours d'exÃ©cution ?
oc get pod -l deployment=ebanking-fraud-consumer-java
# Attendu : STATUS=Running, READY=1/1

# Consumer actif ?
curl -k -s "https://$URL/actuator/health"
# Attendu : {"status":"UP"}
```

#### 6. Script automatisÃ©

```bash
# Bash
./scripts/bash/deploy-and-test-1.3a-java.sh

# PowerShell
.\scripts\powershell\deploy-and-test-1.3a-java.ps1
```

---

## ğŸ§ª Tests

### ScÃ©narios de test

```bash
URL=$(oc get route ebanking-fraud-consumer-java-secure -o jsonpath='{.spec.host}')

# 1. Health check
curl -k -s "https://$URL/actuator/health"

# 2. VÃ©rifier les stats (messagesConsumed doit augmenter)
curl -k -s "https://$URL/api/v1/stats"

# 3. VÃ©rifier les alertes fraude (montants Ã©levÃ©s dÃ©clenchent des alertes)
curl -k -s "https://$URL/api/v1/alerts"
```

---

## ğŸ“‹ Endpoints API

| MÃ©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| `GET` | `/api/v1/alerts` | Toutes les alertes fraude dÃ©tectÃ©es |
| `GET` | `/api/v1/stats` | MÃ©triques du consumer (messages consommÃ©s, alertes, erreurs) |
| `GET` | `/actuator/health` | Health check |

---

## ğŸ¯ Concepts ClÃ©s ExpliquÃ©s

### Spring Kafka vs Confluent.Kafka (.NET)

| Aspect | Java (Spring Kafka) | .NET (Confluent.Kafka) |
| ------ | ------------------- | ---------------------- |
| **Configuration consumer** | `@KafkaListener` annotation | `BackgroundService` + poll loop |
| **DÃ©sÃ©rialisation** | Jackson `ObjectMapper` | `System.Text.Json` |
| **Thread safety** | `AtomicLong`, `CopyOnWriteArrayList` | `Interlocked`, `ConcurrentBag` |
| **Configuration** | `application.properties` | `appsettings.json` + `ConsumerConfig` |
| **Health check** | Spring Actuator `/actuator/health` | Custom `/api/FraudDetection/health` |
| **Auto-commit** | `enable-auto-commit=true` (dÃ©faut) | `EnableAutoCommit = true` |

### RÃ¨gles de Scoring de Risque

| RÃ¨gle | Condition | Score ajoutÃ© |
| ----- | --------- | ------------ |
| Montant Ã©levÃ© | `amount > 10 000` | +40 |
| Montant notable | `amount > 5 000` | +20 |
| Virement international | `type = InternationalTransfer` | +30 |
| Retrait Ã©levÃ© | `type = Withdrawal && amount > 300` | +15 |
| Hors heures | `hour < 6 ou hour > 22` | +15 |

### Niveaux de Risque

| Score | Niveau | Action |
| ----- | ------ | ------ |
| 0-24 | Low | Aucune action |
| 25-49 | Medium | Alerte crÃ©Ã©e |
| 50-74 | High | Alerte + revue requise |
| 75-100 | Critical | Alerte + blocage immÃ©diat |

---

## ğŸ”§ Troubleshooting

| SymptÃ´me | Cause probable | Solution |
| -------- | -------------- | -------- |
| Aucun message consommÃ© | Mauvais bootstrap servers ou topic | VÃ©rifier les variables `KAFKA_BOOTSTRAP_SERVERS` et `KAFKA_TOPIC` |
| Health retourne DOWN | Consumer non connectÃ© Ã  Kafka | VÃ©rifier que Kafka est dÃ©marrÃ© et accessible |
| `messagesConsumed` reste Ã  0 | Pas de messages dans le topic | Envoyer des transactions via l'API Producer |
| Erreurs de dÃ©sÃ©rialisation | Format JSON incompatible | VÃ©rifier que le producer envoie le bon schÃ©ma JSON |
| Pod CrashLoopBackOff | Variables d'environnement manquantes | VÃ©rifier : `oc set env deployment/ebanking-fraud-consumer-java --list` |

---

## âœ… Validation

- [ ] Le consumer dÃ©marre et se connecte Ã  Kafka
- [ ] Les messages sont consommÃ©s depuis `banking.transactions`
- [ ] Le score de risque est calculÃ© pour chaque transaction
- [ ] Des alertes sont crÃ©Ã©es pour les transactions avec score >= 40
- [ ] `/api/v1/alerts` retourne les alertes fraude dÃ©tectÃ©es
- [ ] `/api/v1/stats` montre `messagesConsumed > 0`
- [ ] `/actuator/health` retourne `UP`
- [ ] L'auto-commit est activÃ© (offsets commitÃ©s toutes les 5s)

---

## ğŸ Ã‰tape Suivante

Passez au **[LAB 1.3B (Java) : Consumer Group â€” Calcul de Solde](../../lab-1.3b-consumer-group/java/README.md)** pour apprendre les consumer groups, l'assignation de partitions et le rebalancing.
