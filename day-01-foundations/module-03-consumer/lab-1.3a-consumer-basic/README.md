# LAB 1.3A : API Consumer Basique ‚Äî D√©tection de Fraude E-Banking

## ‚è±Ô∏è Dur√©e estim√©e : 45 minutes

## üè¶ Contexte E-Banking

Dans une banque, chaque transaction publi√©e par l'API Producer (Module 02) doit √™tre **analys√©e en temps r√©el** par un service de d√©tection de fraude. Ce service consomme les messages du topic `banking.transactions`, √©value un **score de risque** pour chaque transaction, et d√©clenche des alertes si le risque est √©lev√©.

### Architecture : Producer ‚Üí Kafka ‚Üí Consumer Fraude

```mermaid
flowchart LR
    subgraph Producer["üì§ Module 02 (d√©j√† fait)"]
        API["üöÄ E-Banking API"]
    end

    subgraph Kafka["üî• Kafka"]
        T["üìã banking.transactions"]
    end

    subgraph Consumer["üì• Ce LAB"]
        FD["üîç Fraud Detection API"]
        RS["‚öôÔ∏è KafkaConsumerService"]
        SC["üìä Risk Scoring Engine"]
    end

    API --> T
    T --> RS
    RS --> SC
    SC --> FD

    style Producer fill:#e8f5e8,stroke:#388e3c
    style Kafka fill:#fff3e0,stroke:#f57c00
    style Consumer fill:#e3f2fd,stroke:#1976d2
```

### S√©quence : D√©tection de Fraude en Temps R√©el

```mermaid
sequenceDiagram
    participant Kafka as üî• Kafka
    participant Worker as ‚öôÔ∏è ConsumerWorker (BackgroundService)
    participant Score as üìä Risk Scoring
    participant DB as üíæ In-Memory Store
    participant API as üåê Swagger API

    loop Poll Loop continu
        Worker->>Kafka: Consume(cancellationToken)
        Kafka-->>Worker: ConsumeResult {Key: CUST-001, Value: transaction JSON}

        Worker->>Worker: D√©s√©rialiser JSON ‚Üí Transaction
        Worker->>Score: CalculateRiskScore(transaction)

        alt Montant > 10000‚Ç¨ ou pays √† risque
            Score-->>Worker: Score: 85/100 üî¥ HIGH RISK
            Worker->>Worker: Logger alerte fraude
        else Transaction normale
            Score-->>Worker: Score: 12/100 üü¢ LOW RISK
        end

        Worker->>DB: Stocker r√©sultat (TransactionId, Score, Status)
        Note over Worker: Auto-commit toutes les 5 secondes
    end

    API->>DB: GET /api/fraud/alerts
    DB-->>API: Liste des transactions √† haut risque
```

### Sc√©narios de Scoring Fraude

| Sc√©nario | Montant | Crit√®res | Score | Action |
| -------- | ------- | -------- | ----- | ------ |
| **Virement normal** | 250‚Ç¨ | M√™me pays, client connu | 5/100 | ‚úÖ Approuv√© |
| **Paiement carte** | 80‚Ç¨ | Commerce local | 8/100 | ‚úÖ Approuv√© |
| **Gros virement** | 15 000‚Ç¨ | Montant √©lev√© | 45/100 | ‚ö†Ô∏è Revue manuelle |
| **Virement international** | 9 000‚Ç¨ | Pays √† risque, nouveau b√©n√©ficiaire | 78/100 | üî¥ Alerte |
| **Transactions rapides** | 3 √ó 500‚Ç¨ | 3 transactions en 1 minute | 85/100 | üî¥ Blocage |
| **Retrait DAB √©tranger** | 400‚Ç¨ | Pays diff√©rent du dernier paiement | 65/100 | ‚ö†Ô∏è SMS de v√©rification |

---

## üéØ Objectifs

√Ä la fin de ce lab, vous serez capable de :

1. Cr√©er un **Consumer Kafka** dans une API Web ASP.NET Core
2. Impl√©menter un **BackgroundService** pour le polling loop continu
3. Comprendre l'**auto-commit** des offsets (comportement et risques)
4. G√©rer les **handlers de partitions** (assigned, revoked, lost)
5. D√©s√©rialiser les **transactions JSON** produites par le Module 02
6. Exposer des **m√©triques** via des endpoints API (Swagger)

---

## üì¶ Ce que vous allez construire

| Composant | R√¥le |
| --------- | ---- |
| `Transaction.cs` | Mod√®le partag√© (identique au Module 02) |
| `FraudAlert.cs` | Mod√®le de r√©sultat de scoring |
| `KafkaConsumerService.cs` | BackgroundService avec poll loop |
| `FraudDetectionController.cs` | Endpoints API : alertes, stats, health |
| `Program.cs` | Configuration ASP.NET Core + Kafka Consumer |
| `appsettings.json` | Configuration Kafka et scoring |

### Architecture des Composants (Code)

```mermaid
flowchart TB
    subgraph API["üåê ASP.NET Core Web API"]
        Ctrl["FraudDetectionController"]
        Swagger["üß™ Swagger/OpenAPI"]
    end

    subgraph Background["‚öôÔ∏è BackgroundService"]
        Worker["KafkaConsumerService"]
        Consumer["Confluent.Kafka Consumer"]
    end

    subgraph Business["üìä Logique M√©tier"]
        Scoring["Risk Scoring Engine"]
        Store["In-Memory Alert Store"]
    end

    Swagger --> Ctrl
    Ctrl --> Store
    Worker --> Consumer
    Consumer --> Worker
    Worker --> Scoring
    Scoring --> Store

    style API fill:#e3f2fd,stroke:#1976d2
    style Background fill:#e8f5e8,stroke:#388e3c
    style Business fill:#fff3e0,stroke:#f57c00
```

---

## üîß Ce que vous allez apprendre

### Le Poll Loop

```mermaid
sequenceDiagram
    participant App as üöÄ Application
    participant Consumer as üì• Kafka Consumer
    participant Broker as üî• Kafka Broker
    participant Offsets as üíæ __consumer_offsets

    App->>Consumer: Subscribe("banking.transactions")
    Consumer->>Broker: JoinGroup(group: "fraud-detection-service")
    Broker-->>Consumer: Partitions assign√©es: [0, 1, 2, 3, 4, 5]

    loop Polling continu
        App->>Consumer: Consume(timeout: 100ms)
        Consumer->>Broker: FetchRequest(partition, offset)
        Broker-->>Consumer: Messages batch
        Consumer-->>App: ConsumeResult

        App->>App: ProcessMessage(result)
    end

    Note over Consumer,Offsets: Auto-commit toutes les 5 secondes
    Consumer->>Offsets: CommitOffsets({P0: 42, P1: 18, P2: 31...})
```

### Auto-Commit : Comportement et Risques

```mermaid
sequenceDiagram
    participant Consumer as üì• Consumer
    participant Broker as üî• Kafka
    participant App as ‚öôÔ∏è Traitement

    Consumer->>Broker: Poll ‚Üí 100 messages
    Consumer->>App: Message 1..60 trait√©s

    Note over Consumer: ‚è∞ T=5s : Auto-commit d√©clench√©
    Consumer->>Broker: Commit offset = 100 (tous les 100 messages)

    Consumer->>App: Message 61..80 en cours de traitement

    Note over App: üí• CRASH √† T=7s (messages 81-100 pas encore trait√©s)

    Consumer->>Broker: Red√©marrage ‚Üí Reprend depuis offset 100
    Note over Consumer: ‚ö†Ô∏è Messages 81-100 PERDUS (d√©j√† commit√©s mais pas trait√©s)
```

> **‚ö†Ô∏è Important** : L'auto-commit est acceptable pour la d√©tection de fraude car rater une transaction n'a pas d'impact financier direct. Pour l'audit r√©glementaire (LAB 1.3C), nous utiliserons le manual commit.

---

## üöÄ Pr√©requis

### Topic Kafka

Le topic `banking.transactions` doit exister (cr√©√© dans le Module 02) :

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions

# Si le topic n'existe pas, cr√©ez-le :
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions \
  --partitions 6 \
  --replication-factor 1
```

### Messages dans le topic

Lancez l'API Producer du Module 02 et envoyez quelques transactions via Swagger pour avoir des messages √† consommer.

---

## üìù Instructions Pas √† Pas

### √âtape 1 : Cr√©er le projet API Web

#### Option VS Code

```bash
mkdir lab-1.3a-consumer-basic
cd lab-1.3a-consumer-basic
mkdir EBankingFraudDetectionAPI
cd EBankingFraudDetectionAPI
dotnet new webapi -n EBankingFraudDetectionAPI --framework net8.0
cd EBankingFraudDetectionAPI
dotnet add package Confluent.Kafka --version 2.3.0
dotnet add package Swashbuckle.AspNetCore --version 6.5.0
```

#### Option Visual Studio 2022

1. **Fichier** ‚Üí **Nouveau** ‚Üí **Projet**
2. S√©lectionner **API Web ASP.NET Core**
3. Nom : `EBankingFraudDetectionAPI`, Framework : **.NET 8.0**
4. Clic droit projet ‚Üí **G√©rer les packages NuGet** :
   - `Confluent.Kafka` version **2.3.0**
   - `Swashbuckle.AspNetCore` version **6.5.0**

---

### √âtape 2 : Cr√©er les mod√®les

#### `Models/Transaction.cs` (identique au Module 02)

```csharp
using System.Text.Json.Serialization;

namespace EBankingFraudDetectionAPI.Models;

public class Transaction
{
    [JsonPropertyName("transactionId")]
    public string TransactionId { get; set; } = string.Empty;

    [JsonPropertyName("fromAccount")]
    public string FromAccount { get; set; } = string.Empty;

    [JsonPropertyName("toAccount")]
    public string ToAccount { get; set; } = string.Empty;

    [JsonPropertyName("amount")]
    public decimal Amount { get; set; }

    [JsonPropertyName("currency")]
    public string Currency { get; set; } = "EUR";

    [JsonPropertyName("type")]
    public string Type { get; set; } = "Transfer";

    [JsonPropertyName("customerId")]
    public string CustomerId { get; set; } = string.Empty;

    [JsonPropertyName("description")]
    public string Description { get; set; } = string.Empty;

    [JsonPropertyName("timestamp")]
    public DateTime Timestamp { get; set; }

    [JsonPropertyName("riskScore")]
    public int RiskScore { get; set; }
}
```

#### `Models/FraudAlert.cs`

```csharp
namespace EBankingFraudDetectionAPI.Models;

public class FraudAlert
{
    public string TransactionId { get; set; } = string.Empty;
    public string CustomerId { get; set; } = string.Empty;
    public decimal Amount { get; set; }
    public string Currency { get; set; } = "EUR";
    public string Type { get; set; } = string.Empty;
    public int RiskScore { get; set; }
    public string RiskLevel { get; set; } = "Low"; // Low, Medium, High, Critical
    public string Reason { get; set; } = string.Empty;
    public DateTime DetectedAt { get; set; } = DateTime.UtcNow;

    // M√©tadonn√©es Kafka
    public int KafkaPartition { get; set; }
    public long KafkaOffset { get; set; }
}

public class ConsumerMetrics
{
    public long MessagesConsumed { get; set; }
    public long FraudAlertsGenerated { get; set; }
    public long ProcessingErrors { get; set; }
    public double AverageRiskScore { get; set; }
    public string ConsumerGroupId { get; set; } = string.Empty;
    public string ConsumerStatus { get; set; } = "Unknown";
    public Dictionary<int, long> PartitionOffsets { get; set; } = new();
    public DateTime StartedAt { get; set; }
    public DateTime LastMessageAt { get; set; }
}
```

---

### √âtape 3 : Cr√©er le service Consumer (BackgroundService)

#### `Services/KafkaConsumerService.cs`

```csharp
using System.Collections.Concurrent;
using System.Text.Json;
using Confluent.Kafka;
using EBankingFraudDetectionAPI.Models;

namespace EBankingFraudDetectionAPI.Services;

public class KafkaConsumerService : BackgroundService
{
    private readonly ILogger<KafkaConsumerService> _logger;
    private readonly IConfiguration _configuration;

    // Stockage en m√©moire des alertes et m√©triques
    private readonly ConcurrentBag<FraudAlert> _alerts = new();
    private readonly ConcurrentDictionary<int, long> _partitionOffsets = new();
    private long _messagesConsumed;
    private long _fraudAlerts;
    private long _processingErrors;
    private double _totalRiskScore;
    private DateTime _startedAt;
    private DateTime _lastMessageAt;
    private string _status = "Starting";

    public KafkaConsumerService(
        ILogger<KafkaConsumerService> logger,
        IConfiguration configuration)
    {
        _logger = logger;
        _configuration = configuration;
    }

    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        _startedAt = DateTime.UtcNow;
        _status = "Running";

        var config = new ConsumerConfig
        {
            BootstrapServers = _configuration["Kafka:BootstrapServers"] ?? "localhost:9092",
            GroupId = _configuration["Kafka:GroupId"] ?? "fraud-detection-service",
            ClientId = $"fraud-detector-{Environment.MachineName}-{Guid.NewGuid():N}",
            AutoOffsetReset = AutoOffsetReset.Earliest,
            EnableAutoCommit = true,
            AutoCommitIntervalMs = 5000,
            SessionTimeoutMs = 10000,
            HeartbeatIntervalMs = 3000,
            MaxPollIntervalMs = 300000,
            PartitionAssignmentStrategy = PartitionAssignmentStrategy.CooperativeSticky
        };

        var topic = _configuration["Kafka:Topic"] ?? "banking.transactions";

        _logger.LogInformation(
            "Starting Fraud Detection Consumer. Group: {Group}, Topic: {Topic}, Servers: {Servers}",
            config.GroupId, topic, config.BootstrapServers);

        using var consumer = new ConsumerBuilder<string, string>(config)
            .SetErrorHandler((_, e) =>
            {
                _logger.LogError("Consumer error: Code={Code}, Reason={Reason}, IsFatal={IsFatal}",
                    e.Code, e.Reason, e.IsFatal);
                if (e.IsFatal) _status = "Fatal Error";
            })
            .SetPartitionsAssignedHandler((c, partitions) =>
            {
                _logger.LogInformation("‚úÖ Partitions assigned: {Partitions}",
                    string.Join(", ", partitions.Select(p => $"[{p.Partition.Value}]")));
                _status = "Consuming";
            })
            .SetPartitionsRevokedHandler((c, partitions) =>
            {
                _logger.LogWarning("‚ö†Ô∏è Partitions revoked: {Partitions}",
                    string.Join(", ", partitions.Select(p => $"[{p.Partition.Value}]")));
                _status = "Rebalancing";
            })
            .SetPartitionsLostHandler((c, partitions) =>
            {
                _logger.LogError("‚ùå Partitions lost: {Partitions}",
                    string.Join(", ", partitions.Select(p => $"[{p.Partition.Value}]")));
                _status = "Partitions Lost";
            })
            .Build();

        consumer.Subscribe(topic);

        try
        {
            while (!stoppingToken.IsCancellationRequested)
            {
                try
                {
                    var consumeResult = consumer.Consume(stoppingToken);
                    if (consumeResult == null) continue;

                    await ProcessMessageAsync(consumeResult);
                }
                catch (ConsumeException ex)
                {
                    _logger.LogError(ex, "Consume error: {Reason}", ex.Error.Reason);
                    Interlocked.Increment(ref _processingErrors);
                }
            }
        }
        catch (OperationCanceledException)
        {
            _logger.LogInformation("Consumer shutdown requested");
        }
        finally
        {
            _status = "Stopped";
            consumer.Close();
            _logger.LogInformation("Consumer closed gracefully");
        }
    }

    private async Task ProcessMessageAsync(ConsumeResult<string, string> result)
    {
        try
        {
            // D√©s√©rialiser la transaction
            var transaction = JsonSerializer.Deserialize<Transaction>(result.Message.Value);
            if (transaction == null)
            {
                _logger.LogWarning("Failed to deserialize message at P{Partition}:O{Offset}",
                    result.Partition.Value, result.Offset.Value);
                Interlocked.Increment(ref _processingErrors);
                return;
            }

            // Calculer le score de risque
            var (riskScore, riskLevel, reason) = CalculateRiskScore(transaction);

            // Mettre √† jour les m√©triques
            Interlocked.Increment(ref _messagesConsumed);
            _totalRiskScore += riskScore;
            _lastMessageAt = DateTime.UtcNow;
            _partitionOffsets[result.Partition.Value] = result.Offset.Value;

            _logger.LogInformation(
                "üì¶ Transaction {TxId} | Customer: {Customer} | {Amount} {Currency} | Risk: {Score}/100 ({Level}) | P{Partition}:O{Offset}",
                transaction.TransactionId, transaction.CustomerId,
                transaction.Amount, transaction.Currency,
                riskScore, riskLevel,
                result.Partition.Value, result.Offset.Value);

            // Cr√©er une alerte si risque √©lev√©
            if (riskScore >= 40)
            {
                var alert = new FraudAlert
                {
                    TransactionId = transaction.TransactionId,
                    CustomerId = transaction.CustomerId,
                    Amount = transaction.Amount,
                    Currency = transaction.Currency,
                    Type = transaction.Type,
                    RiskScore = riskScore,
                    RiskLevel = riskLevel,
                    Reason = reason,
                    KafkaPartition = result.Partition.Value,
                    KafkaOffset = result.Offset.Value
                };

                _alerts.Add(alert);
                Interlocked.Increment(ref _fraudAlerts);

                _logger.LogWarning(
                    "üö® FRAUD ALERT: {TxId} | {Customer} | {Amount}{Currency} | Score: {Score} | {Reason}",
                    transaction.TransactionId, transaction.CustomerId,
                    transaction.Amount, transaction.Currency,
                    riskScore, reason);
            }

            // Simuler temps de traitement (scoring ML en production)
            await Task.Delay(50);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error processing message at P{Partition}:O{Offset}",
                result.Partition.Value, result.Offset.Value);
            Interlocked.Increment(ref _processingErrors);
        }
    }

    private (int score, string level, string reason) CalculateRiskScore(Transaction tx)
    {
        int score = 0;
        var reasons = new List<string>();

        // R√®gle 1 : Montant √©lev√©
        if (tx.Amount > 10000)
        {
            score += 40;
            reasons.Add($"Montant √©lev√©: {tx.Amount}{tx.Currency}");
        }
        else if (tx.Amount > 5000)
        {
            score += 20;
            reasons.Add($"Montant notable: {tx.Amount}{tx.Currency}");
        }

        // R√®gle 2 : Type de transaction √† risque
        if (tx.Type == "InternationalTransfer")
        {
            score += 30;
            reasons.Add("Virement international");
        }
        else if (tx.Type == "Withdrawal" && tx.Amount > 300)
        {
            score += 15;
            reasons.Add("Retrait √©lev√©");
        }

        // R√®gle 3 : Transaction hors heures
        if (tx.Timestamp.Hour < 6 || tx.Timestamp.Hour > 22)
        {
            score += 15;
            reasons.Add("Hors heures ouvr√©es");
        }

        // R√®gle 4 : Score de risque d√©j√† √©lev√© (venant du producer)
        if (tx.RiskScore > 50)
        {
            score += 20;
            reasons.Add($"Risque producer √©lev√©: {tx.RiskScore}");
        }

        score = Math.Min(score, 100);

        var level = score switch
        {
            >= 75 => "Critical",
            >= 50 => "High",
            >= 25 => "Medium",
            _ => "Low"
        };

        return (score, level, string.Join(" | ", reasons.DefaultIfEmpty("Aucun facteur de risque")));
    }

    // M√©thodes publiques pour l'API
    public IReadOnlyList<FraudAlert> GetAlerts() => _alerts.ToList().AsReadOnly();

    public IReadOnlyList<FraudAlert> GetHighRiskAlerts() =>
        _alerts.Where(a => a.RiskScore >= 50).OrderByDescending(a => a.RiskScore).ToList().AsReadOnly();

    public ConsumerMetrics GetMetrics() => new()
    {
        MessagesConsumed = Interlocked.Read(ref _messagesConsumed),
        FraudAlertsGenerated = Interlocked.Read(ref _fraudAlerts),
        ProcessingErrors = Interlocked.Read(ref _processingErrors),
        AverageRiskScore = _messagesConsumed > 0 ? _totalRiskScore / _messagesConsumed : 0,
        ConsumerGroupId = _configuration["Kafka:GroupId"] ?? "fraud-detection-service",
        ConsumerStatus = _status,
        PartitionOffsets = new Dictionary<int, long>(_partitionOffsets),
        StartedAt = _startedAt,
        LastMessageAt = _lastMessageAt
    };
}
```

---

### √âtape 4 : Cr√©er le contr√¥leur API

#### `Controllers/FraudDetectionController.cs`

```csharp
using Microsoft.AspNetCore.Mvc;
using EBankingFraudDetectionAPI.Services;

namespace EBankingFraudDetectionAPI.Controllers;

[ApiController]
[Route("api/[controller]")]
public class FraudDetectionController : ControllerBase
{
    private readonly KafkaConsumerService _consumerService;
    private readonly ILogger<FraudDetectionController> _logger;

    public FraudDetectionController(
        KafkaConsumerService consumerService,
        ILogger<FraudDetectionController> logger)
    {
        _consumerService = consumerService;
        _logger = logger;
    }

    /// <summary>
    /// R√©cup√®re toutes les alertes fraude d√©tect√©es
    /// </summary>
    [HttpGet("alerts")]
    [ProducesResponseType(StatusCodes.Status200OK)]
    public IActionResult GetAlerts()
    {
        var alerts = _consumerService.GetAlerts();
        return Ok(new
        {
            count = alerts.Count,
            alerts
        });
    }

    /// <summary>
    /// R√©cup√®re les alertes √† haut risque (score >= 50)
    /// </summary>
    [HttpGet("alerts/high-risk")]
    [ProducesResponseType(StatusCodes.Status200OK)]
    public IActionResult GetHighRiskAlerts()
    {
        var alerts = _consumerService.GetHighRiskAlerts();
        return Ok(new
        {
            count = alerts.Count,
            alerts
        });
    }

    /// <summary>
    /// R√©cup√®re les m√©triques du consumer Kafka
    /// </summary>
    [HttpGet("metrics")]
    [ProducesResponseType(StatusCodes.Status200OK)]
    public IActionResult GetMetrics()
    {
        var metrics = _consumerService.GetMetrics();
        return Ok(metrics);
    }

    /// <summary>
    /// Health check du service de d√©tection de fraude
    /// </summary>
    [HttpGet("health")]
    [ProducesResponseType(StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status503ServiceUnavailable)]
    public IActionResult GetHealth()
    {
        var metrics = _consumerService.GetMetrics();

        var isHealthy = metrics.ConsumerStatus == "Consuming" ||
                        metrics.ConsumerStatus == "Running";

        var health = new
        {
            status = isHealthy ? "Healthy" : "Degraded",
            consumerStatus = metrics.ConsumerStatus,
            messagesConsumed = metrics.MessagesConsumed,
            lastMessageAt = metrics.LastMessageAt,
            uptime = DateTime.UtcNow - metrics.StartedAt
        };

        return isHealthy ? Ok(health) : StatusCode(503, health);
    }
}
```

---

### √âtape 5 : Configurer l'application

#### `appsettings.json`

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "EBankingFraudDetectionAPI": "Information"
    }
  },
  "Kafka": {
    "BootstrapServers": "localhost:9092",
    "GroupId": "fraud-detection-service",
    "Topic": "banking.transactions"
  },
  "AllowedHosts": "*"
}
```

#### `Program.cs`

```csharp
using EBankingFraudDetectionAPI.Services;

var builder = WebApplication.CreateBuilder(args);

// Enregistrer le consumer comme BackgroundService (singleton)
builder.Services.AddSingleton<KafkaConsumerService>();
builder.Services.AddHostedService(sp => sp.GetRequiredService<KafkaConsumerService>());

// Contr√¥leurs + Swagger
builder.Services.AddControllers();
builder.Services.AddEndpointsApiExplorer();
builder.Services.AddSwaggerGen(c =>
{
    c.SwaggerDoc("v1", new()
    {
        Title = "E-Banking Fraud Detection API",
        Version = "v1",
        Description = "Consumer Kafka pour la d√©tection de fraude en temps r√©el sur les transactions bancaires"
    });
});

var app = builder.Build();

app.UseSwagger();
app.UseSwaggerUI(c =>
{
    c.SwaggerEndpoint("/swagger/v1/swagger.json", "Fraud Detection API v1");
    c.RoutePrefix = "swagger";
});

app.MapControllers();

app.Run();
```

#### `EBankingFraudDetectionAPI.csproj`

```xml
<Project Sdk="Microsoft.NET.Sdk.Web">
  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
  </PropertyGroup>
  <ItemGroup>
    <PackageReference Include="Confluent.Kafka" Version="2.3.0" />
    <PackageReference Include="Swashbuckle.AspNetCore" Version="6.5.0" />
  </ItemGroup>
</Project>
```

---

### √âtape 6 : Ex√©cuter et tester

#### 1. D√©marrer Kafka (si pas d√©j√† fait)

```bash
cd ../../module-01-cluster
docker compose up -d
```

#### 2. Produire des messages (Module 02)

Lancez l'API Producer du Module 02 et envoyez des transactions via Swagger (`https://localhost:5001/swagger`).

#### 3. D√©marrer le Consumer

```bash
cd EBankingFraudDetectionAPI
dotnet run
```

#### 4. Observer les logs

```text
info: EBankingFraudDetectionAPI.Services.KafkaConsumerService
      Starting Fraud Detection Consumer. Group: fraud-detection-service, Topic: banking.transactions
info: EBankingFraudDetectionAPI.Services.KafkaConsumerService
      ‚úÖ Partitions assigned: [0], [1], [2], [3], [4], [5]
info: EBankingFraudDetectionAPI.Services.KafkaConsumerService
      üì¶ Transaction TX-001 | Customer: CUST-001 | 250 EUR | Risk: 5/100 (Low) | P2:O0
info: EBankingFraudDetectionAPI.Services.KafkaConsumerService
      üì¶ Transaction TX-002 | Customer: CUST-002 | 15000 EUR | Risk: 60/100 (High) | P5:O0
warn: EBankingFraudDetectionAPI.Services.KafkaConsumerService
      üö® FRAUD ALERT: TX-002 | CUST-002 | 15000EUR | Score: 60 | Montant √©lev√©: 15000EUR
```

#### 6. V√©rifier via l'API (Swagger)

Ouvrez `https://localhost:5001/swagger` (ou `http://localhost:5000/swagger`) :
- `GET /api/FraudDetection/alerts` : Liste toutes les alertes.
- `GET /api/FraudDetection/metrics` : Statistiques de consommation et offsets.

---

## ‚òÅÔ∏è Alternative : D√©ploiement sur OpenShift Sandbox

Si vous utilisez l'environnement **OpenShift Sandbox**, suivez ces √©tapes pour d√©ployer et exposer votre Consumer publiquement.

### 1. Pr√©parer le Build et le D√©ploiement

```bash
# Se placer dans le dossier du projet
cd EBankingFraudDetectionAPI

# Cr√©er une build binaire pour .NET
oc new-build dotnet:8.0-ubi8 --binary=true --name=ebanking-fraud-detection-api

# Lancer la build en envoyant le dossier courant
oc start-build ebanking-fraud-detection-api --from-dir=. --follow

# Cr√©er l'application
oc new-app ebanking-fraud-detection-api
```

### 2. Configurer les variables d'environnement

Le Consumer doit savoir o√π se trouve Kafka (interne au cluster) et quel groupe utiliser.

```bash
oc set env deployment/ebanking-fraud-detection-api \
  Kafka__BootstrapServers=kafka-svc:9092 \
  Kafka__GroupId=fraud-detection-service \
  Kafka__Topic=banking.transactions \
  ASPNETCORE_URLS=http://0.0.0.0:8080 \
  ASPNETCORE_ENVIRONMENT=Development
```

### 3. Exposer publiquement (Secure Edge Route)

```bash
oc create route edge ebanking-fraud-api-secure --service=ebanking-fraud-detection-api --port=8080-tcp
```

### 4. Tester l'API d√©ploy√©e

```bash
# Obtenir l'URL publique
URL=$(oc get route ebanking-fraud-api-secure -o jsonpath='{.spec.host}')
echo "https://$URL/swagger"

# Tester le Health Check
curl -k -i "https://$URL/api/FraudDetection/health"

# Voir les m√©triques de consommation
curl -k -s "https://$URL/api/FraudDetection/metrics"
```

### 5. Test de Bout-en-Bout (E2E)

1. Envoyez une transaction via l'**API Producer Resilient** (Lab 1.2c).
2. V√©rifiez imm√©diatement les **Logs** du Consumer :
   ```bash
   oc logs deployment/ebanking-fraud-detection-api -f
   ```
3. V√©rifiez l'apparition de l'alerte dans les m√©triques :
   ```bash
   curl -k -s "https://$URL/api/FraudDetection/alerts/high-risk"
   ```

---

## üèÜ Crit√®res de succ√®s
1. L'application d√©marre et affiche `‚úÖ Partitions assigned`.
2. Le `messagesConsumed` augmente quand vous envoyez des transactions.
3. Les transactions > 10,000‚Ç¨ g√©n√®rent une `üö® FRAUD ALERT` dans les logs et l'API.
4. Les offsets sont commit√©s automatiquement toutes les 5 secondes (visible dans les logs Kafka ou UI).

---

## üéØ Concepts Cl√©s Expliqu√©s

### S√©quence D√©taill√©e : Consumer Poll Loop (Code Expliqu√©)

```mermaid
sequenceDiagram
    participant Main as üöÄ Program.cs
    participant DI as üì¶ DI Container
    participant Worker as ‚öôÔ∏è KafkaConsumerService
    participant Builder as üîß ConsumerBuilder
    participant Consumer as üì• IConsumer
    participant Broker as üî• Kafka Broker
    participant Coord as üëë Group Coordinator

    Main->>DI: AddSingleton<KafkaConsumerService>()
    Main->>DI: AddHostedService(provider => ...)
    DI->>Worker: ExecuteAsync(stoppingToken)

    Worker->>Builder: new ConsumerBuilder(config)
    Builder->>Builder: SetErrorHandler, SetPartitionsAssignedHandler...
    Builder->>Consumer: .Build()

    Consumer->>Broker: Subscribe("banking.transactions")
    Consumer->>Coord: JoinGroup(groupId: "fraud-detection-service")
    Coord-->>Consumer: Assignment: [P0, P1, P2, P3, P4, P5]
    Note over Worker: Handler: "‚úÖ Partitions assigned"

    loop while !stoppingToken.IsCancellationRequested
        Consumer->>Broker: Consume(stoppingToken) ‚Üí FetchRequest
        Broker-->>Consumer: ConsumeResult {Key, Value, Partition, Offset}
        Worker->>Worker: Deserialize JSON ‚Üí Transaction
        Worker->>Worker: CalculateRiskScore(tx)
        Worker->>Worker: if score >= 40 ‚Üí cr√©er FraudAlert
        Worker->>Worker: Stocker m√©triques (thread-safe)
    end

    Note over Consumer: ‚è∞ Toutes les 5s: Auto-commit offsets
    Consumer->>Coord: CommitOffsets
```

### S√©quence : Rebalancing lors de l'Ajout d'un Consumer

```mermaid
sequenceDiagram
    participant C1 as üì• Consumer 1 (existant)
    participant Coord as üëë Group Coordinator
    participant C2 as üì• Consumer 2 (nouveau)

    Note over C1: Consomme P0-P5 (seul)

    C2->>Coord: JoinGroup("fraud-detection-service")
    Coord->>C1: Rebalance ‚Üí PartitionsRevoked [P0-P5]
    Note over C1: ‚ö†Ô∏è Handler: "Partitions revoked"
    Note over C1: PAUSE consommation

    Coord->>Coord: Recalculer assignation (CooperativeSticky)

    Coord->>C1: PartitionsAssigned [P0, P1, P2]
    Coord->>C2: PartitionsAssigned [P3, P4, P5]
    Note over C1: ‚úÖ Reprend P0-P2
    Note over C2: ‚úÖ Commence P3-P5
```

### Consumer Config : Impact sur le Comportement

| Param√®tre | Valeur | Impact E-Banking |
| --------- | ------ | ---------------- |
| `AutoOffsetReset = Earliest` | Lire depuis le d√©but | Analyse de l'historique des transactions |
| `EnableAutoCommit = true` | Commit automatique | Risque de rater une transaction lors d'un crash |
| `AutoCommitIntervalMs = 5000` | Commit toutes les 5s | Fen√™tre de perte max : 5 secondes de transactions |
| `SessionTimeoutMs = 10000` | 10s sans heartbeat = √©jection | D√©tection rapide de consumer mort |
| `CooperativeSticky` | Rebalancing incr√©mental | Continuit√© du scoring pendant les mises √† jour |

---

## üèãÔ∏è Exercices Pratiques

### Exercice 1 : Ajouter un compteur par type de transaction

Ajoutez un dictionnaire `ConcurrentDictionary<string, int>` pour compter les transactions par type (Transfer, CardPayment, Withdrawal...) et exposez-le via un nouveau endpoint `GET /api/frauddetection/stats/types`.

### Exercice 2 : Alerte sur transactions rapides

Modifiez `CalculateRiskScore` pour d√©tecter si un m√™me client a plus de 3 transactions en moins de 5 minutes (stockez les timestamps par customer).

### Exercice 3 : Endpoint pour r√©initialiser les alertes

Ajoutez un endpoint `DELETE /api/frauddetection/alerts` pour vider la liste des alertes (utile pour les tests).

---

## ‚úÖ Validation

- [ ] Le BackgroundService d√©marre automatiquement avec l'application
- [ ] Les partitions sont assign√©es au consumer (log `‚úÖ Partitions assigned`)
- [ ] Les transactions du Module 02 sont consomm√©es et logu√©es
- [ ] Le scoring de risque fonctionne (scores vari√©s selon les transactions)
- [ ] Les alertes √† haut risque apparaissent dans les logs (`üö® FRAUD ALERT`)
- [ ] Swagger fonctionne et expose les 4 endpoints
- [ ] Les m√©triques sont coh√©rentes (messagesConsumed, fraudAlerts)
- [ ] Le health check retourne `Healthy` quand le consumer est actif

---

## üîë Points √† Retenir

| Concept | Ce qu'il faut retenir |
| ------- | -------------------- |
| **BackgroundService** | Le consumer tourne en t√¢che de fond, ind√©pendant des requ√™tes HTTP |
| **Auto-commit** | Simple mais risque de perte si crash (OK pour fraude, pas pour audit) |
| **Singleton** | Le consumer est un singleton partag√© avec l'API pour exposer les m√©triques |
| **Poll Loop** | `Consume()` est bloquant avec timeout ‚Äî ne jamais bloquer le thread plus longtemps que `MaxPollIntervalMs` |
| **Partition Handlers** | Essentiels pour observer le rebalancing et initialiser/nettoyer des ressources |

---

## ‚û°Ô∏è Prochaine √âtape

üëâ **[LAB 1.3B : Consumer Group Scaling & Rebalancing ‚Äî Calcul de Solde](../lab-1.3b-consumer-group/README.md)**
