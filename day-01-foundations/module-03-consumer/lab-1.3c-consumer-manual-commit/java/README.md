# LAB 1.3C (Java) : Consumer avec Manual Commit ‚Äî Audit R√©glementaire E-Banking

## ‚è±Ô∏è Dur√©e estim√©e : 45 minutes

## üè¶ Contexte E-Banking

Dans le secteur bancaire, la **conformit√© r√©glementaire** (B√¢le III, RGPD, PSD2, AML) exige que **chaque transaction soit enregistr√©e** dans un journal d'audit. **Perdre une seule transaction** peut entra√Æner des sanctions de plusieurs millions d'euros. L'auto-commit du LAB 1.3A n'offre pas cette garantie ‚Äî il faut un **commit manuel** qui ne valide l'offset qu'**apr√®s** la persistance r√©ussie en base de donn√©es.

### Le Probl√®me : Auto-Commit et Perte de Donn√©es

```mermaid
sequenceDiagram
    participant Consumer as üì• Consumer (Auto-commit)
    participant Kafka as üî• Kafka
    participant DB as üíæ Base Audit

    Consumer->>Kafka: Poll ‚Üí 100 transactions
    Consumer->>DB: Persister tx 1..60 ‚úÖ

    Note over Consumer: ‚è∞ T=5s : Auto-commit ‚Üí offset = 100
    Consumer->>Kafka: Commit offset 100

    Consumer->>DB: Persister tx 61..80

    Note over Consumer: üí• CRASH!
    Note over DB: tx 81-100 jamais persist√©es!

    Consumer->>Kafka: Red√©marrage ‚Üí offset 100
    Note over Consumer: Reprend √† tx 101
    Note over DB: ‚ö†Ô∏è tx 81-100 PERDUES! Non-conformit√© r√©glementaire!
```

### La Solution : Manual Commit

```mermaid
sequenceDiagram
    participant Consumer as üì• Consumer (Manual commit)
    participant Kafka as üî• Kafka
    participant DB as üíæ Base Audit

    Consumer->>Kafka: Poll ‚Üí transaction TX-042
    Consumer->>DB: INSERT INTO audit_log (TX-042)
    DB-->>Consumer: ‚úÖ Persist√©
    Consumer->>Kafka: Commit offset 42
    Note over Consumer: Offset committ√© APR√àS persistance

    Consumer->>Kafka: Poll ‚Üí transaction TX-043
    Consumer->>DB: INSERT INTO audit_log (TX-043)

    Note over Consumer: üí• CRASH avant commit!

    Consumer->>Kafka: Red√©marrage ‚Üí dernier offset committ√© = 42
    Consumer->>Kafka: Poll ‚Üí transaction TX-043 (rejou√©e)
    Consumer->>DB: INSERT INTO audit_log (TX-043)
    Note over DB: ‚ö†Ô∏è Doublon possible ‚Üí besoin d'idempotence
    DB-->>Consumer: ‚úÖ Persist√© (ou ignor√© si doublon)
    Consumer->>Kafka: Commit offset 43

    Note over DB: ‚úÖ Aucune transaction perdue! Conformit√© OK!
```

### Garanties de Livraison : Comparaison

```mermaid
flowchart TB
    subgraph AtMostOnce["At-Most-Once (Auto-commit)"]
        direction LR
        AMO1["Commit offset"] --> AMO2["Traiter message"]
        AMO3["üí• Crash ‚Üí message perdu"]
    end

    subgraph AtLeastOnce["At-Least-Once (Manual commit) ‚úÖ"]
        direction LR
        ALO1["Traiter message"] --> ALO2["Commit offset"]
        ALO3["üí• Crash ‚Üí message rejou√© (doublon possible)"]
    end

    subgraph ExactlyOnce["Exactly-Once (Transactionnel)"]
        direction LR
        EO1["Traiter + Commit"] --> EO2["En une transaction atomique"]
        EO3["üîí Aucune perte, aucun doublon"]
    end

    style AtMostOnce fill:#ffcdd2,stroke:#d32f2f
    style AtLeastOnce fill:#c8e6c9,stroke:#388e3c
    style ExactlyOnce fill:#bbdefb,stroke:#1976d2
```

| Garantie | Perte possible ? | Doublon possible ? | Complexit√© | Cas d'usage E-Banking |
| -------- | ---------------- | ------------------ | ---------- | -------------------- |
| **At-most-once** | ‚úÖ Oui | ‚ùå Non | Faible | Logs, analytics non-critiques |
| **At-least-once** | ‚ùå Non | ‚úÖ Oui | Moyenne | **Audit, conformit√©** (ce lab) |
| **Exactly-once** | ‚ùå Non | ‚ùå Non | √âlev√©e | Paiements, virements |

> **‚ö†Ô∏è Note p√©dagogique** : La garantie *exactly-once* native de Kafka repose sur l'API Transactions. Ce lab impl√©mente **at-least-once + idempotence applicative** (d√©duplication par `TransactionId`), ce qui produit un *effet* √©quivalent √† exactly-once sans recourir aux transactions Kafka.

### Sc√©narios d'Audit R√©glementaire

| R√©glementation | Exigence | Impact d'une perte |
| -------------- | -------- | ------------------ |
| **B√¢le III** | Tra√ßabilit√© compl√®te des transactions | Sanction financi√®re |
| **PSD2** | Journalisation des paiements √©lectroniques | R√©vocation de licence |
| **AML/KYC** | Suivi des transactions suspectes | Amende jusqu'√† 10% du CA |
| **RGPD** | Droit d'acc√®s aux donn√©es de paiement | Amende jusqu'√† 4% du CA |
| **MiFID II** | Enregistrement des ordres financiers | Interdiction d'exercer |

---

## üéØ Objectifs

√Ä la fin de ce lab, vous serez capable de :

1. Impl√©menter le **manual commit** (`ack-mode=manual`) avec Spring Kafka
2. Comprendre la diff√©rence entre **at-most-once** et **at-least-once**
3. Utiliser `Acknowledgment.acknowledge()` pour un contr√¥le fin des offsets
4. Impl√©menter l'**idempotence c√¥t√© consumer** (g√©rer les doublons)
5. Impl√©menter un **retry + DLQ** c√¥t√© consumer pour les erreurs de traitement
6. G√©rer le **graceful shutdown** avec commit final

---

## üì¶ Ce que vous allez construire

| Composant | R√¥le |
| --------- | ---- |
| `Transaction.java` | Mod√®le partag√© (identique au Module 02) |
| `AuditRecord.java` | Mod√®le d'enregistrement d'audit |
| `AuditService.java` | @KafkaListener avec manual ack, retry et DLQ |
| `AuditController.java` | Endpoints API : journal d'audit, m√©triques, DLQ |
| `application.properties` | Configuration Kafka manual commit |

### Architecture des Composants

```mermaid
flowchart TB
    subgraph Kafka["üî• Kafka"]
        T["üìã banking.transactions"]
        DLQ["‚ò†Ô∏è banking.transactions.audit-dlq"]
    end

    subgraph Consumer["üì• Audit Consumer"]
        Worker["AuditService\n(@KafkaListener)"]
        Retry["üîÅ Retry 3x\n+ Exponential Backoff"]
    end

    subgraph Storage["üíæ Stockage"]
        DB["In-Memory Audit Store\n(idempotent par TransactionId)"]
    end

    subgraph API["üåê API"]
        Ctrl["AuditController"]
    end

    T --> Worker
    Worker --> Retry
    Retry -->|Succ√®s| DB
    Retry -->|√âchec permanent| DLQ
    Worker -->|Manual Ack| T
    Ctrl --> DB

    style Kafka fill:#fff3e0,stroke:#f57c00
    style Consumer fill:#e8f5e8,stroke:#388e3c
    style Storage fill:#e3f2fd,stroke:#1976d2
    style DLQ fill:#ffcdd2,stroke:#d32f2f
```

---

## üèóÔ∏è Diagramme de Classes

```mermaid
classDiagram
    class AuditService {
        -ObjectMapper objectMapper
        -KafkaTemplate dlqTemplate
        -ConcurrentHashMap~String, AuditRecord~ auditLog
        -ConcurrentLinkedQueue dlqMessages
        -AtomicLong messagesConsumed
        -AtomicLong auditRecords
        -AtomicLong duplicatesSkipped
        -AtomicLong processingErrors
        -AtomicLong dlqCount
        +onMessage(ConsumerRecord, Acknowledgment) void
        -processWithRetry(ConsumerRecord, int) boolean
        -sendToDlq(ConsumerRecord, String) void
        +getAuditLog() List~AuditRecord~
        +getDlqMessages() List
        +getStats() Map
    }

    class AuditController {
        -AuditService service
        +audit() ResponseEntity
        +dlq() ResponseEntity
        +stats() ResponseEntity
    }

    class AuditRecord {
        +String auditId
        +String transactionId
        +String customerId
        +BigDecimal amount
        +String status
        +int kafkaPartition
        +long kafkaOffset
        +int processingAttempts
    }

    AuditService --> AuditRecord : cr√©e
    AuditService --> KafkaTemplate : envoie en DLQ
    AuditController --> AuditService : utilise
```

---

## üîß S√©quence : Manual Commit (Code Expliqu√©)

```mermaid
sequenceDiagram
    participant Worker as ‚öôÔ∏è AuditService
    participant Consumer as üì• @KafkaListener
    participant Broker as üî• Kafka Broker
    participant DB as üíæ Audit Store
    participant DLQ as ‚ò†Ô∏è DLQ (KafkaTemplate)

    loop Boucle de consommation
        Broker-->>Consumer: ConsumerRecord {P2, O42, TX-042}
        Consumer-->>Worker: onMessage(record, acknowledgment)

        Worker->>Worker: D√©s√©rialiser ‚Üí Transaction
        Worker->>DB: Persister AuditRecord(tx)

        alt Persistance r√©ussie
            DB-->>Worker: ‚úÖ OK
            Worker->>Consumer: acknowledgment.acknowledge()
            Note over Consumer: Offset 43 committ√© au broker
        else Erreur de persistance
            Worker->>Worker: Retry 1/3 (backoff 1s)
            Worker->>Worker: Retry 2/3 (backoff 2s)
            Worker->>Worker: Retry 3/3 (backoff 4s)
            Worker->>DLQ: kafkaTemplate.send(dlqTopic, message)
            Worker->>Consumer: acknowledgment.acknowledge()
            Note over Consumer: Avancer l'offset (message en DLQ)
        end
    end
```

### S√©quence : Idempotence

```mermaid
flowchart TD
    A["üì• Message re√ßu: TX-042"] --> B{"TX-042 d√©j√†\ndans audit_log ?"}
    B -->|Non| C["üìã Cr√©er AuditRecord"]
    C --> D["üíæ Persister"]
    D --> E["‚úÖ acknowledge()"]
    B -->|Oui| F["‚è≠Ô∏è Skip (doublon)"]
    F --> E

    style B fill:#fff9c4,stroke:#fbc02d
    style C fill:#c8e6c9,stroke:#388e3c
    style F fill:#e3f2fd,stroke:#1976d2
```

---

## üöÄ Pr√©requis

### LABs 1.3A et 1.3B compl√©t√©s

Ce lab √©tend les concepts des LABs pr√©c√©dents avec le manual commit.

### Topics Kafka

```bash
# Cr√©er le topic DLQ pour l'audit
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions.audit-dlq \
  --partitions 6 \
  --replication-factor 1
```

### JDK 17+ et Maven 3.9+

```bash
java -version   # Attendu : 17.x+
mvn -version    # Attendu : 3.9.x+
```

---

## üìù Instructions Pas √† Pas

### √âtape 1 : Structure du projet

```text
java/
‚îú‚îÄ‚îÄ pom.xml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄ src/main/
    ‚îú‚îÄ‚îÄ resources/
    ‚îÇ   ‚îî‚îÄ‚îÄ application.properties
    ‚îî‚îÄ‚îÄ java/com/data2ai/kafka/consumer/audit/
        ‚îú‚îÄ‚îÄ AuditConsumerApplication.java
        ‚îú‚îÄ‚îÄ model/
        ‚îÇ   ‚îú‚îÄ‚îÄ Transaction.java
        ‚îÇ   ‚îî‚îÄ‚îÄ AuditRecord.java
        ‚îú‚îÄ‚îÄ service/
        ‚îÇ   ‚îî‚îÄ‚îÄ AuditService.java
        ‚îî‚îÄ‚îÄ controller/
            ‚îî‚îÄ‚îÄ AuditController.java
```

### √âtape 2 : Configuration de l'application (`application.properties`)

```properties
server.port=${SERVER_PORT:8080}

spring.application.name=lab-1-3c-audit-consumer

# Kafka
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
app.kafka.topic=${KAFKA_TOPIC:banking.transactions}
app.kafka.group-id=${KAFKA_GROUP_ID:audit-compliance-service-java}
app.kafka.dlq-topic=${KAFKA_DLQ_TOPIC:banking.transactions.audit-dlq}

# *** MANUAL COMMIT : cl√© de ce lab ***
spring.kafka.consumer.group-id=${app.kafka.group-id}
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.listener.ack-mode=manual

# Retry configuration
app.retry.max-attempts=${MAX_RETRY_ATTEMPTS:3}
app.retry.backoff-ms=${RETRY_BACKOFF_MS:1000}

# Producer pour DLQ
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# Actuator
management.endpoints.web.exposure.include=health,info
management.endpoint.health.show-details=always
```

**Points de configuration cl√©s :**

| Propri√©t√© | Valeur | R√¥le |
| --------- | ------ | ---- |
| `enable-auto-commit` | `false` | **D√©sactive** l'auto-commit ‚Äî cl√© du lab |
| `ack-mode` | `manual` | L'offset n'est committ√© que quand `acknowledge()` est appel√© |
| `dlq-topic` | `banking.transactions.audit-dlq` | Topic DLQ pour les messages en √©chec |
| `max-attempts` | `3` | Nombre max de tentatives avant envoi en DLQ |

### √âtape 3 : Mod√®le AuditRecord (`model/AuditRecord.java`)

```java
package com.data2ai.kafka.consumer.audit.model;

import java.math.BigDecimal;
import java.time.Instant;

public class AuditRecord {
    private String auditId;
    private String transactionId;
    private String customerId;
    private BigDecimal amount;
    private String currency;
    private String type;
    private String fromAccount;
    private String toAccount;
    private Instant transactionTimestamp;
    private Instant auditTimestamp = Instant.now();
    private String status = "Recorded";  // Recorded, Failed, DLQ

    // M√©tadonn√©es Kafka
    private int kafkaPartition;
    private long kafkaOffset;
    private String consumerGroupId;

    // Tra√ßabilit√©
    private int processingAttempts = 1;
    private String errorDetails;

    // Getters et setters omis ‚Äî voir le code source complet
}
```

### √âtape 4 : Service Consumer avec Manual Commit (`service/AuditService.java`)

C'est le **c≈ìur du lab** ‚Äî `Acknowledgment.acknowledge()` pour le commit manuel :

```java
@Service
public class AuditService {

    private static final Logger log = LoggerFactory.getLogger(AuditService.class);
    private final ObjectMapper objectMapper;
    private final KafkaTemplate<String, String> kafkaTemplate;

    @Value("${app.kafka.dlq-topic}")
    private String dlqTopic;

    @Value("${app.retry.max-attempts}")
    private int maxRetryAttempts;

    @Value("${app.retry.backoff-ms}")
    private long retryBackoffMs;

    // Audit store idempotent (in-memory, par TransactionId)
    private final ConcurrentHashMap<String, AuditRecord> auditLog = new ConcurrentHashMap<>();
    private final ConcurrentLinkedQueue<Map<String, Object>> dlqMessages = new ConcurrentLinkedQueue<>();

    // M√©triques
    private final AtomicLong messagesConsumed = new AtomicLong();
    private final AtomicLong auditRecords = new AtomicLong();
    private final AtomicLong duplicatesSkipped = new AtomicLong();
    private final AtomicLong processingErrors = new AtomicLong();
    private final AtomicLong dlqCount = new AtomicLong();

    @KafkaListener(topics = "${app.kafka.topic}")
    public void onMessage(ConsumerRecord<String, String> record,
                          Acknowledgment acknowledgment) {
        messagesConsumed.incrementAndGet();

        try {
            Transaction tx = objectMapper.readValue(record.value(), Transaction.class);

            // IDEMPOTENCE : v√©rifier si d√©j√† trait√©
            if (auditLog.containsKey(tx.getTransactionId())) {
                duplicatesSkipped.incrementAndGet();
                log.info("‚è≠Ô∏è Doublon ignor√©: {} (d√©j√† dans le journal) | P{}:O{}",
                        tx.getTransactionId(), record.partition(), record.offset());
                acknowledgment.acknowledge();  // Avancer l'offset
                return;
            }

            // Traiter avec retry
            boolean success = processWithRetry(record, tx);

            if (!success) {
                // Envoyer en DLQ apr√®s √©chec de tous les retries
                sendToDlq(record, "√âchec apr√®s " + maxRetryAttempts + " tentatives");
            }

        } catch (Exception ex) {
            processingErrors.incrementAndGet();
            log.error("Erreur fatale P{}:O{}: {}", record.partition(), record.offset(), ex.getMessage());
            sendToDlq(record, ex.getMessage());
        }

        // MANUAL COMMIT : committ√© APR√àS traitement (ou envoi en DLQ)
        acknowledgment.acknowledge();
    }

    private boolean processWithRetry(ConsumerRecord<String, String> record,
                                     Transaction tx) {
        for (int attempt = 1; attempt <= maxRetryAttempts; attempt++) {
            try {
                // Cr√©er l'enregistrement d'audit
                AuditRecord audit = new AuditRecord();
                audit.setTransactionId(tx.getTransactionId());
                audit.setCustomerId(tx.getCustomerId());
                audit.setAmount(tx.getAmount());
                audit.setCurrency(tx.getCurrency());
                audit.setType(tx.getType());
                audit.setKafkaPartition(record.partition());
                audit.setKafkaOffset(record.offset());
                audit.setProcessingAttempts(attempt);

                // Persister (idempotent par TransactionId)
                auditLog.put(tx.getTransactionId(), audit);
                auditRecords.incrementAndGet();

                log.info("üìã Audit enregistr√©: {} | {} | {}{} | {} | P{}:O{} | Tentative {}",
                        tx.getTransactionId(), tx.getCustomerId(),
                        tx.getAmount(), tx.getCurrency(), tx.getType(),
                        record.partition(), record.offset(), attempt);

                return true;

            } catch (Exception ex) {
                log.warn("Tentative {}/{} √©chou√©e pour P{}:O{}: {}",
                        attempt, maxRetryAttempts, record.partition(), record.offset(), ex.getMessage());

                if (attempt < maxRetryAttempts) {
                    long delay = retryBackoffMs * (long) Math.pow(2, attempt - 1);
                    log.info("‚è≥ Nouvelle tentative dans {}ms...", delay);
                    try { Thread.sleep(delay); } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                        return false;
                    }
                }
            }
        }
        processingErrors.incrementAndGet();
        return false;
    }

    private void sendToDlq(ConsumerRecord<String, String> failedRecord, String errorReason) {
        try {
            kafkaTemplate.send(dlqTopic, failedRecord.key(), failedRecord.value());
            dlqCount.incrementAndGet();

            dlqMessages.add(Map.of(
                    "transactionKey", String.valueOf(failedRecord.key()),
                    "errorReason", errorReason,
                    "originalPartition", failedRecord.partition(),
                    "originalOffset", failedRecord.offset(),
                    "failedAt", Instant.now().toString()
            ));

            log.warn("‚ò†Ô∏è Envoy√© en DLQ: Key={} | P{}:O{} | Raison: {}",
                    failedRecord.key(), failedRecord.partition(),
                    failedRecord.offset(), errorReason);
        } catch (Exception ex) {
            log.error("√âchec envoi en DLQ: {}", ex.getMessage());
        }
    }

    // --- M√©thodes publiques pour l'API ---
    public List<AuditRecord> getAuditLog() {
        return auditLog.values().stream()
                .sorted(Comparator.comparing(AuditRecord::getAuditTimestamp).reversed())
                .toList();
    }

    public List<Map<String, Object>> getDlqMessages() { return List.copyOf(dlqMessages); }

    public Map<String, Object> getStats() {
        return Map.of(
                "messagesConsumed", messagesConsumed.get(),
                "auditRecordsCreated", auditRecords.get(),
                "duplicatesSkipped", duplicatesSkipped.get(),
                "processingErrors", processingErrors.get(),
                "messagesSentToDlq", dlqCount.get(),
                "enableAutoCommit", false,
                "ackMode", "manual"
        );
    }
}
```

**Concepts cl√©s d√©montr√©s :**

- **`Acknowledgment.acknowledge()`** ‚Äî Commit manuel de l'offset (remplace `.NET consumer.Commit()`)
- **`ack-mode=manual`** ‚Äî Spring Kafka ne commite l'offset que quand `acknowledge()` est appel√©
- **Idempotence** ‚Äî V√©rification par `TransactionId` avant √©criture (√©vite les doublons)
- **Retry avec backoff exponentiel** ‚Äî 3 tentatives avec d√©lai croissant (1s, 2s, 4s)
- **DLQ via `KafkaTemplate`** ‚Äî Les messages en √©chec sont redirig√©s vers `banking.transactions.audit-dlq`

### √âtape 5 : Contr√¥leur REST (`controller/AuditController.java`)

```java
@RestController
@RequestMapping("/api/v1")
public class AuditController {

    private final AuditService service;

    public AuditController(AuditService service) {
        this.service = service;
    }

    @GetMapping("/audit")
    public ResponseEntity<List<AuditRecord>> audit() {
        return ResponseEntity.ok(service.getAuditLog());
    }

    @GetMapping("/dlq")
    public ResponseEntity<List<Map<String, Object>>> dlq() {
        return ResponseEntity.ok(service.getDlqMessages());
    }

    @GetMapping("/stats")
    public ResponseEntity<Map<String, Object>> stats() {
        return ResponseEntity.ok(service.getStats());
    }
}
```

---

## üöÄ D√©ploiement

### D√©veloppement Local

#### 1. Cr√©er le topic DLQ

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions.audit-dlq \
  --partitions 6 \
  --replication-factor 1
```

#### 2. D√©marrer le Consumer

```bash
cd java
mvn spring-boot:run
```

#### 3. Observer les logs

```text
INFO  AuditService : üìã Audit enregistr√©: TX-001 | CUST-001 | 500EUR | Transfer | P2:O0 | Tentative 1
INFO  AuditService : üìã Audit enregistr√©: TX-002 | CUST-002 | 15000EUR | InternationalTransfer | P5:O0 | Tentative 1
```

#### 4. Tester l'idempotence

R√©initialisez les offsets du consumer group pour retraiter les messages :

```bash
# Arr√™ter le consumer d'abord, puis :
docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group audit-compliance-service-java \
  --topic banking.transactions \
  --reset-offsets --to-earliest \
  --execute
```

Red√©marrez le consumer et observez :

```text
INFO  AuditService : ‚è≠Ô∏è Doublon ignor√©: TX-001 (d√©j√† dans le journal) | P2:O0
INFO  AuditService : ‚è≠Ô∏è Doublon ignor√©: TX-002 (d√©j√† dans le journal) | P5:O0
```

#### 5. V√©rifier via l'API

- `GET http://localhost:8080/api/v1/audit` ‚Äî Journal d'audit complet
- `GET http://localhost:8080/api/v1/dlq` ‚Äî Messages en Dead Letter Queue
- `GET http://localhost:8080/api/v1/stats` ‚Äî M√©triques (commits, doublons, DLQ)
- `GET http://localhost:8080/actuator/health` ‚Äî Health check

### Docker

```bash
cd java
docker build -t ebanking-audit-consumer-java .
docker run -p 8080:8080 \
  -e KAFKA_BOOTSTRAP_SERVERS=host.docker.internal:9092 \
  ebanking-audit-consumer-java
```

### OpenShift Sandbox ‚Äî Option A : Build S2I Binaire

> **üéØ Objectif** : Ce d√©ploiement valide les patterns avanc√©s du **Consumer Kafka** dans un environnement cloud :
> - **Manual Commit** : les offsets sont commit√©s explicitement apr√®s traitement r√©ussi (at-least-once)
> - **D√©duplication** : les messages d√©j√† trait√©s sont d√©tect√©s et ignor√©s (idempotence applicative)
> - **Dead Letter Queue (DLQ)** : les messages impossibles √† traiter sont redirig√©s vers un topic DLQ
> - **Retry avec backoff** : les erreurs transitoires sont retent√©es avant envoi en DLQ

#### 1. Cr√©er le topic DLQ

```bash
oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic banking.transactions.audit-dlq \
  --partitions 6 --replication-factor 3
```

#### 2. Build et D√©ploiement

```bash
cd module-03-consumer/lab-1.3c-consumer-manual-commit/java

# Cr√©er le BuildConfig (avec image stream explicite)
oc new-build --image-stream="openshift/java:openjdk-17-ubi8" --binary=true --name=ebanking-audit-consumer-java

# Build depuis le source local
oc start-build ebanking-audit-consumer-java --from-dir=. --follow

# D√©ployer
oc new-app ebanking-audit-consumer-java
```

#### 3. Configurer les variables d'environnement

```bash
oc set env deployment/ebanking-audit-consumer-java \
  SERVER_PORT=8080 \
  KAFKA_BOOTSTRAP_SERVERS=kafka-svc:9092 \
  KAFKA_TOPIC=banking.transactions \
  KAFKA_DLQ_TOPIC=banking.transactions.audit-dlq \
  MAX_RETRY_ATTEMPTS=3 \
  RETRY_BACKOFF_MS=1000
```

#### 4. Cr√©er la route Edge

```bash
oc create route edge ebanking-audit-consumer-java-secure \
  --service=ebanking-audit-consumer-java --port=8080-tcp
```

#### 5. V√©rifier le d√©ploiement

```bash
URL=$(oc get route ebanking-audit-consumer-java-secure -o jsonpath='{.spec.host}')

# Health check
curl -k "https://$URL/actuator/health"

# Journal d'audit
curl -k -s "https://$URL/api/v1/audit"

# Messages DLQ
curl -k -s "https://$URL/api/v1/dlq"

# M√©triques
curl -k -s "https://$URL/api/v1/stats"
```

> **üìù Note** : Sur PowerShell, utilisez :
> ```powershell
> $URL = oc get route ebanking-audit-consumer-java-secure -o jsonpath='{.spec.host}'
> [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.SecurityProtocolType]::Tls12
> (New-Object System.Net.WebClient).DownloadString("https://$URL/api/v1/audit")
> ```

#### 6. ‚úÖ Crit√®res de succ√®s

```bash
# Pod en cours d'ex√©cution ?
oc get pod -l deployment=ebanking-audit-consumer-java
# Attendu : STATUS=Running, READY=1/1

# Consumer actif ?
curl -k -s "https://$URL/actuator/health"
# Attendu : {"status":"UP"}

# Manual commit actif ?
curl -k -s "https://$URL/api/v1/stats"
# Attendu : enableAutoCommit=false, ackMode=manual

# Topic DLQ existe ?
oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions.audit-dlq
# Attendu : PartitionCount: 6
```

#### 7. Script automatis√©

```bash
# Bash
./scripts/bash/deploy-and-test-1.3c-java.sh

# PowerShell
.\scripts\powershell\deploy-and-test-1.3c-java.ps1
```

---

## üß™ Tests

### Sc√©narios de test

```bash
URL=$(oc get route ebanking-audit-consumer-java-secure -o jsonpath='{.spec.host}')

# 1. Health check
curl -k -s "https://$URL/actuator/health"

# 2. Journal d'audit (chaque transaction enregistr√©e avec tra√ßabilit√© compl√®te)
curl -k -s "https://$URL/api/v1/audit"
# Attendu : records avec auditId, transactionId, status="Recorded", processingAttempts=1

# 3. M√©triques (manual commit, doublons, DLQ)
curl -k -s "https://$URL/api/v1/stats"
# Attendu : enableAutoCommit=false, ackMode=manual

# 4. Messages DLQ
curl -k -s "https://$URL/api/v1/dlq"

# 5. V√©rifier les offsets commit√©s via Kafka CLI
oc exec kafka-0 -- /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe --group audit-compliance-service-java
```

---

## üìã Endpoints API

| M√©thode | Endpoint | Description |
| ------- | -------- | ----------- |
| `GET` | `/api/v1/audit` | Journal d'audit complet |
| `GET` | `/api/v1/dlq` | Messages envoy√©s en Dead Letter Queue |
| `GET` | `/api/v1/stats` | M√©triques (commits, doublons, DLQ, mode ack) |
| `GET` | `/actuator/health` | Health check |

---

## üéØ Concepts Cl√©s Expliqu√©s

### Spring Kafka vs Confluent.Kafka (.NET) ‚Äî Manual Commit

| Aspect | Java (Spring Kafka) | .NET (Confluent.Kafka) |
| ------ | ------------------- | ---------------------- |
| **D√©sactiver auto-commit** | `enable-auto-commit=false` + `ack-mode=manual` | `EnableAutoCommit = false` + `EnableAutoOffsetStore = false` |
| **Commit manuel** | `Acknowledgment.acknowledge()` | `consumer.StoreOffset()` + `consumer.Commit()` |
| **DLQ producer** | `KafkaTemplate.send()` | `IProducer.ProduceAsync()` |
| **Retry** | Boucle manuelle ou `@RetryableTopic` | Boucle manuelle avec `Task.Delay` |
| **Idempotence** | `ConcurrentHashMap.containsKey()` | `ConcurrentDictionary.ContainsKey()` |
| **Graceful shutdown** | G√©r√© par Spring Kafka lifecycle | `Commit()` dans le `finally` |

### Comparaison des 3 LABs

| Aspect | LAB 1.3A (Fraude) | LAB 1.3B (Solde) | LAB 1.3C (Audit) |
| ------ | ----------------- | ----------------- | ----------------- |
| **Commit** | Auto | Auto | **Manual** |
| **Garantie** | At-most-once | At-most-once | **At-least-once** |
| **Perte possible** | ‚ö†Ô∏è Oui | ‚ö†Ô∏è Oui | ‚úÖ Non |
| **Doublon possible** | ‚ùå Non | ‚ùå Non | ‚ö†Ô∏è Oui (g√©r√© par idempotence) |
| **DLQ** | Non | Non | **Oui** |
| **Idempotence** | Non n√©cessaire | Non n√©cessaire | **Oui (par TransactionId)** |
| **Cas d'usage** | D√©tection fraude | Calcul solde | **Audit r√©glementaire** |

### Concepts valid√©s

| Concept | Comment le v√©rifier |
| ------- | ------------------- |
| Manual Commit | `enableAutoCommit=false` et `ackMode=manual` dans `/api/v1/stats` |
| At-least-once | `kafka-consumer-groups.sh --describe` montre les offsets commit√©s |
| D√©duplication | `duplicatesSkipped` augmente quand on renvoie le m√™me `transactionId` |
| DLQ | `GET /api/v1/dlq` montre les messages impossibles √† traiter |
| Audit log | `GET /api/v1/audit` retrouve chaque transaction enregistr√©e |

---

## üîß Troubleshooting

| Sympt√¥me | Cause probable | Solution |
| -------- | -------------- | -------- |
| Consumer status `Rebalancing` permanent | Kafka coordinator instable | Attendre 30s. Si persiste, supprimer le pod : `oc delete pod -l deployment=ebanking-audit-consumer-java` |
| Health retourne 503 | Consumer pas encore assign√© aux partitions | Attendre 10-15s pour l'assignation. V√©rifier les pods Kafka |
| `messagesConsumed` reste √† 0 | Pas de messages ou commit √©chou√© | Envoyer des transactions via l'API Producer. V√©rifier les logs |
| `duplicatesSkipped` augmente | Messages rejou√©s apr√®s red√©marrage | Comportement attendu ‚Äî l'idempotence fonctionne correctement |
| Messages DLQ apparaissent | √âchecs de traitement apr√®s 3 retries | V√©rifier `/api/v1/dlq` pour les d√©tails d'erreur |
| Journal d'audit vide | Consumer sur mauvaise partition ou pas de donn√©es | V√©rifier que le topic a des messages |
| Pod CrashLoopBackOff | Variables d'env manquantes | V√©rifier : `oc set env deployment/ebanking-audit-consumer-java --list` |

---

## ‚úÖ Validation

- [ ] `enable-auto-commit=false` et `ack-mode=manual` dans la config
- [ ] Les offsets sont commit√©s **apr√®s** le traitement r√©ussi
- [ ] Les doublons sont d√©tect√©s et ignor√©s (idempotence par TransactionId)
- [ ] Les messages en erreur sont envoy√©s en DLQ apr√®s 3 retries
- [ ] Les m√©triques montrent `enableAutoCommit=false`
- [ ] Un reset des offsets + red√©marrage ne cr√©e pas de doublons dans l'audit
- [ ] `/api/v1/audit` retourne le journal d'audit complet
- [ ] `/api/v1/dlq` retourne les messages en Dead Letter Queue

---

## üîë Points √† Retenir

| Concept | Ce qu'il faut retenir |
| ------- | -------------------- |
| **Manual commit** | `enable-auto-commit=false` + `ack-mode=manual` + `acknowledge()` explicite |
| **At-least-once** | Aucune perte, mais doublons possibles ‚Üí idempotence obligatoire |
| **Idempotence** | V√©rifier par `TransactionId` avant d'√©crire (UNIQUE constraint en prod) |
| **DLQ** | Messages non traitables ‚Üí DLQ via `KafkaTemplate` pour retraitement |
| **Retry + backoff** | Exponential backoff (1s, 2s, 4s) avant envoi en DLQ |
| **Spring Kafka** | `Acknowledgment.acknowledge()` remplace `.NET consumer.Commit()` |

---

## üèÅ R√©capitulatif du Module 03

Vous avez maintenant ma√Ætris√© les 3 patterns fondamentaux de consommation Kafka en contexte e-banking :

1. **LAB 1.3A** : Consumer basique avec auto-commit ‚Üí D√©tection de fraude en temps r√©el
2. **LAB 1.3B** : Consumer Group avec scaling horizontal ‚Üí Calcul de solde distribu√©
3. **LAB 1.3C** : Manual commit avec idempotence ‚Üí Audit r√©glementaire (aucune perte)

Ces 3 consumers consomment les **m√™mes messages** produits par le Module 02, chacun dans son propre **Consumer Group**, d√©montrant le pattern multi-consumer de Kafka.

üëâ Retour au **[Module 03 ‚Äî Overview](../../README.md)**
