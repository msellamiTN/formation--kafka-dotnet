# Module 03 - Premier Consumer C# - Formation Auto-rythm√©e

## Dur√©e estim√©e

‚è±Ô∏è **2 heures 30 minutes**

## üè¶ Contexte E-Banking : Du Producer au Consumer

Dans le **Module 02**, vous avez cr√©√© une API Web qui **publie** des transactions bancaires vers Kafka. Maintenant, ces transactions doivent √™tre **consomm√©es** par les syst√®mes en aval : d√©tection de fraude, calcul de solde, notifications client, et audit r√©glementaire.

```mermaid
flowchart LR
    subgraph Module02["üì§ Module 02 - Producer (d√©j√† fait)"]
        API["üöÄ E-Banking API"]
        KPS["‚öôÔ∏è KafkaProducerService"]
    end

    subgraph Kafka["üî• Apache Kafka"]
        T["üìã banking.transactions"]
    end

    subgraph Module03["üì• Module 03 - Consumer (ce module)"]
        FD["üîç LAB 1.3A\nD√©tection Fraude\n(Auto-commit)"]
        BAL["üí∞ LAB 1.3B\nCalcul Solde\n(Consumer Group)"]
        AUD["üìã LAB 1.3C\nAudit R√©glementaire\n(Manual Commit)"]
    end

    API --> KPS
    KPS --> T
    T --> FD
    T --> BAL
    T --> AUD

    style Module02 fill:#e8f5e8,stroke:#388e3c
    style Kafka fill:#fff3e0,stroke:#f57c00
    style Module03 fill:#e3f2fd,stroke:#1976d2
```

### Cycle Complet : Producer ‚Üí Kafka ‚Üí Consumer

```mermaid
sequenceDiagram
    actor Client as üßë‚Äçüíº Client Bancaire
    participant API as üöÄ E-Banking API (Module 02)
    participant Kafka as üî• Kafka
    participant Fraud as üîç Anti-Fraude (LAB 1.3A)
    participant Balance as üí∞ Calcul Solde (LAB 1.3B)
    participant Audit as üìã Audit (LAB 1.3C)

    Client->>API: POST /api/transactions (virement 500‚Ç¨)
    API->>Kafka: Publish (Key: CUST-001)
    Kafka-->>API: ACK (Partition 2, Offset 42)
    API-->>Client: 201 Created

    par Consommation parall√®le (Consumer Groups diff√©rents)
        Kafka->>Fraud: Poll ‚Üí Transaction 500‚Ç¨
        Fraud->>Fraud: Score risque: 12/100 ‚Üí OK
    and
        Kafka->>Balance: Poll ‚Üí Transaction 500‚Ç¨
        Balance->>Balance: Solde: 1200‚Ç¨ - 500‚Ç¨ = 700‚Ç¨
    and
        Kafka->>Audit: Poll ‚Üí Transaction 500‚Ç¨
        Audit->>Audit: Commit manuel apr√®s √©criture en base
    end

    Fraud-->>Client: ‚úÖ Transaction approuv√©e
    Balance-->>Client: üìß Nouveau solde: 700‚Ç¨
```

---

## Objectifs p√©dagogiques

√Ä la fin de ce module, vous serez capable de :

1. ‚úÖ D√©velopper un Consumer .NET avec polling loop et gestion d'√©tat
2. ‚úÖ Comprendre **auto-commit vs manual commit** et leurs trade-offs
3. ‚úÖ Impl√©menter le **scaling horizontal** avec Consumer Groups
4. ‚úÖ Observer le **rebalancing** en action et g√©rer ses effets
5. ‚úÖ G√©rer les erreurs de consommation avec retry et DLQ
6. ‚úÖ Monitorer le **consumer lag** en temps r√©el

---

## üó∫Ô∏è Parcours d'Apprentissage

```mermaid
flowchart LR
    A["üìò LAB 1.3A\nConsumer Basique\nAuto-Commit\n45 min"] --> B["üìó LAB 1.3B\nConsumer Group\nScaling & Rebalancing\n60 min"]
    B --> C["üìô LAB 1.3C\nManual Commit\nTransactions Critiques\n45 min"]

    style A fill:#bbdefb,stroke:#1976d2
    style B fill:#c8e6c9,stroke:#388e3c
    style C fill:#fff9c4,stroke:#fbc02d
```

**Progression** : Basique ‚Üí Interm√©diaire ‚Üí Avanc√©

---

## üìñ Structure du Module

Ce module contient 3 labs progressifs qui consomment les messages produits dans le Module 02 :

### LAB 1.3A : Consumer Basique (Auto-Commit) ‚Äî D√©tection de Fraude

**Dur√©e** : 45 minutes
**Objectif** : Cr√©er une API Web ASP.NET Core qui consomme les transactions bancaires du topic `banking.transactions` et ex√©cute un scoring de risque en temps r√©el.

üìÅ [`lab-1.3a-consumer-basic/`](./lab-1.3a-consumer-basic/)

**Ce que vous allez apprendre** :

- Configuration d'un Consumer avec `ConsumerConfig`
- Le **Poll Loop** et son cycle de vie
- Auto-commit des offsets (comportement et risques)
- Handlers de partitions (assigned, revoked, lost)
- D√©s√©rialisation JSON des transactions bancaires
- Exposition des m√©triques via API (messages consomm√©s, lag)

**Sc√©nario E-Banking** : Service de d√©tection de fraude qui analyse chaque transaction en temps r√©el et attribue un score de risque.

---

### LAB 1.3B : Consumer Group Scaling & Rebalancing ‚Äî Calcul de Solde

**Dur√©e** : 60 minutes
**Objectif** : Observer et comprendre le rebalancing en d√©ployant plusieurs consumers dans le m√™me groupe, simuler des pannes, et scaler horizontalement.

üìÅ [`lab-1.3b-consumer-group/`](./lab-1.3b-consumer-group/)

**Ce que vous allez apprendre** :

- Consumer Groups et partitionnement automatique
- Rebalancing : triggers, phases, dur√©e
- Strat√©gies d'assignation (RoundRobin, Range, CooperativeSticky)
- Scaling horizontal optimal (N consumers = N partitions)
- Gestion des consumers inactifs (sur-capacit√©)
- Impact du rebalancing sur la latence

**Sc√©nario E-Banking** : Service de calcul de solde en temps r√©el, scal√© sur plusieurs instances pour traiter le volume de transactions.

---

### LAB 1.3C : Consumer avec Manual Commit ‚Äî Audit R√©glementaire

**Dur√©e** : 45 minutes
**Objectif** : Impl√©menter un consumer avec commit manuel pour garantir le traitement exact des transactions critiques (aucune perte, aucun doublon).

üìÅ [`lab-1.3c-consumer-manual-commit/`](./lab-1.3c-consumer-manual-commit/)

**Ce que vous allez apprendre** :

- Manual commit (`Commit()` et `StoreOffset()`)
- Diff√©rence entre at-most-once, at-least-once, exactly-once
- Pattern retry + DLQ c√¥t√© consumer
- Gestion du graceful shutdown (commit final)
- Idempotence c√¥t√© consumer
- Monitoring avanc√© (consumer lag, throughput)

**Sc√©nario E-Banking** : Service d'audit r√©glementaire qui persiste chaque transaction en base de donn√©es et ne doit jamais en perdre une.

---

## üöÄ Pr√©requis

### Module 02 compl√©t√©

Vous devez avoir compl√©t√© le **Module 02 (Producer)** car les consumers de ce module consomment les messages produits par les labs du Module 02.

### Environnement Kafka

Vous devez avoir un cluster Kafka en fonctionnement avec le topic `banking.transactions` cr√©√© :

#### Option A : Docker (D√©veloppement local)

```bash
cd ../module-01-cluster
./scripts/up.sh
```

V√©rifiez que Kafka est accessible et le topic existe :

```bash
docker ps
# Vous devez voir : kafka (healthy) et kafka-ui (healthy)

docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions
```

#### Option B : OKD/K3s (Production-like)

```bash
kubectl get kafka -n kafka
# Attendu : bhf-kafka avec status Ready

kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --describe --topic banking.transactions
```

### Outils de d√©veloppement

**Visual Studio Code** :

- Extension C# Dev Kit
- Extension Docker (optionnel)

**Visual Studio 2022** :

- Workload ".NET Desktop Development"
- Workload "ASP.NET and web development"

### SDK .NET

```bash
dotnet --version
# Attendu : 8.0.x ou sup√©rieur
```

---

## üìö Ordre de R√©alisation

Suivez les labs dans l'ordre :

1. **LAB 1.3A** ‚Üí Consumer basique avec auto-commit (d√©tection fraude)
2. **LAB 1.3B** ‚Üí Consumer Group scaling & rebalancing (calcul solde)
3. **LAB 1.3C** ‚Üí Manual commit pour transactions critiques (audit)

Chaque lab contient :

- ‚úÖ Un README d√©taill√© avec instructions pas √† pas
- ‚úÖ Le code complet comment√©
- ‚úÖ Les fichiers de configuration
- ‚úÖ Les commandes de test et validation
- ‚úÖ Des exercices pratiques
- ‚úÖ Des diagrammes Mermaid expliquant le flux

---

## üéØ Concepts Th√©oriques Cl√©s

### Le Poll Loop : C≈ìur du Consumer

```mermaid
flowchart TD
    A["üìã Subscribe(topic)"] --> B["üîÑ Poll(timeout)"]
    B --> C{"Message re√ßu ?"}
    C -->|Oui| D["‚öôÔ∏è Process Record"]
    C -->|Non| B
    D --> E["üíæ Commit Offset"]
    E --> B
    D -->|Erreur| F["üîÅ Retry / DLQ"]
    F --> E

    style A fill:#bbdefb,stroke:#1976d2
    style D fill:#c8e6c9,stroke:#388e3c
    style F fill:#ffcdd2,stroke:#d32f2f
```

### Auto-Commit vs Manual Commit

| Aspect | Auto-Commit | Manual Commit |
| ------ | ----------- | ------------- |
| **Configuration** | `EnableAutoCommit = true` | `EnableAutoCommit = false` |
| **Quand commit ?** | Toutes les 5s (configurable) | Apr√®s traitement r√©ussi |
| **Risque de perte** | ‚ö†Ô∏è Oui (si crash entre commit et fin traitement) | ‚úÖ Non |
| **Risque de doublon** | ‚úÖ Non | ‚ö†Ô∏è Oui (si crash apr√®s traitement, avant commit) |
| **Garantie** | At-most-once | At-least-once |
| **Performance** | Meilleure (moins d'appels r√©seau) | L√©g√®rement plus lent |
| **Cas d'usage** | Logs, m√©triques, analytics | Paiements, audit, transactions |

### Consumer Group : Partage des Partitions

```mermaid
flowchart TB
    subgraph Topic["üìã banking.transactions (6 partitions)"]
        P0["P0"] ~~~ P1["P1"] ~~~ P2["P2"] ~~~ P3["P3"] ~~~ P4["P4"] ~~~ P5["P5"]
    end

    subgraph G1["Consumer Group: fraud-detection"]
        C1["Consumer 1\nP0, P1, P2"]
        C2["Consumer 2\nP3, P4, P5"]
    end

    subgraph G2["Consumer Group: balance-service"]
        C3["Consumer 1\nP0, P1"]
        C4["Consumer 2\nP2, P3"]
        C5["Consumer 3\nP4, P5"]
    end

    P0 --> C1
    P1 --> C1
    P2 --> C1
    P3 --> C2
    P4 --> C2
    P5 --> C2

    P0 --> C3
    P1 --> C3
    P2 --> C4
    P3 --> C4
    P4 --> C5
    P5 --> C5

    style Topic fill:#fff3e0,stroke:#f57c00
    style G1 fill:#e3f2fd,stroke:#1976d2
    style G2 fill:#e8f5e8,stroke:#388e3c
```

> **R√®gle d'or** : Chaque consumer group lit **ind√©pendamment** le topic. Au sein d'un groupe, chaque partition est assign√©e √† **un seul** consumer.

### Configuration Consumer : Param√®tres Cl√©s

| Param√®tre | D√©faut | Description |
| --------- | ------ | ----------- |
| `GroupId` | (requis) | Identifiant du consumer group |
| `AutoOffsetReset` | `Latest` | `Earliest` = depuis le d√©but, `Latest` = nouveaux messages |
| `EnableAutoCommit` | `true` | Auto-commit des offsets |
| `AutoCommitIntervalMs` | `5000` | Intervalle entre les auto-commits |
| `SessionTimeoutMs` | `45000` | Timeout de session (√©jection si pas de heartbeat) |
| `HeartbeatIntervalMs` | `3000` | Intervalle d'envoi des heartbeats |
| `MaxPollIntervalMs` | `300000` | Temps max entre 2 polls (5 min) |
| `PartitionAssignmentStrategy` | `Range` | Strat√©gie de r√©partition des partitions |

---

## üõ†Ô∏è Commandes Utiles

### V√©rifier le topic banking.transactions

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic banking.transactions

# OKD/K3s
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --describe --topic banking.transactions
```

### V√©rifier le consumer lag

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group fraud-detection-service \
  --describe

# OKD/K3s
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-consumer-groups.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --group fraud-detection-service --describe
```

### Lister les consumer groups

```bash
# Docker
docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --list

# OKD/K3s
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-consumer-groups.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --list
```

### R√©initialiser les offsets d'un consumer group

```bash
# Docker - Reset au d√©but du topic
docker exec kafka /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group fraud-detection-service \
  --topic banking.transactions \
  --reset-offsets --to-earliest \
  --execute
```

---

## üí° Tips & Best Practices

### TIP #1 : Singleton Consumer via BackgroundService

```csharp
// ‚úÖ BON : Consumer dans un BackgroundService (long-running)
public class FraudDetectionWorker : BackgroundService
{
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        using var consumer = new ConsumerBuilder<string, string>(config).Build();
        consumer.Subscribe("banking.transactions");
        while (!stoppingToken.IsCancellationRequested)
        {
            var result = consumer.Consume(stoppingToken);
            await ProcessAsync(result);
        }
    }
}

// ‚ùå MAUVAIS : Consumer dans un Controller (par requ√™te HTTP)
```

### TIP #2 : Graceful Shutdown

```csharp
// TOUJOURS fermer proprement le consumer
consumer.Close(); // Commit final + quitter le groupe + trigger rebalancing rapide
```

### TIP #3 : CooperativeSticky pour minimiser le rebalancing

```csharp
PartitionAssignmentStrategy = PartitionAssignmentStrategy.CooperativeSticky
// 10x plus rapide que RoundRobin/Range pour grands groupes
```

### TIP #4 : Consumer Lag = m√©trique #1 en production

```bash
# Si LAG > 0 de fa√ßon persistante ‚Üí consumer trop lent ou en panne
# Alerte recommand√©e : LAG > 1000 pendant > 5 minutes
```

---

## üéØ Validation du Module

√Ä la fin de ce module, vous devez √™tre capable de :

- [ ] Cr√©er un Consumer .NET avec polling loop
- [ ] Comprendre auto-commit vs manual commit
- [ ] Configurer et observer un Consumer Group
- [ ] Observer le rebalancing (join, leave, crash)
- [ ] Scaler horizontalement un consumer group
- [ ] G√©rer les erreurs de consommation (retry + DLQ)
- [ ] Impl√©menter le manual commit pour transactions critiques
- [ ] Monitorer le consumer lag en temps r√©el
- [ ] Expliquer les garanties at-most-once vs at-least-once

---

## üìñ Ressources Compl√©mentaires

- [Documentation Confluent.Kafka Consumer](https://docs.confluent.io/kafka-clients/dotnet/current/overview.html#consumer)
- [Kafka Consumer Configuration](https://kafka.apache.org/documentation/#consumerconfigs)
- [Consumer Group Protocol](https://developer.confluent.io/courses/architecture/consumer-group-protocol/)
- [Exactly-Once Semantics](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)

---

## üöÄ Commencer le Module

Rendez-vous dans le premier lab :

üëâ **[LAB 1.3A : Consumer Basique ‚Äî D√©tection de Fraude](./lab-1.3a-consumer-basic/README.md)**
