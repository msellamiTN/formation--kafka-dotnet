# üìÖ Day 02 ‚Äî Patterns de Production & S√©rialisation

> **Mercredi 11 f√©vrier 2026** | 6h (9h‚Äì12h / 13h30‚Äì16h30) | **Niveau** : Interm√©diaire ‚Üí Avanc√©

---

## üéØ Objectifs p√©dagogiques

√Ä la fin de cette journ√©e, vous serez capable de :

| # | Objectif | Bloc |
| --- | -------- | ---- |
| 1 | Choisir la bonne strat√©gie de **s√©rialisation** (JSON, Avro, Protobuf) | 2.1 |
| 2 | Configurer **Schema Registry** et g√©rer l'**√©volution de sch√©ma** | 2.1 |
| 3 | Activer l'**idempotence** producer (`EnableIdempotence = true`) | 2.2 |
| 4 | Comprendre les **transactions Kafka** et l'exactly-once semantics | 2.2 |
| 5 | Impl√©menter un **Dead Letter Topic** (DLT) pour messages en erreur | 2.3 |
| 6 | Configurer des **retries avec backoff exponentiel + jitter** | 2.3 |
| 7 | G√©rer le **rebalancing** avec CooperativeSticky | 2.3 |
| 8 | Comprendre **Kafka Connect** et ses cas d'usage (preview Day 03) | 2.4 |

> **Ratio th√©orie/pratique** : 30% / 70% ‚Äî Chaque bloc commence par 15-20 min de th√©orie puis encha√Æne sur un lab hands-on.

---

## üìã Pr√©requis

- ‚úÖ **Day 01 compl√©t√©** (M01-M03, Labs 1.2a‚Äì1.3c)
- ‚úÖ Infrastructure Kafka fonctionnelle (Docker ou OpenShift Sandbox)
- ‚úÖ Topic `banking.transactions` existant (6 partitions)
- ‚úÖ .NET 8 SDK + Confluent.Kafka 2.3.0+

---

## üóìÔ∏è Planning de la journ√©e

| Cr√©neau | Bloc | Dur√©e | Contenu |
| ------- | ---- | ----- | ------- |
| 09h00‚Äì09h30 | Recap | 30 min | Quiz Day 01 + correction, questions ouvertes |
| 09h30‚Äì10h30 | **2.1** | 1h | S√©rialisation : JSON patterns ‚Üí Avro ‚Üí Schema Registry |
| 10h30‚Äì10h45 | | 15 min | ‚òï Pause |
| 10h45‚Äì12h00 | **2.2** | 1h15 | Producer Avanc√© : Idempotence, Transactions, Exactly-once |
| 12h00‚Äì13h30 | | 1h30 | üçΩÔ∏è D√©jeuner |
| 13h30‚Äì15h00 | **2.3** | 1h30 | Consumer Avanc√© : DLT, Retry, Rebalancing (Lab M04) |
| 15h00‚Äì15h15 | | 15 min | ‚òï Pause |
| 15h15‚Äì16h00 | **2.4** | 45 min | Kafka Connect Introduction (preview Day 03) |
| 16h00‚Äì16h30 | Recap | 30 min | Bilan Day 02, Q&A, preview Day 03 |

---

## üìö Bloc 2.1 ‚Äî S√©rialisation Avanc√©e (1h)

> **Th√©orie** : 20 min | **Lab** : 40 min

### Concepts cl√©s

```mermaid
flowchart LR
    subgraph Formats["üì¶ Formats de S√©rialisation"]
        JSON["JSON<br/>‚úÖ Lisible<br/>‚ùå Verbeux"]
        AVRO["Avro<br/>‚úÖ Compact<br/>‚úÖ Schema Evolution"]
        PROTO["Protobuf<br/>‚úÖ Rapide<br/>‚úÖ Multi-langage"]
    end

    subgraph SR["üèõÔ∏è Schema Registry"]
        S1["Schema v1"]
        S2["Schema v2"]
        S1 -->|"BACKWARD<br/>compatible"| S2
    end

    JSON --> SR
    AVRO --> SR
    PROTO --> SR
```

| Format | Taille (msg 1KB JSON) | Schema Evolution | Lisibilit√© | Cas d'usage |
| ------ | --------------------- | ---------------- | ---------- | ----------- |
| **JSON** | 1000 bytes | ‚ùå Manuelle | ‚úÖ Lisible | Prototypage, debug |
| **Avro** | ~400 bytes | ‚úÖ Registry | ‚ùå Binaire | Production (recommand√©) |
| **Protobuf** | ~350 bytes | ‚úÖ Registry | ‚ùå Binaire | gRPC, multi-langage |

### √âvolution de sch√©ma

| Strat√©gie | R√®gle | Exemple |
| --------- | ----- | ------- |
| **BACKWARD** | Nouveau consumer lit ancien format | Ajouter champ optionnel |
| **FORWARD** | Ancien consumer lit nouveau format | Supprimer champ optionnel |
| **FULL** | Les deux | Ajouter/supprimer champs optionnels uniquement |
| **NONE** | Pas de v√©rification | D√©veloppement uniquement |

### Lab 2.1 ‚Äî S√©rialisation JSON structur√©e & intro Avro

> üìÇ **[lab-2.1a ‚Äî Serialization](./module-04-advanced-patterns/lab-2.1a-serialization/README.md)**

**Objectifs du lab** :

1. Impl√©menter un serializer/deserializer JSON typ√© pour `Transaction`
2. Ajouter la validation de sch√©ma c√¥t√© producer et consumer
3. D√©montrer le probl√®me d'√©volution de sch√©ma avec JSON brut
4. (Bonus) Configurer Avro avec Schema Registry

**Concepts .NET** :

```csharp
// Custom JSON serializer with schema validation
var producerConfig = new ProducerConfig { /* ... */ };

using var producer = new ProducerBuilder<string, Transaction>(producerConfig)
    .SetValueSerializer(new TransactionJsonSerializer())  // Custom serializer
    .Build();
```

---

## üìö Bloc 2.2 ‚Äî Producer Patterns Avanc√©s (1h15)

> **Th√©orie** : 20 min | **Lab** : 55 min

### Concepts cl√©s

#### Idempotence : √âviter les duplicatas

```mermaid
sequenceDiagram
    participant P as üì§ Producer
    participant B as üì¶ Broker

    P->>B: Send msg (PID=1, Seq=0)
    B-->>P: ACK ‚úÖ
    P->>B: Send msg (PID=1, Seq=1)
    Note over B: Network timeout
    P->>B: Retry msg (PID=1, Seq=1)
    B->>B: Seq=1 d√©j√† vu ‚Üí d√©dupliqu√©
    B-->>P: ACK ‚úÖ (pas de duplicata)
```

| Config | Sans Idempotence | Avec Idempotence |
| ------ | ---------------- | ---------------- |
| `EnableIdempotence` | `false` | `true` |
| `Acks` | `Leader` ou `All` | **`All`** (forc√©) |
| `MaxInFlight` | 5 (d√©faut) | **‚â§ 5** (forc√©) |
| `MessageSendMaxRetries` | 2 (d√©faut) | **`int.MaxValue`** (forc√©) |
| Risque duplicata | ‚ö†Ô∏è Oui (retry) | ‚úÖ Non |
| Performance | Rapide | ~identique |

#### Transactions Kafka (Exactly-Once)

```mermaid
flowchart LR
    subgraph TX["üîí Transaction Kafka"]
        P["Producer"] -->|"InitTransactions()"| B["Broker"]
        P -->|"BeginTransaction()"| B
        P -->|"Send(msg1)"| B
        P -->|"Send(msg2)"| B
        P -->|"SendOffsetsToTransaction()"| B
        P -->|"CommitTransaction()"| B
    end

    subgraph Consumer["üì• Consumer"]
        C["IsolationLevel =<br/>ReadCommitted"]
    end

    B --> C
    style TX fill:#e8f5e9,stroke:#388e3c
```

| Garantie | Configuration Producer | Configuration Consumer |
| -------- | --------------------- | --------------------- |
| **At-most-once** | `Acks = 0` | Auto-commit |
| **At-least-once** | `Acks = All` + Idempotence | Manual commit apr√®s traitement |
| **Exactly-once** | `Acks = All` + Transactions | `IsolationLevel = ReadCommitted` |

### Lab 2.2a ‚Äî Producer Idempotent

> üìÇ **[lab-2.2a ‚Äî Producer Idempotent](./module-04-advanced-patterns/lab-2.2-producer-advanced/README.md)**

**Objectifs du lab** :

1. Activer `EnableIdempotence = true` et observer le Producer ID (PID)
2. Simuler des retries r√©seau et v√©rifier l'absence de duplicatas
3. Comparer throughput avec/sans idempotence
4. Observer les sequence numbers dans les m√©triques

### Lab 2.2b ‚Äî Transactions Kafka (Exactly-Once)

> üìÇ **[lab-2.2b ‚Äî Kafka Transactions](./module-04-advanced-patterns/lab-2.2b-transactions/README.md)**

**Objectifs du lab** :

1. Configurer un `TransactionalId` persistant
2. Impl√©menter `BeginTransaction()` ‚Üí `CommitTransaction()` / `AbortTransaction()`
3. Envoyer un lot de messages atomique (all-or-nothing)
4. Configurer un consumer avec `IsolationLevel.ReadCommitted`

**Code cl√©** :

```csharp
var config = new ProducerConfig
{
    BootstrapServers = "localhost:9092",
    EnableIdempotence = true,       // Activates PID + sequence numbers
    Acks = Acks.All,                // Required for idempotence
    MaxInFlight = 5,                // Max with idempotence
    MessageSendMaxRetries = int.MaxValue,
    LingerMs = 10,
    CompressionType = CompressionType.Snappy
};
```

---

## üì• Bloc 2.3 ‚Äî Consumer Patterns Avanc√©s (1h30)

> **Th√©orie** : 20 min | **Lab** : 1h10

### Concepts cl√©s

```mermaid
flowchart LR
    subgraph Pipeline["üè¶ E-Banking Pipeline"]
        T["banking.transactions<br/>(6 partitions)"]
        C["‚öôÔ∏è Consumer"]
        D{OK?}
        R["üîÑ Retry<br/>(backoff + jitter)"]
        DLT["üíÄ DLT"]
        DB[("üíæ Audit DB")]
    end

    T --> C --> D
    D -->|"‚úÖ"| DB
    D -->|"‚ùå transient"| R
    R -->|"max retries"| DLT
    R -->|"retry"| C
    D -->|"‚ùå permanent"| DLT

    style DLT fill:#ffcccc
    style DB fill:#ccffcc
```

| Pattern | Quand | Impl√©mentation |
| ------- | ----- | -------------- |
| **DLT (Dead Letter Topic)** | Message non traitable apr√®s N retries | Producer vers `banking.transactions.dlq` avec headers de tra√ßabilit√© |
| **Retry + Backoff** | Erreur transitoire (timeout, DB lock) | `Math.Pow(2, attempt) * baseDelay + jitter` |
| **Error Classification** | Distinguer transient vs permanent | `IsTransient(ex)` ‚Üí retry, sinon DLT imm√©diat |
| **Rebalancing Handlers** | Scaling up/down des consumers | `SetPartitionsRevokedHandler` ‚Üí commit avant r√©vocation |

### Lab 2.3 ‚Äî DLT, Retry & Rebalancing

> üìÇ **[lab-2.3a ‚Äî Consumer DLT & Retry](./module-04-advanced-patterns/lab-2.3a-consumer-dlt-retry/README.md)**

**Objectifs du lab** :

1. Envoyer des messages valides et invalides, observer le routage vers DLT
2. Observer les retries avec backoff exponentiel dans les logs
3. Scaler le consumer √† 2 replicas et observer le rebalancing CooperativeSticky
4. Consulter les m√©triques via `/api/v1/stats` et `/api/v1/dlt/messages`

**Concepts couverts** :

- `EnableAutoCommit = false` + `Commit()` explicite
- `EnableAutoOffsetStore = false` + `StoreOffset()` pour contr√¥le fin
- `PartitionAssignmentStrategy = CooperativeSticky`
- Classification transient vs permanent avec pattern matching C#
- DLT avec headers : `original-topic`, `error-reason`, `retry-count`, `failed-at`

---

## üîå Bloc 2.4 ‚Äî Kafka Connect Introduction (45 min)

> **Th√©orie** : 30 min | **D√©mo** : 15 min

### Concepts cl√©s

```mermaid
flowchart LR
    subgraph Sources["üì• Sources"]
        DB[("üóÑÔ∏è SQL Server")]
        FILE["üìÑ CSV/JSON"]
    end

    subgraph Connect["üîå Kafka Connect"]
        SC["Source Connector"]
        SK["Sink Connector"]
    end

    subgraph Kafka["üì¶ Kafka"]
        T["Topics"]
    end

    subgraph Sinks["üì§ Destinations"]
        ES[("üîç Elasticsearch")]
        S3["‚òÅÔ∏è Blob Storage"]
    end

    DB --> SC --> T
    FILE --> SC
    T --> SK --> ES
    T --> SK --> S3
```

| Concept | Description |
| ------- | ----------- |
| **Source Connector** | Lit des donn√©es externes ‚Üí Kafka topics |
| **Sink Connector** | Lit Kafka topics ‚Üí √©crit vers syst√®mes externes |
| **Worker** | Process JVM qui ex√©cute les connecteurs |
| **Task** | Unit√© de parall√©lisme au sein d'un connecteur |
| **Converter** | Transforme les donn√©es (JsonConverter, AvroConverter) |

> üîó **Lab complet Kafka Connect** : voir **[Day 03 ‚Äî Module 06](../day-03-integration/module-06-kafka-connect/README.md)**

**Preview** : Demain (Day 03) vous d√©ploierez un connecteur **SQL Server CDC ‚Üí Kafka** et un **Kafka ‚Üí Elasticsearch** pour indexer les transactions bancaires en temps r√©el.

---

## üèóÔ∏è Architecture Day 02

```mermaid
flowchart TB
    subgraph Docker["üê≥ Docker Network: bhf-kafka-network"]
        subgraph Infra["Infrastructure"]
            K["üì¶ Kafka<br/>:9092"]
            UI["üñ•Ô∏è Kafka UI<br/>:8080"]
            SR["üèõÔ∏è Schema Registry<br/>:8081"]
        end

        subgraph Bloc21["Bloc 2.1 - Serialization"]
            SER["üî∑ .NET Serializer Demo"]
        end

        subgraph Bloc22["Bloc 2.2 - Producer Advanced"]
            IDEM["üî∑ .NET Idempotent Producer"]
            TXAPI["üî∑ .NET Transactional Producer"]
        end

        subgraph Bloc23["Bloc 2.3 - Consumer Advanced"]
            NET04["üî∑ .NET DLT Consumer<br/>:18083"]
        end
    end

    SER --> K
    IDEM --> K
    TXAPI --> K
    K -->|"banking.transactions"| NET04
    NET04 -->|"banking.transactions.dlq"| K
    UI --> K
    SER --> SR
```

---

## üì¶ Modules & Labs

| Bloc | Module | Lab | Dur√©e | Description |
| ---- | ------ | --- | ----- | ----------- |
| 2.1 | [Serialization](./module-04-advanced-patterns/lab-2.1a-serialization/README.md) | Lab 2.1a | 40 min | JSON typ√©, validation, intro Avro |
| 2.2 | [Producer Advanced](./module-04-advanced-patterns/lab-2.2-producer-advanced/README.md) | Lab 2.2a | 30 min | Idempotence, PID, sequence numbers |
| 2.2 | [Transactions](./module-04-advanced-patterns/lab-2.2b-transactions/README.md) | Lab 2.2b | 25 min | Kafka Transactions, Exactly-Once Semantics |
| 2.3 | [Consumer Advanced](./module-04-advanced-patterns/lab-2.3a-consumer-dlt-retry/README.md) | Lab 2.3a | 1h10 | DLT, Retry, Rebalancing |
| 2.4 | Kafka Connect | (Day 03 preview) | 15 min | D√©mo Source/Sink connectors |

---

## üöÄ Quick Start

### D√©marrer l'infrastructure

<details>
<summary>üê≥ Docker</summary>

```bash
# Depuis la racine du projet
cd day-01-foundations/module-01-cluster
./scripts/up.sh

# V√©rifier que Kafka est healthy
docker ps | grep kafka
```

</details>

<details>
<summary>‚òÅÔ∏è OpenShift Sandbox</summary>

```bash
oc login --token=<TOKEN> --server=<SERVER>
oc get pods -l app=kafka
```

</details>

### Lancer les labs

<details>
<summary>üñ•Ô∏è Local (dotnet run)</summary>

```bash
# Lab 2.1a ‚Äî Serialization (port 5170)
cd day-02-development/module-04-advanced-patterns/lab-2.1a-serialization/dotnet
dotnet run

# Lab 2.2a ‚Äî Idempotent Producer (port 5171)
cd ../../lab-2.2-producer-advanced/dotnet
dotnet run

# Lab 2.2b ‚Äî Transactional Producer (port 5172)
cd ../../lab-2.2b-transactions/dotnet
dotnet run

# Lab 2.3a ‚Äî DLT & Retry Consumer (port 18083)
cd ../../lab-2.3a-consumer-dlt-retry/dotnet
dotnet run
```

</details>

<details>
<summary>üê≥ Docker Compose (tous les labs)</summary>

```bash
# D√©marrer les 3 labs Day 02 via Docker Compose
cd day-02-development/module-04-advanced-patterns
docker compose -f docker-compose.module.yml up -d --build

# V√©rifier
docker ps | grep m04

# Swagger UIs :
#   Lab 2.1a : http://localhost:5170/swagger
#   Lab 2.2a : http://localhost:5171/swagger
#   Lab 2.3a : http://localhost:18083/swagger

# Arr√™ter
docker compose -f docker-compose.module.yml down
```

</details>

---

## üö¢ D√©ploiement ‚Äî 3 Environnements

Chaque lab Day 02 peut √™tre d√©ploy√© dans **3 environnements**, comme les labs Day 01 :

| Environnement | Outil | Kafka Bootstrap | Acc√®s API |
| ------------- | ----- | --------------- | --------- |
| **üê≥ Docker / Local** | `dotnet run` | `localhost:9092` | `http://localhost:{port}/swagger` |
| **‚òÅÔ∏è OpenShift Sandbox** | `oc new-build` + Binary Build | `kafka-svc:9092` | `https://{route}/swagger` |
| **üñ•Ô∏è OpenShift Local (CRC)** | `oc new-build` + Binary Build | `kafka-svc:9092` | `https://{route}/swagger` |
| **‚ò∏Ô∏è K8s / OKD** | `docker build` + `kubectl apply` | `kafka-svc:9092` | `http://localhost:8080/swagger` (port-forward) |

### Ports locaux Day 02

| Lab | API Name | Local Port | Swagger URL |
| --- | -------- | ---------- | ----------- |
| 2.1a | Serialization API | `:5170` | `http://localhost:5170/swagger` |
| 2.2a | Idempotent Producer API | `:5171` | `http://localhost:5171/swagger` |
| 2.2b | Transactional Producer API | `:5172` | `http://localhost:5172/swagger` |
| 2.3a | DLT Consumer API | `:18083` | `http://localhost:18083/swagger` |

### D√©ploiement sur OpenShift (Sandbox ou CRC)

```bash
# Pattern commun : Binary Build S2I pour chaque lab
cd day-02-development/module-04-advanced-patterns/<lab-folder>/dotnet

oc new-build dotnet:8.0-ubi8 --binary=true --name=<app-name>
oc start-build <app-name> --from-dir=. --follow
oc new-app <app-name>
oc set env deployment/<app-name> Kafka__BootstrapServers=kafka-svc:9092 ASPNETCORE_URLS=http://0.0.0.0:8080
oc create route edge <app-name>-secure --service=<app-name> --port=8080-tcp
```

### D√©ploiement Kubernetes / OKD

Chaque lab fournit des manifestes YAML dans `dotnet/deployment/` :

```bash
cd day-02-development/module-04-advanced-patterns/<lab-folder>/dotnet

# Build Docker
docker build -t <app-name>:latest .

# Deploy
kubectl apply -f deployment/k8s-deployment.yaml
kubectl port-forward svc/<app-name> 8080:8080
```

### R√©capitulatif des noms d'applications

| Lab | App Name (oc/kubectl) | Image Docker | DLL |
| --- | --------------------- | ------------ | --- |
| 2.1a | `ebanking-serialization-api` | `ebanking-serialization-api:latest` | `SerializationLab.dll` |
| 2.2a | `ebanking-idempotent-api` | `ebanking-idempotent-api:latest` | `EBankingIdempotentProducerAPI.dll` |
| 2.2b | `ebanking-transactional-api` | `ebanking-transactional-api:latest` | `EBankingTransactionsAPI.dll` |
| 2.3a | `ebanking-dlt-consumer` | `ebanking-dlt-consumer:latest` | `EBankingDltConsumer.dll` |

> **Note** : Lab 2.3a utilise `KAFKA_*` (env vars directes) au lieu de `Kafka__*` (ASP.NET config). Voir le README du lab pour les variables exactes.

Pour les instructions d√©taill√©es par lab, consultez chaque README individuel.

---

## ‚ö†Ô∏è Troubleshooting

| Erreur | Cause | Solution |
| ------ | ----- | -------- |
| `ClusterAuthorizationException` | Idempotence non autoris√©e | V√©rifier les ACLs broker ou d√©sactiver `EnableIdempotence` |
| `InvalidPidMappingException` | PID expir√© (transaction timeout) | Augmenter `TransactionalId` timeout ou recr√©er le producer |
| `SerializationException` | Schema incompatible | V√©rifier compatibilit√© dans Schema Registry |
| Message dans DLT | Erreur de traitement | Analyser headers `error-reason` dans le message DLT |
| `Rebalancing in progress` | Consumer group instable | V√©rifier `SessionTimeoutMs` et `HeartbeatIntervalMs` |

---

## ‚úÖ Validation Day 02

- [ ] Lab 2.1 : Serializer JSON typ√© fonctionne, validation d√©tecte les sch√©mas invalides
- [ ] Lab 2.2a : Producer idempotent activ√©, PID visible dans les logs, pas de duplicatas apr√®s retry
- [ ] Lab 2.2b : Transactions Kafka fonctionnelles, lot atomique commit√©, consumer ReadCommitted
- [ ] Lab 2.3 : Messages invalides rout√©s vers DLT, retries visibles dans les logs, rebalancing observ√©
- [ ] Comprendre la diff√©rence entre at-least-once et exactly-once
- [ ] Savoir quand utiliser `EnableIdempotence` vs Transactions compl√®tes

---

## ‚û°Ô∏è Navigation

‚¨ÖÔ∏è **[Day 01 ‚Äî Fondamentaux](../day-01-foundations/module-01-cluster/README.md)** | ‚û°Ô∏è **[Day 03 ‚Äî Int√©gration, Tests & Observabilit√©](../day-03-integration/README.md)**
