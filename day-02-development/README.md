# ğŸ“… Day 02 â€” Patterns de Production & SÃ©rialisation

> **Mercredi 11 fÃ©vrier 2026** | 6h (9hâ€“12h / 13h30â€“16h30) | **Niveau** : IntermÃ©diaire â†’ AvancÃ©

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ã€ la fin de cette journÃ©e, vous serez capable de :

| # | Objectif | Bloc |
| --- | -------- | ---- |
| 1 | Choisir la bonne stratÃ©gie de **sÃ©rialisation** (JSON, Avro, Protobuf) | 2.1 |
| 2 | Configurer **Schema Registry** et gÃ©rer l'**Ã©volution de schÃ©ma** | 2.1 |
| 3 | Activer l'**idempotence** producer (`EnableIdempotence = true`) | 2.2 |
| 4 | Comprendre les **transactions Kafka** et l'exactly-once semantics | 2.2 |
| 5 | ImplÃ©menter un **Dead Letter Topic** (DLT) pour messages en erreur | 2.3 |
| 6 | Configurer des **retries avec backoff exponentiel + jitter** | 2.3 |
| 7 | GÃ©rer le **rebalancing** avec CooperativeSticky | 2.3 |
| 8 | Comprendre **Kafka Connect** et ses cas d'usage (preview Day 03) | 2.4 |

> **Ratio thÃ©orie/pratique** : 30% / 70% â€” Chaque bloc commence par 15-20 min de thÃ©orie puis enchaÃ®ne sur un lab hands-on.

---

## ğŸ“‹ PrÃ©requis

- âœ… **Day 01 complÃ©tÃ©** (M01-M03, Labs 1.2aâ€“1.3c)
- âœ… Infrastructure Kafka fonctionnelle (Docker ou OpenShift Sandbox)
- âœ… Topic `banking.transactions` existant (6 partitions)
- âœ… .NET 8 SDK + Confluent.Kafka 2.3.0+

---

## ğŸ—“ï¸ Planning de la journÃ©e

| CrÃ©neau | Bloc | DurÃ©e | Contenu |
| ------- | ---- | ----- | ------- |
| 09h00â€“09h30 | Recap | 30 min | Quiz Day 01 + correction, questions ouvertes |
| 09h30â€“10h30 | **2.1** | 1h | SÃ©rialisation : JSON patterns â†’ Avro â†’ Schema Registry |
| 10h30â€“10h45 | | 15 min | â˜• Pause |
| 10h45â€“12h00 | **2.2** | 1h15 | Producer AvancÃ© : Idempotence, Transactions, Exactly-once |
| 12h00â€“13h30 | | 1h30 | ğŸ½ï¸ DÃ©jeuner |
| 13h30â€“15h00 | **2.3** | 1h30 | Consumer AvancÃ© : DLT, Retry, Rebalancing (Lab M04) |
| 15h00â€“15h15 | | 15 min | â˜• Pause |
| 15h15â€“16h00 | **2.4** | 45 min | Kafka Connect Introduction (preview Day 03) |
| 16h00â€“16h30 | Recap | 30 min | Bilan Day 02, Q&A, preview Day 03 |

---

## ğŸ“š Bloc 2.1 â€” SÃ©rialisation AvancÃ©e (1h)

> **ThÃ©orie** : 20 min | **Lab** : 40 min

### Concepts clÃ©s

```mermaid
flowchart LR
    subgraph Formats["ğŸ“¦ Formats de SÃ©rialisation"]
        JSON["JSON<br/>âœ… Lisible<br/>âŒ Verbeux"]
        AVRO["Avro<br/>âœ… Compact<br/>âœ… Schema Evolution"]
        PROTO["Protobuf<br/>âœ… Rapide<br/>âœ… Multi-langage"]
    end

    subgraph SR["ğŸ›ï¸ Schema Registry"]
        S1["Schema v1"]
        S2["Schema v2"]
        S1 -->|"BACKWARD<br/>compatible"| S2
    end

    JSON --> SR
    AVRO --> SR
    PROTO --> SR
```

| Format | Taille (msg 1KB JSON) | Schema Evolution | LisibilitÃ© | Cas d'usage |
| ------ | --------------------- | ---------------- | ---------- | ----------- |
| **JSON** | 1000 bytes | âŒ Manuelle | âœ… Lisible | Prototypage, debug |
| **Avro** | ~400 bytes | âœ… Registry | âŒ Binaire | Production (recommandÃ©) |
| **Protobuf** | ~350 bytes | âœ… Registry | âŒ Binaire | gRPC, multi-langage |

### Ã‰volution de schÃ©ma

| StratÃ©gie | RÃ¨gle | Exemple |
| --------- | ----- | ------- |
| **BACKWARD** | Nouveau consumer lit ancien format | Ajouter champ optionnel |
| **FORWARD** | Ancien consumer lit nouveau format | Supprimer champ optionnel |
| **FULL** | Les deux | Ajouter/supprimer champs optionnels uniquement |
| **NONE** | Pas de vÃ©rification | DÃ©veloppement uniquement |

### Lab 2.1 â€” SÃ©rialisation JSON structurÃ©e & intro Avro

> ğŸ“‚ **[lab-2.1a â€” Serialization](./module-04-advanced-patterns/lab-2.1a-serialization/README.md)**

**Objectifs du lab** :

1. ImplÃ©menter un serializer/deserializer JSON typÃ© pour `Transaction`
2. Ajouter la validation de schÃ©ma cÃ´tÃ© producer et consumer
3. DÃ©montrer le problÃ¨me d'Ã©volution de schÃ©ma avec JSON brut
4. (Bonus) Configurer Avro avec Schema Registry

**Concepts .NET** :

```csharp
// Custom JSON serializer with schema validation
var producerConfig = new ProducerConfig { /* ... */ };

using var producer = new ProducerBuilder<string, Transaction>(producerConfig)
    .SetValueSerializer(new TransactionJsonSerializer())  // Custom serializer
    .Build();
```

---

## ğŸ“š Bloc 2.2 â€” Producer Patterns AvancÃ©s (1h15)

> **ThÃ©orie** : 20 min | **Lab** : 55 min

### Concepts clÃ©s

#### Idempotence : Ã‰viter les duplicatas

```mermaid
sequenceDiagram
    participant P as ğŸ“¤ Producer
    participant B as ğŸ“¦ Broker

    P->>B: Send msg (PID=1, Seq=0)
    B-->>P: ACK âœ…
    P->>B: Send msg (PID=1, Seq=1)
    Note over B: Network timeout
    P->>B: Retry msg (PID=1, Seq=1)
    B->>B: Seq=1 dÃ©jÃ  vu â†’ dÃ©dupliquÃ©
    B-->>P: ACK âœ… (pas de duplicata)
```

| Config | Sans Idempotence | Avec Idempotence |
| ------ | ---------------- | ---------------- |
| `EnableIdempotence` | `false` | `true` |
| `Acks` | `Leader` ou `All` | **`All`** (forcÃ©) |
| `MaxInFlight` | 5 (dÃ©faut) | **â‰¤ 5** (forcÃ©) |
| `MessageSendMaxRetries` | 2 (dÃ©faut) | **`int.MaxValue`** (forcÃ©) |
| Risque duplicata | âš ï¸ Oui (retry) | âœ… Non |
| Performance | Rapide | ~identique |

#### Transactions Kafka (Exactly-Once)

```mermaid
flowchart LR
    subgraph TX["ğŸ”’ Transaction Kafka"]
        P["Producer"] -->|"InitTransactions()"| B["Broker"]
        P -->|"BeginTransaction()"| B
        P -->|"Send(msg1)"| B
        P -->|"Send(msg2)"| B
        P -->|"SendOffsetsToTransaction()"| B
        P -->|"CommitTransaction()"| B
    end

    subgraph Consumer["ğŸ“¥ Consumer"]
        C["IsolationLevel =<br/>ReadCommitted"]
    end

    B --> C
    style TX fill:#e8f5e9,stroke:#388e3c
```

| Garantie | Configuration Producer | Configuration Consumer |
| -------- | --------------------- | --------------------- |
| **At-most-once** | `Acks = 0` | Auto-commit |
| **At-least-once** | `Acks = All` + Idempotence | Manual commit aprÃ¨s traitement |
| **Exactly-once** | `Acks = All` + Transactions | `IsolationLevel = ReadCommitted` |

### Lab 2.2 â€” Producer Idempotent & Transactions

> ğŸ“‚ **[lab-2.2a â€” Producer Idempotent](./module-04-advanced-patterns/lab-2.2-producer-advanced/README.md)**

**Objectifs du lab** :

1. Activer `EnableIdempotence = true` et observer le Producer ID (PID)
2. Simuler des retries rÃ©seau et vÃ©rifier l'absence de duplicatas
3. Comparer throughput avec/sans idempotence
4. (Bonus) ImplÃ©menter une transaction Kafka read-process-write

**Code clÃ©** :

```csharp
var config = new ProducerConfig
{
    BootstrapServers = "localhost:9092",
    EnableIdempotence = true,       // Activates PID + sequence numbers
    Acks = Acks.All,                // Required for idempotence
    MaxInFlight = 5,                // Max with idempotence
    MessageSendMaxRetries = int.MaxValue,
    LingerMs = 10,
    CompressionType = CompressionType.Snappy
};
```

---

## ğŸ“¥ Bloc 2.3 â€” Consumer Patterns AvancÃ©s (1h30)

> **ThÃ©orie** : 20 min | **Lab** : 1h10

### Concepts clÃ©s

```mermaid
flowchart LR
    subgraph Pipeline["ğŸ¦ E-Banking Pipeline"]
        T["banking.transactions<br/>(6 partitions)"]
        C["âš™ï¸ Consumer"]
        D{OK?}
        R["ğŸ”„ Retry<br/>(backoff + jitter)"]
        DLT["ğŸ’€ DLT"]
        DB[("ğŸ’¾ Audit DB")]
    end

    T --> C --> D
    D -->|"âœ…"| DB
    D -->|"âŒ transient"| R
    R -->|"max retries"| DLT
    R -->|"retry"| C
    D -->|"âŒ permanent"| DLT

    style DLT fill:#ffcccc
    style DB fill:#ccffcc
```

| Pattern | Quand | ImplÃ©mentation |
| ------- | ----- | -------------- |
| **DLT (Dead Letter Topic)** | Message non traitable aprÃ¨s N retries | Producer vers `banking.transactions.dlq` avec headers de traÃ§abilitÃ© |
| **Retry + Backoff** | Erreur transitoire (timeout, DB lock) | `Math.Pow(2, attempt) * baseDelay + jitter` |
| **Error Classification** | Distinguer transient vs permanent | `IsTransient(ex)` â†’ retry, sinon DLT immÃ©diat |
| **Rebalancing Handlers** | Scaling up/down des consumers | `SetPartitionsRevokedHandler` â†’ commit avant rÃ©vocation |

### Lab 2.3 â€” DLT, Retry & Rebalancing

> ğŸ“‚ **[lab-2.3a â€” Consumer DLT & Retry](./module-04-advanced-patterns/lab-2.3a-consumer-dlt-retry/README.md)**

**Objectifs du lab** :

1. Envoyer des messages valides et invalides, observer le routage vers DLT
2. Observer les retries avec backoff exponentiel dans les logs
3. Scaler le consumer Ã  2 replicas et observer le rebalancing CooperativeSticky
4. Consulter les mÃ©triques via `/api/v1/stats` et `/api/v1/dlt/messages`

**Concepts couverts** :

- `EnableAutoCommit = false` + `Commit()` explicite
- `EnableAutoOffsetStore = false` + `StoreOffset()` pour contrÃ´le fin
- `PartitionAssignmentStrategy = CooperativeSticky`
- Classification transient vs permanent avec pattern matching C#
- DLT avec headers : `original-topic`, `error-reason`, `retry-count`, `failed-at`

---

## ğŸ”Œ Bloc 2.4 â€” Kafka Connect Introduction (45 min)

> **ThÃ©orie** : 30 min | **DÃ©mo** : 15 min

### Concepts clÃ©s

```mermaid
flowchart LR
    subgraph Sources["ğŸ“¥ Sources"]
        DB[("ğŸ—„ï¸ SQL Server")]
        FILE["ğŸ“„ CSV/JSON"]
    end

    subgraph Connect["ğŸ”Œ Kafka Connect"]
        SC["Source Connector"]
        SK["Sink Connector"]
    end

    subgraph Kafka["ğŸ“¦ Kafka"]
        T["Topics"]
    end

    subgraph Sinks["ğŸ“¤ Destinations"]
        ES[("ğŸ” Elasticsearch")]
        S3["â˜ï¸ Blob Storage"]
    end

    DB --> SC --> T
    FILE --> SC
    T --> SK --> ES
    T --> SK --> S3
```

| Concept | Description |
| ------- | ----------- |
| **Source Connector** | Lit des donnÃ©es externes â†’ Kafka topics |
| **Sink Connector** | Lit Kafka topics â†’ Ã©crit vers systÃ¨mes externes |
| **Worker** | Process JVM qui exÃ©cute les connecteurs |
| **Task** | UnitÃ© de parallÃ©lisme au sein d'un connecteur |
| **Converter** | Transforme les donnÃ©es (JsonConverter, AvroConverter) |

> ğŸ”— **Lab complet Kafka Connect** : voir **[Day 03 â€” Module 06](../day-03-integration/module-06-kafka-connect/README.md)**

**Preview** : Demain (Day 03) vous dÃ©ploierez un connecteur **SQL Server CDC â†’ Kafka** et un **Kafka â†’ Elasticsearch** pour indexer les transactions bancaires en temps rÃ©el.

---

## ğŸ—ï¸ Architecture Day 02

```mermaid
flowchart TB
    subgraph Docker["ğŸ³ Docker Network: bhf-kafka-network"]
        subgraph Infra["Infrastructure"]
            K["ğŸ“¦ Kafka<br/>:9092"]
            UI["ğŸ–¥ï¸ Kafka UI<br/>:8080"]
            SR["ğŸ›ï¸ Schema Registry<br/>:8081"]
        end

        subgraph Bloc21["Bloc 2.1 - Serialization"]
            SER["ğŸ”· .NET Serializer Demo"]
        end

        subgraph Bloc22["Bloc 2.2 - Idempotent Producer"]
            IDEM["ğŸ”· .NET Idempotent Producer"]
        end

        subgraph Bloc23["Bloc 2.3 - Consumer Advanced"]
            NET04["ğŸ”· .NET DLT Consumer<br/>:18083"]
        end
    end

    SER --> K
    IDEM --> K
    K -->|"banking.transactions"| NET04
    NET04 -->|"banking.transactions.dlq"| K
    UI --> K
    SER --> SR
```

---

## ğŸ“¦ Modules & Labs

| Bloc | Module | Lab | DurÃ©e | Description |
| ---- | ------ | --- | ----- | ----------- |
| 2.1 | [Serialization](./module-04-advanced-patterns/lab-2.1a-serialization/README.md) | Lab 2.1a | 40 min | JSON typÃ©, validation, intro Avro |
| 2.2 | [Producer Advanced](./module-04-advanced-patterns/lab-2.2-producer-advanced/README.md) | Lab 2.2a | 55 min | Idempotence, PID, transactions |
| 2.3 | [Consumer Advanced](./module-04-advanced-patterns/lab-2.3a-consumer-dlt-retry/README.md) | Lab 2.3a | 1h10 | DLT, Retry, Rebalancing |
| 2.4 | Kafka Connect | (Day 03 preview) | 15 min | DÃ©mo Source/Sink connectors |

---

## ğŸš€ Quick Start

### DÃ©marrer l'infrastructure

<details>
<summary>ğŸ³ Docker</summary>

```bash
# Depuis la racine du projet
cd day-01-foundations/module-01-cluster
./scripts/up.sh

# VÃ©rifier que Kafka est healthy
docker ps | grep kafka
```

</details>

<details>
<summary>â˜ï¸ OpenShift Sandbox</summary>

```bash
oc login --token=<TOKEN> --server=<SERVER>
oc get pods -l app=kafka
```

</details>

### Lancer les labs

```bash
# Lab 2.1a â€” Serialization
cd day-02-development/module-04-advanced-patterns/lab-2.1a-serialization/dotnet
dotnet run

# Lab 2.2a â€” Idempotent Producer
cd ../../lab-2.2-producer-advanced/dotnet
dotnet run

# Lab 2.3a â€” DLT & Retry Consumer
cd ../../lab-2.3a-consumer-dlt-retry/dotnet
dotnet run
```

---

## âš ï¸ Troubleshooting

| Erreur | Cause | Solution |
| ------ | ----- | -------- |
| `ClusterAuthorizationException` | Idempotence non autorisÃ©e | VÃ©rifier les ACLs broker ou dÃ©sactiver `EnableIdempotence` |
| `InvalidPidMappingException` | PID expirÃ© (transaction timeout) | Augmenter `TransactionalId` timeout ou recrÃ©er le producer |
| `SerializationException` | Schema incompatible | VÃ©rifier compatibilitÃ© dans Schema Registry |
| Message dans DLT | Erreur de traitement | Analyser headers `error-reason` dans le message DLT |
| `Rebalancing in progress` | Consumer group instable | VÃ©rifier `SessionTimeoutMs` et `HeartbeatIntervalMs` |

---

## âœ… Validation Day 02

- [ ] Lab 2.1 : Serializer JSON typÃ© fonctionne, validation dÃ©tecte les schÃ©mas invalides
- [ ] Lab 2.2 : Producer idempotent activÃ©, PID visible dans les logs, pas de duplicatas aprÃ¨s retry
- [ ] Lab 2.3 : Messages invalides routÃ©s vers DLT, retries visibles dans les logs, rebalancing observÃ©
- [ ] Comprendre la diffÃ©rence entre at-least-once et exactly-once
- [ ] Savoir quand utiliser `EnableIdempotence` vs Transactions complÃ¨tes

---

## â¡ï¸ Navigation

â¬…ï¸ **[Day 01 â€” Fondamentaux](../day-01-foundations/module-01-cluster/README.md)** | â¡ï¸ **[Day 03 â€” IntÃ©gration, Tests & ObservabilitÃ©](../day-03-integration/README.md)**
