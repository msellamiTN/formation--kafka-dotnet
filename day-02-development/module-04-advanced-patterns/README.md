# üîÑ Module 04 - Patterns Avanc√©s : DLT, Retries & Rebalancing

| Dur√©e | Niveau | Pr√©requis |
|-------|--------|-----------|
| 3 heures | Interm√©diaire | Modules 01-03 compl√©t√©s |

## üè¶ Sc√©nario E-Banking (suite)

Dans les modules pr√©c√©dents, vous avez construit un Producer et un Consumer pour traiter les transactions bancaires (`banking.transactions`). Dans ce module, vous allez renforcer la **r√©silience** de ce pipeline en ajoutant :

- Un **Dead Letter Topic** pour isoler les transactions qui √©chouent au traitement (montant invalide, client inconnu, etc.)
- Des **retries avec backoff exponentiel** pour les erreurs transitoires (timeout base de donn√©es, service de scoring indisponible)
- Le **rebalancing CooperativeSticky** pour scaler horizontalement le service de d√©tection de fraude

> **Note** : Les labs pratiques utilisent un topic `orders` g√©n√©rique configurable via la variable d'environnement `KAFKA_TOPIC`. Les patterns appris s'appliquent directement √† votre pipeline `banking.transactions`.

## ÔøΩ Objectifs d'apprentissage

√Ä la fin de ce module, vous serez capable de :

- ‚úÖ Impl√©menter un Dead Letter Topic (DLT) pour g√©rer les messages en erreur
- ‚úÖ Configurer des strat√©gies de retry robustes avec Polly (.NET) ou Spring Retry (Java)
- ‚úÖ Comprendre et g√©rer le rebalancing des consumer groups
- ‚úÖ Impl√©menter des patterns de gestion d'erreurs professionnels
- ‚úÖ Appliquer ces patterns √† un pipeline de transactions bancaires

---

## üìö Partie Th√©orique (30%)

### 1. Dead Letter Topics (DLT)

#### Concept

Un **Dead Letter Topic** est un topic sp√©cial o√π sont envoy√©s les messages qui ne peuvent pas √™tre trait√©s apr√®s plusieurs tentatives. C'est un pattern essentiel pour la r√©silience des applications.

```mermaid
flowchart LR
    subgraph flow[" "]
        direction LR
        P["üì§ Producer"] --> T["üì¶ Topic"]
        T --> C["‚öôÔ∏è Consumer"]
        C --> D{OK?}
        D -->|‚úÖ| CO["Commit"]
        D -->|‚ùå| R["Retry"]
        R -->|max| DLT["üíÄ DLT"]
        R -->|retry| C
    end
    style DLT fill:#ffcccc
    style CO fill:#ccffcc
```

#### Quand utiliser un DLT ?

| Situation | Avec DLT | Sans DLT |
|-----------|----------|----------|
| Message malform√© | ‚úÖ Isol√© pour analyse | ‚ùå Bloque le consumer |
| Service externe down | ‚úÖ Retry puis DLT | ‚ùå Perte ou blocage |
| Erreur de validation | ‚úÖ Tra√ßabilit√© | ‚ùå Message perdu |
| Bug applicatif | ‚úÖ Replay possible | ‚ùå Donn√©es perdues |

#### Structure d'un message DLT

```json
{
  "originalTopic": "orders",
  "originalPartition": 2,
  "originalOffset": 12345,
  "originalKey": "order-123",
  "originalValue": "{...}",
  "errorMessage": "ValidationException: Invalid amount",
  "errorTimestamp": "2024-01-15T10:30:00Z",
  "retryCount": 3,
  "stackTrace": "..."
}
```

---

### 2. Strat√©gies de Retry

#### Types de Retry

```mermaid
flowchart TB
    subgraph strategies["STRAT√âGIES DE RETRY"]
        direction TB
        subgraph s1["1Ô∏è‚É£ Imm√©diat"]
            A1["T1‚ÜíT2‚ÜíT3‚ÜíDLT"]
        end
        subgraph s2["2Ô∏è‚É£ Fixe (1s)"]
            A2["T1‚îÄ1s‚îÄT2‚îÄ1s‚îÄT3"]
        end
        subgraph s3["3Ô∏è‚É£ Exponentiel ‚úÖ"]
            A3["T1‚îÄ1s‚îÄT2‚îÄ2s‚îÄT3‚îÄ4s"]
        end
        subgraph s4["4Ô∏è‚É£ Expo+Jitter"]
            A4["T1‚îÄ1s¬±‚îÄT2‚îÄ2s¬±‚îÄT3"]
        end
    end
    style s3 fill:#e8f5e9
```

#### Configuration recommand√©e

```csharp
// Backoff exponentiel avec jitter (utilisant Polly)
var retryPolicy = Policy
    .Handle<KafkaException>(ex => ex.Error.IsFatal == false) // Erreurs transient uniquement
    .WaitAndRetryAsync(
        retryCount: 5,
        sleepDurationProvider: attempt =>
        {
            var baseDelay = TimeSpan.FromSeconds(Math.Pow(2, attempt - 1)); // 1s, 2s, 4s, 8s, 16s
            var maxDelay = TimeSpan.FromMinutes(5);
            var delay = baseDelay < maxDelay ? baseDelay : maxDelay;
            var jitter = TimeSpan.FromMilliseconds(Random.Shared.Next(0, (int)(delay.TotalMilliseconds * 0.2)));
            return delay + jitter;
        },
        onRetry: (exception, timespan, attempt, context) =>
        {
            logger.LogWarning("Retry {Attempt}/5 dans {Delay}ms : {Error}",
                attempt, timespan.TotalMilliseconds, exception.Message);
        });
```

#### Erreurs Retryables vs Non-Retryables

| Type | Exemples | Action |
|------|----------|--------|
| **Retryable** | Timeout r√©seau, Service indisponible, Rate limit | Retry avec backoff |
| **Non-Retryable** | Validation √©chou√©e, Message malform√©, Auth failure | DLT imm√©diat |

---

### 3. Consumer Rebalancing

#### Qu'est-ce que le Rebalancing ?

Le **rebalancing** est le processus par lequel Kafka redistribue les partitions entre les consumers d'un m√™me group lorsque :
- Un consumer rejoint le group
- Un consumer quitte le group (crash ou shutdown)
- Le nombre de partitions change

```mermaid
flowchart LR
    subgraph avant["AVANT"]
        C1["C1: P0,P1,P2"]
        C2["C2: P3,P4,P5"]
    end
    
    avant -->|"üîÑ"| apres
    
    subgraph apres["APR√àS"]
        C1B["C1: P0,P1"]
        C2B["C2: P2,P3"]
        C3B["C3: P4,P5"]
    end
    
    style C3B fill:#e8f5e9
```

> ‚ö†Ô∏è **PENDANT LE REBALANCING** : Aucun consumer ne traite de messages!

#### Strat√©gies d'assignation

| Strat√©gie | Description | Cas d'usage |
|-----------|-------------|-------------|
| **RangeAssignor** | Assignation par plage contigu√´ | Par d√©faut, simple |
| **RoundRobinAssignor** | Distribution √©quitable | Charge uniforme |
| **StickyAssignor** | Minimise les mouvements | R√©duire le rebalancing |
| **CooperativeStickyAssignor** | Rebalancing incr√©mental | Production (recommand√©) |

#### Callbacks de Rebalancing

```csharp
using var consumer = new ConsumerBuilder<string, string>(config)
    .SetPartitionsRevokedHandler((c, partitions) =>
    {
        // Appel√© AVANT que les partitions soient retir√©es
        // ‚Üí Commit les offsets, flush les buffers
        logger.LogInformation("Partitions r√©voqu√©es: {Partitions}",
            string.Join(", ", partitions));
        c.Commit();
    })
    .SetPartitionsAssignedHandler((c, partitions) =>
    {
        // Appel√© APR√àS que les nouvelles partitions sont assign√©es
        // ‚Üí Initialiser l'√©tat, seek si n√©cessaire
        logger.LogInformation("Partitions assign√©es: {Partitions}",
            string.Join(", ", partitions));
    })
    .Build();

consumer.Subscribe(topics);
```

---

### 4. Gestion d'erreurs professionnelle

#### Hi√©rarchie des erreurs Kafka

```mermaid
flowchart LR
    KE["KafkaException"] --> RP["üîÑ Retriable"]
    KE --> FE["üíÄ Fatal"]
    
    RP --> R1["Timeout"]
    RP --> R2["Leader N/A"]
    RP --> R3["Rebalance"]
    
    FE --> F1["Auth fail"]
    FE --> F2["Bad config"]
    FE --> F3["Serialize err"]
    
    style RP fill:#fff3cd
    style FE fill:#ffcccc
```

| Type | Action |
|------|--------|
| **Retriable** | Retry avec backoff |
| **Fatal** | Fail fast ‚Üí DLT |

#### Pattern de gestion d'erreurs complet

```csharp
async Task ProcessWithErrorHandlingAsync(
    ConsumeResult<string, string> result, 
    ILogger logger,
    int maxRetries = 3)
{
    int retryCount = 0;
    bool processed = false;

    while (!processed && retryCount < maxRetries)
    {
        try
        {
            // Traitement m√©tier
            await ProcessRecordAsync(result);
            processed = true;
        }
        catch (Exception ex) when (IsTransient(ex))
        {
            // Erreur temporaire ‚Üí retry
            retryCount++;
            logger.LogWarning("Retry {RetryCount}/{MaxRetries} pour offset {Offset}: {Error}",
                retryCount, maxRetries, result.Offset.Value, ex.Message);
            var delay = TimeSpan.FromSeconds(Math.Pow(2, retryCount - 1)
                        + Random.Shared.NextDouble());
            await Task.Delay(delay);
        }
        catch (Exception ex)
        {
            // Erreur permanente ‚Üí DLT imm√©diat
            await SendToDltAsync(result, ex);
            processed = true;
        }
    }

    if (!processed)
    {
        // Max retries atteint ‚Üí DLT
        await SendToDltAsync(result, new InvalidOperationException("Max retries exceeded"));
    }
}

bool IsTransient(Exception ex) => ex is TimeoutException
    or OperationCanceledException
    or KafkaException { Error.IsFatal: false };
```

---

## üîå Ports et Services

| Service | Port | Description |
|---------|------|-------------|
| Java API (Producer/Consumer) | 18082 | API avec DLT et retries |
| .NET API (Consumer) | 18083 | Consumer avec DLT, retries et rebalancing |
| Kafka UI | 8080 | Visualisation des topics |
| Kafka | 9092 | Broker externe |

### üî∑ Code .NET disponible

Le consumer .NET avec DLT, retry et rebalancing est disponible dans [`dotnet/Program.cs`](./dotnet/Program.cs). Il impl√©mente :

- **Dead Letter Topic** : envoi des messages en erreur permanente vers `orders.DLT` avec headers de tra√ßabilit√©
- **Retry avec backoff exponentiel + jitter** : erreurs transitoires retent√©es N fois avant DLT
- **Classification des erreurs** : transient (timeout, r√©seau) ‚Üí retry, permanent (validation, JSON invalide) ‚Üí DLT imm√©diat
- **Validation m√©tier** : rejet des montants n√©gatifs, JSON malform√©
- `CooperativeSticky` partition assignment
- `SetPartitionsAssignedHandler` / `SetPartitionsRevokedHandler` / `SetPartitionsLostHandler`
- Manual commit apr√®s chaque message
- API REST : `/api/v1/stats`, `/api/v1/partitions`, `/api/v1/dlt/count`, `/api/v1/dlt/messages`

---

## üõ†Ô∏è Partie Pratique (70%)

### Pr√©requis

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
cd formation-v2/
./scripts/up.sh
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# V√©rifier que le cluster Kafka est pr√™t
kubectl get kafka -n kafka
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka
```

</details>

---

### √âtape 1 - D√©marrer le module

**Objectif** : Lancer les services du module.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker compose -f day-02-development/module-04-advanced-patterns/docker-compose.module.yml up -d --build
```

**V√©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}' | grep m04
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Builder et pousser les images vers le registry local
cd formation-v2/day-02-development/module-04-advanced-patterns

docker build -t localhost:5000/m04-java-api:latest -f java/Dockerfile java/
docker push localhost:5000/m04-java-api:latest

# D√©ployer sur K8s
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: m04-java-api
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: m04-java-api
  template:
    metadata:
      labels:
        app: m04-java-api
    spec:
      containers:
      - name: java-api
        image: localhost:5000/m04-java-api:latest
        ports:
        - containerPort: 8080
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "bhf-kafka-kafka-bootstrap.kafka.svc:9092"
---
apiVersion: v1
kind: Service
metadata:
  name: m04-java-api
  namespace: kafka
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    nodePort: 31082
  selector:
    app: m04-java-api
EOF
```

**V√©rification** :

```bash
kubectl get pods -n kafka -l app=m04-java-api
```

</details>

---

### √âtape 2 - Cr√©er les topics

**Objectif** : Cr√©er le topic principal et le DLT.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Topic principal
docker exec kafka kafka-topics --create \
  --topic orders \
  --partitions 6 \
  --replication-factor 1 \
  --bootstrap-server localhost:9092

# Dead Letter Topic
docker exec kafka kafka-topics --create \
  --topic orders.DLT \
  --partitions 3 \
  --replication-factor 1 \
  --bootstrap-server localhost:9092

# Topic de retry
docker exec kafka kafka-topics --create \
  --topic orders.retry \
  --partitions 3 \
  --replication-factor 1 \
  --bootstrap-server localhost:9092
```

**V√©rification** :

```bash
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 | grep orders
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Cr√©er les topics via KafkaTopic CRs
cat <<EOF | kubectl apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: orders
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 6
  replicas: 3
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: orders.dlt
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 3
  replicas: 3
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: orders.retry
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 3
  replicas: 3
EOF
```

**V√©rification** :

```bash
kubectl get kafkatopics -n kafka | grep orders
```

</details>

**R√©sultat attendu** :

```text
orders
orders.DLT
orders.retry
```

---

### √âtape 3 - Lab 1 : Envoi de messages valides

**Objectif** : V√©rifier le flux normal sans erreur.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Envoyer 5 messages valides
for i in {1..5}; do
  curl -X POST "http://localhost:18082/api/v1/orders" \
    -H "Content-Type: application/json" \
    -d "{\"orderId\": \"ORD-$i\", \"amount\": $((i * 100)), \"status\": \"PENDING\"}"
  echo ""
done
```

**V√©rification dans Kafka UI** :

1. Ouvrez http://localhost:8080
2. Cliquez sur **Topics** ‚Üí **orders**
3. V√©rifiez que 5 messages sont pr√©sents

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Envoyer 5 messages valides (NodePort 31082)
for i in {1..5}; do
  curl -X POST "http://localhost:31082/api/v1/orders" \
    -H "Content-Type: application/json" \
    -d "{\"orderId\": \"ORD-$i\", \"amount\": $((i * 100)), \"status\": \"PENDING\"}"
  echo ""
done
```

**V√©rification via kubectl** :

```bash
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic orders --from-beginning --max-messages 5
```

</details>

---

### √âtape 4 - Lab 2 : Simulation d'erreurs et DLT

**Objectif** : Observer le comportement avec des messages invalides.

#### 4.1 Envoyer un message invalide (montant n√©gatif)

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
curl -X POST "http://localhost:18082/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-INVALID", "amount": -50, "status": "PENDING"}'
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
curl -X POST "http://localhost:31082/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-INVALID", "amount": -50, "status": "PENDING"}'
```

</details>

**R√©sultat attendu** : Le message est rejet√© et envoy√© au DLT.

#### 4.2 V√©rifier le DLT

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker exec kafka kafka-console-consumer \
  --topic orders.DLT \
  --from-beginning \
  --max-messages 1 \
  --bootstrap-server localhost:9092
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic orders.dlt --from-beginning --max-messages 1
```

</details>

**R√©sultat attendu** : Message avec m√©tadonn√©es d'erreur.

---

### √âtape 5 - Lab 3 : Test des retries avec erreur transitoire

**Objectif** : Observer le m√©canisme de retry.

#### 5.1 Activer le mode "erreur transitoire"

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
curl -X POST "http://localhost:18082/api/v1/config/simulate-transient-error?enabled=true"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
curl -X POST "http://localhost:31082/api/v1/config/simulate-transient-error?enabled=true"
```

</details>

#### 5.2 Envoyer un message

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
curl -X POST "http://localhost:18082/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-RETRY", "amount": 200, "status": "PENDING"}'
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
curl -X POST "http://localhost:31082/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-RETRY", "amount": 200, "status": "PENDING"}'
```

</details>

#### 5.3 Observer les logs

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker logs m04-java-api --tail 50 | grep -E "(Retry|attempt|DLT)"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl logs -n kafka -l app=m04-java-api --tail 50 | grep -E "(Retry|attempt|DLT)"
```

</details>

**R√©sultat attendu** : Plusieurs tentatives avant succ√®s ou DLT.

#### 5.4 D√©sactiver le mode erreur

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
curl -X POST "http://localhost:18082/api/v1/config/simulate-transient-error?enabled=false"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
curl -X POST "http://localhost:31082/api/v1/config/simulate-transient-error?enabled=false"
```

</details>

---

### √âtape 6 - Lab 4 : Observer le Rebalancing

**Objectif** : Voir le rebalancing en action.

#### 6.1 D√©marrer un second consumer

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker compose -f day-02-development/module-04-advanced-patterns/docker-compose.module.yml \
  up -d --scale dotnet-consumer=2
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl scale deployment m04-java-api -n kafka --replicas=2
```

</details>

#### 6.2 Observer les logs de rebalancing

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker logs m04-dotnet-consumer-1 --tail 20 | grep -i rebalance
docker logs m04-dotnet-consumer-2 --tail 20 | grep -i rebalance
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl logs -n kafka -l app=m04-java-api --tail 20 | grep -i rebalance
```

</details>

#### 6.3 Envoyer des messages pendant le rebalancing

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
for i in {1..10}; do
  curl -X POST "http://localhost:18082/api/v1/orders" \
    -H "Content-Type: application/json" \
    -d "{\"orderId\": \"ORD-REBAL-$i\", \"amount\": 100, \"status\": \"PENDING\"}"
done
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
for i in {1..10}; do
  curl -X POST "http://localhost:31082/api/v1/orders" \
    -H "Content-Type: application/json" \
    -d "{\"orderId\": \"ORD-REBAL-$i\", \"amount\": 100, \"status\": \"PENDING\"}"
done
```

</details>

#### 6.4 Arr√™ter un consumer pour d√©clencher un rebalancing

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker stop m04-dotnet-consumer-2
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl scale deployment m04-java-api -n kafka --replicas=1
```

</details>

**Observer** : Les logs du consumer 1 montrent la r√©assignation des partitions.

---

### √âtape 7 - Lab 5 : Monitoring des erreurs

**Objectif** : Utiliser les endpoints de monitoring.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Statistiques des erreurs
curl -s http://localhost:18082/api/v1/stats | jq

# Messages dans le DLT
curl -s http://localhost:18082/api/v1/dlt/count

# Health check
curl -s http://localhost:18082/health
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Statistiques des erreurs (NodePort 31082)
curl -s http://localhost:31082/api/v1/stats | jq

# Messages dans le DLT
curl -s http://localhost:31082/api/v1/dlt/count

# Health check
curl -s http://localhost:31082/health
```

</details>

---

## ‚úÖ Checkpoint de validation

Cochez chaque √©l√©ment compl√©t√© :

- [ ] Topic `orders` cr√©√© avec 6 partitions
- [ ] Topic `orders.DLT` cr√©√©
- [ ] Messages valides trait√©s correctement
- [ ] Message invalide rout√© vers DLT
- [ ] Retries observ√©s dans les logs
- [ ] Rebalancing d√©clench√© et observ√©
- [ ] Statistiques d'erreurs consult√©es

---

## ‚òÅÔ∏è D√©ploiement sur OpenShift Sandbox

Si vous utilisez le **Red Hat Developer Sandbox** au lieu de Docker local ou K3s, suivez ces √©tapes pour d√©ployer les deux services du module.

### 1. Cr√©er les topics sur le Sandbox

```bash
oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic orders --partitions 6 --replication-factor 3

oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic orders.DLT --partitions 3 --replication-factor 3

oc exec kafka-0 -- /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic orders.retry --partitions 3 --replication-factor 3
```

### 2. D√©ployer l'API Java (Producer + DLT)

```bash
cd day-02-development/module-04-advanced-patterns/java

oc new-build java:17 --binary=true --name=m04-java-api
oc start-build m04-java-api --from-dir=. --follow
oc new-app m04-java-api

oc set env deployment/m04-java-api \
  KAFKA_BOOTSTRAP_SERVERS="kafka-svc:9092" \
  KAFKA_TOPIC="orders" \
  KAFKA_DLT_TOPIC="orders.DLT" \
  KAFKA_RETRY_TOPIC="orders.retry" \
  MAX_RETRIES="3" \
  RETRY_BACKOFF_MS="1000" \
  SERVER_PORT="8080"

oc expose svc/m04-java-api
```

### 3. D√©ployer le Consumer .NET (Rebalancing)

```bash
cd ../dotnet

oc new-build dotnet:8.0-ubi8 --binary=true --name=m04-dotnet-consumer
oc start-build m04-dotnet-consumer --from-dir=. --follow
oc new-app m04-dotnet-consumer

oc set env deployment/m04-dotnet-consumer \
  KAFKA_BOOTSTRAP_SERVERS="kafka-svc:9092" \
  KAFKA_TOPIC="orders" \
  KAFKA_GROUP_ID="orders-consumer-group" \
  KAFKA_AUTO_OFFSET_RESET="earliest" \
  ASPNETCORE_URLS="http://0.0.0.0:8080"

oc expose svc/m04-dotnet-consumer
```

### 4. Tester sur le Sandbox

```bash
# URLs publiques
JAVA_HOST=$(oc get route m04-java-api -o jsonpath='{.spec.host}')
DOTNET_HOST=$(oc get route m04-dotnet-consumer -o jsonpath='{.spec.host}')

# Envoyer un message valide
curl -s -X POST "https://$JAVA_HOST/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-1", "amount": 100, "status": "PENDING"}' | jq .

# Envoyer un message invalide (‚Üí DLT)
curl -s -X POST "https://$JAVA_HOST/api/v1/orders" \
  -H "Content-Type: application/json" \
  -d '{"orderId": "ORD-INVALID", "amount": -50, "status": "PENDING"}' | jq .

# Statistiques du consumer .NET
curl -s "https://$DOTNET_HOST/api/v1/stats" | jq .

# V√©rifier le DLT
oc exec kafka-0 -- /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic orders.DLT --from-beginning --max-messages 5
```

### 5. Observer le Rebalancing sur le Sandbox

```bash
# Scaler √† 2 replicas
oc scale deployment/m04-dotnet-consumer --replicas=2

# Observer les logs de rebalancing
oc logs -l deployment=m04-dotnet-consumer --tail=20 | grep -i rebalance

# Revenir √† 1 replica
oc scale deployment/m04-dotnet-consumer --replicas=1
```

---

## üîß Troubleshooting

### Consumer bloqu√©

**Sympt√¥me** : Pas de traitement des messages.

```bash
# V√©rifier le lag
docker exec kafka kafka-consumer-groups \
  --describe --group orders-consumer-group \
  --bootstrap-server localhost:9092
```

### DLT vide alors qu'il devrait y avoir des erreurs

**Sympt√¥me** : Pas de messages dans le DLT.

```bash
# V√©rifier les logs
docker logs m04-java-api --tail 100 | grep -i error
```

### Rebalancing trop fr√©quent

**Sympt√¥me** : Logs montrant des rebalancing constants.

**Cause possible** : `session.timeout.ms` trop court.

---

## üßπ Nettoyage

```bash
docker compose -f day-02-development/module-04-advanced-patterns/docker-compose.module.yml down

# Supprimer les topics (optionnel)
docker exec kafka kafka-topics --delete --topic orders --bootstrap-server localhost:9092
docker exec kafka kafka-topics --delete --topic orders.DLT --bootstrap-server localhost:9092
docker exec kafka kafka-topics --delete --topic orders.retry --bootstrap-server localhost:9092
```

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Configurez un backoff exponentiel** avec un maximum de 5 minutes
2. **Ajoutez un circuit breaker** pour les erreurs r√©p√©t√©es
3. **Impl√©mentez un DLT processor** qui retraite automatiquement les erreurs corrigibles

### Ressources

- [Error Handling in Kafka](https://docs.confluent.io/platform/current/clients/consumer.html#error-handling)
- [Consumer Rebalance Protocol](https://cwiki.apache.org/confluence/display/KAFKA/KIP-429%3A+Kafka+Consumer+Incremental+Rebalance+Protocol)
- [Dead Letter Queue Pattern](https://www.enterpriseintegrationpatterns.com/patterns/messaging/DeadLetterChannel.html)

---

## üõ†Ô∏è Tutorials pas-√†-pas

| IDE | Tutorial | Description |
|-----|----------|-------------|
| **VS Code** | [TUTORIAL-DOTNET.md](./TUTORIAL-DOTNET.md) | DLT, Retry avec Polly, Batch |
| **Visual Studio 2022** | [TUTORIAL-VS2022.md](./TUTORIAL-VS2022.md) | Projet complet avec Circuit Breaker, debugging |
| **IntelliJ / VS Code** | [TUTORIAL-JAVA.md](./TUTORIAL-JAVA.md) | Spring Kafka avec RetryTemplate |
